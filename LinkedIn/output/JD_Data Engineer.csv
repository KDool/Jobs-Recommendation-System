id|jobTitle|location|company|type|description
2987770247|Data Engineer|Hanoi, Hanoi, Vietnam|APERO|Full-time|"About the job
Responsibilities
X√¢y d·ª±ng v√† b·∫£o tr√¨ h·ªá th·ªëng dwh c·ªßa c√¥ng ty, s·ª≠ d·ª•ng google bigquery
Collect y√™u c·∫ßu tracking t·ª´ marketing ho·∫∑c PO, l√™n ph∆∞∆°ng √°n tracking data v√† l√†m vi·ªác v·ªõi team dev ƒë·ªÉ setup vi·ªác collect data
Thu th·∫≠p d·ªØ li·ªáu t·ª´ c√°c ngu·ªìn kh√°c nhau v·ªÅ DWH
Qualifications
C√≥ √≠t nh·∫•t 2 nƒÉm kinh nghi·ªám l√†m vi·ªác trong lƒ©nh v·ª±c data engineering
Th√†nh th·∫°o google firebase, bigquery
C√≥ kinh nghi·ªám l√†m vi·ªác v·ªõi √≠t nh·∫•t 1 trong c√°c ng√¥n ng·ªØ: Java, Python
C√≥ kinh nghi·ªám l√†m vi·ªác v·ªõi SQL DB (MySQL, Postgres, Redshift) v√† NoSql DB (MongoDb, Redis, DynamoDB..).
C√≥ kinh nghi·ªám l√†m vi·ªác v·ªõi nhi·ªÅu ngu·ªìn d·ªØ li·ªáu kh√°c nhau l√† 1 l·ª£i th·∫ø
C√≥ kinh nghi·ªám ph√¢n t√≠ch data l√† l·ª£i th·∫ø l·ªõn
Benefits
M·ª©c l∆∞∆°ng th·ªèa thu·∫≠n h·∫•p d·∫´n theo nƒÉng l·ª±c (25-40M)
X√©t tƒÉng l∆∞∆°ng 2 l·∫ßn/ nƒÉm.
Th∆∞·ªüng ƒë·ªãnh k·ª≥ 2 l·∫ßn/ nƒÉm
Tham gia c√°c d·ª± √°n ch·∫•t l∆∞·ª£ng cao ƒë·ªÉ ph√°t tri·ªÉn b·∫£n th√¢n.
ƒê∆∞·ª£c tr·∫£i nghi·ªám t·ª´ ƒë·∫ßu qu√° tr√¨nh khai ph√° v√† tr·ªü th√†nh co-founder c·ªßa h·ªá sinh th√°i game/app mobile h√†ng tri·ªáu download/th√°ng
L√†m vi·ªác trong m√¥i tr∆∞·ªùng chuy√™n nghi·ªáp c√πng c√°c ƒë·ªìng nghi·ªáp gi·ªèi, c√≥ nhi·ªÅu kinh nghi·ªám.
Tham gia c√°c ho·∫°t ƒë·ªông vui ch∆°i gi·∫£i tr√≠, du l·ªãch, team building, ƒÉn u·ªëng c√πng c√°c th√†nh vi√™n trong c√¥ng ty.
About Us
Startup v·ªÅ App v√† Game. - Th√†nh l·∫≠p 05/2020
Link gi·ªõi thi·ªáu v·ªÅ c√¥ng ty: https://drive.google.com/file/d/1KRKRrEV217Uly7wd2OjQgouW5cFPXdSi/view?fbclid=IwAR1tspKGLoT28qqpjKknFnh6Iry6ZoSkfL6vxLaRXvSZRN9tHpkSmQaDXEg
Vision c·ªßa c√¥ng ty trong 3-5 nƒÉm s·∫Ω tr·ªü th√†nh top Tech Company in Vietnam and Asia
Link: https://play.google.com/store/apps/developer?id=TrustedApp
Link game store: https://play.google.com/store/apps/details?
Link andoroid app: id=com.pixel.art.coloring.by.number&fbclid=IwAR1QrloT7Uf6DKgoS8QnGljwuqr4vyEzgXnt389nv-tmtIcI8IqVqO2ZE3g
Link App: https://play.google.com/store/apps/dev?id=8737102155398054550
https://play.google.com/store/apps/developer?id=Apero+Games
Contact the job poster
H√≤a Nh√£ 2nd
Technical Recruiter
Job Poster Location
Vietnam
Send InMail"
2975607931|Data Engineer|Hanoi, Hanoi, Vietnam|Picket Homes|Full-time ¬∑ Entry level|"About the job
Picket is a technology-powered real estate company that is transforming the single-family home rental market at every stage of the value chain, from the way investors acquire and manage high-quality rental properties, to the quality, service, and flexibility residents enjoy when they live in them.

Our proprietary Decision Science platform uses advanced data science and machine learning to identify homes that fit investor criteria and optimize portfolio management and performance at scale.

Picket believes it should be easier to live where you want and love where you live, and we think that starts with a better way to rent. With innovative technology and a customer-first philosophy, we‚Äôre transforming the experience of renting a home at every stage of the value chain, from the way investors acquire and manage single-family rentals, to the quality, service, and flexibility residents enjoy when they live in them.

We are seeking an exceptional startup hybrid of quantitative analyst, data scientist, and software engineer to work closely with executives, real estate professionals, product managers, and engineers to build and implement dynamic models, algorithms, and analysis to predict fair market rental and sale prices, forward appreciation curves, and risk-adjusted investment projections through the incorporation of geo-spatial, financial, real estate, census, and any other relevant data sources, analytics and models. This person must embrace an unusual combination of advanced technologies and extreme pragmatism to solve hard problems quickly, iterating on improvement relentlessly.

Our computing environment consists of common technologies. Time-to-market is a top consideration, so we launch quickly and leverage current team knowledge. Each separable functional product area and tech team will have some latitude in its tech choices, and we support and encourage cross-team sharing and migration as per product priorities and individual passions.

We are hiring smart and passionate people who are flexible, eager, passionate, and customer-centric. We are looking for candidates who can communicate clearly in English and are driven, self-motivated, and willing to take on challenges head on. We are always open to any candidates as long as we believe that we would be able to provide you with an environment for you to grow, develop, and build our company together.

Picket is venture funded, and founded by a team of entrepreneurs and executives from top technology, real estate, and investment companies.

CULTURE
Entrepreneurial: demonstrates passion for customers, innovation, adaption, risk-taking, and bouncing back from failure. Ideal candidates have built their own tech project, regardless of size or success.
Self-determined: continuous self-learner, thrives in a vacuum, shows urgent ownership, operates autonomously, and delivers with discipline in office or remotely.
Communicates frequently, efficiently, openly, and critically in all formats.
Team Player: Ready to mentor, lead, and set a high bar for other team members, and conversely- ready to follow, learn from any, and correct misses.

SALARY & BENEFITS
Competitive compensation package with incentives, including stock options.
Open, flexible, and dynamic working environment.
Industry standard benefits for the health and well-being of our team members

We do not accept solicitations from third-party recruiters for any positions. A background check is required for this position. Picket is an equal-opportunity employer that celebrates diversity and we welcome applicants from all backgrounds.

At Picket Homes, we are building something new and different - come build with us."
2950870014|Data Engineer|Hanoi, Hanoi, Vietnam|Techcombank (TCB)|Full-time ¬∑ Entry level|"About the job
Job Purpose
The job holder is responsible for developing programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from disparate sources and implement complex business logic as needed with the available data processing tools.
The job holder will be responsible for helping build a reliable, sustainable and scalable data processing platform, working with other tribe members to support data pipelines, convert models to machine learning codes and recommend Big Data reporting and visualization applications.
Key Accountabilities (1)
Data Architecture

Deliver functionality required for business and data analysts, data scientists and other business roles to advance the overall analytic performance and strategy of the bank

Assist in building best practices and strategies for data infrastructure to fulfill data analytic and utilization needs of the business with emerging latest technologies and capabilities.
Collaborate with relevant teams on opportunities to manage data and provide solutions for complex data feeds within the bank.
Maintain data integration processes into the data platform by building data pipelines and align with business representatives and business information needs.
Review internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.
Key Accountabilities (2)
Data Integration
Obtain and integrate data and information from various sources into the firm‚Äôs platforms, solutions and statistical models.
Collaborate with Data Scientists to understand data requirements and create re-usable data assets to enable data scientists to build and deploy machine learning models faster.
Write scripts and ingest raw data to build and maintain optimized data pipelines and ETL solutions as business support tools in providing analysis.
Ensure data assets are organized and stored in an efficient way so that information is easy to access and retrieve.
Key Accountabilities (3)

Key Relationships - Direct Manager
Team Lead, Data Engineering; Senior Manager, Data Engineering

Key Relationships - Direct Reports

Key Relationships - Internal Stakeholders
Teams within the Data Office and relevant departments in the Bank

Key Relationships - External Stakeholders
Partners providing professional services

Success Profile - Qualification and Experiences
Qualifications
Bachelor‚Äôs or Master‚Äôs degree in Statistics, Mathematics, Quantitative Analysis, Computer Science, Software Engineering or Information Technology
Work Experience
5+ years of relevant experience with developing, debugging, scripting and employing big data technologies (e.g. Hadoop, Spark, Flink, Kafka, Arrow, Tableau), database technologies (e.g. SQL, NoSQL, Graph databases), and programming languages (e.g. Python, R, Scala, Java, Rust, Kotlin) with preference towards functional/trait oriented
English proficiency requirements are pursuant to Techcombank's policy
Experience in designing and building dimensional data models, ETL processes, applied data warehouse concepts and methodologies, optimized data pipelines and assisted the architect as needed
Experience monitoring complex system and solving data and systems issues having a consistent and algorithmic approach to resolving them
Deep understanding of Information Security principles to ensure compliant handling and management of all data
Experience working in Agile teams to support digital transformation projects, having a clear understanding of Agile principles, practices and Scrum methodologies
Has some know-how and partial scripting and coding experience to set up, configure v√† maintain a machine learning model development environment
Some experience architecting, coding and delivering high performance micro services and/or recommenders delivering recommendations to a large user-base"
2975673294|Data Engineer in Business Intelligence Team (Bangkok based, relocation provided)|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Agoda|Full-time ¬∑ Entry level|"About the job
About Agoda

Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 4,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,‚ÄØenhancing the ability for our customers to experience the world.

Get to Know Our Team

The Data department oversees all of Agoda‚Äôs data-related requirements. Our ultimate goal is to enable and increase the use of data in the company through creative approaches and the implementation of powerful resources such as operational and analytical databases, queue systems, BI tools, and data science technology. We hire the brightest minds from around the world to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company‚Äôs culture of diversity and experimentation. The role the Data team plays at Agoda is critical as business users, product managers, engineers, and many others rely on us to empower their decision making. We are equally dedicated to our customers by improving their search experience with faster results and protecting them from any fraudulent activities. Data is interesting only when you have enough of it, and we have plenty. This is what drives up the challenge as part of the Data department, but also the reward.

The Opportunity

As a Data Engineer in Business Intelligence Team, you will work closely with product managers and BI team to interpret business questions into data needed. You make a design, development, until support and maintain the data pipeline. You will work with variety of data sources, data technology and data tools both in-house and enterprise licenses to build data pipeline and generating data reports.

In This Role, You‚Äôll Get to

Works professionally to understand data needed for finance data analytics and be able to design proper data pipeline solution which is measurable and scalable
Develop data pipeline on Bigdata platform by the following technology stack: Scala, Golang, Python3, scripting (Bash/Python), Hadoop, etc
Ensure delivered data achieve team‚Äôs standard quality checklist and always have visibility on it
Be responsive to work within a deadline
Keep catching up on data technology and have up to date data insight with the team

What You‚Äôll Need To Succeed

Bachelor‚Äôs or advance degree in IT/Statistic related field
More than 3 years of experience in data technology
Fluent in English and Interpersonal skills
Experience in ETL tools or data pipeline language such as Python, Scala
Knowledgeable in using Databases and writing SQL queries
Good time management and multitasking skills
Self-motivation and ability to work well independently as part of the scrum team

It‚Äôs Great If You Have

Experience on data warehouse design
Experience with ‚ÄòBig Data‚Äô technologies / tools Ex. Tensorflow)
Experience with third-party libraries and APIs
Experience with automate operation tasks with Shell Script, Python
Knowledge in business analysis or data modeling
Hungry to learn new tools, languages and technologies

#sydney #kyiv #melbourne #london #tokyo #dhaka #edinburgh #amsterdam #munich #moscow #dublin #seoul #hcmc #telaviv #moscow #taipei #manila

Equal Opportunity Employer

At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person‚Äôs merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.

We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .

To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes."
3003499444|Senior Data Engineer|Ho Chi Minh City, Vietnam|Amanotes|Full-time ¬∑ Mid-Senior level|"About the job
ABOUT AMANOTES
We are Amanotes! A fast-growing startup in the music-tech industry. We seek to delight people with interactive music experiences. Since 2014, 30+ music games and mobile applications were published under our name with over 1 billion downloads worldwide and 95+ million monthly active users. In 2019, we were proudly listed as the #1 mobile apps publisher from Southeast Asia, the #1 music games publisher in the world, and one of the top 20 mobile apps publishers in the world across all categories.

If you love to work in a creative environment with music all around the corner, come join us!

Explore our products on Google Play and iOS App Store such as Magic Tiles 3, Dancing Ballz, and Tiles Hop.

OBJECTIVES
Every month we are proud to have millions of users around the world. When you join our company, you will contribute to our mission to give your best to all users. You will have the chance to work with top-class scientists, engineers, and domain experts and to drive the data science process of our technology end-to-end. We integrate the R&D workflow on state-of-the-art machine intelligence into product features and internal services aiming at understanding and personalizing the learning experiences of our users
The ideal candidate is an enthusiast of educational technologies with a background in software engineering and a skillset that blends cloud infrastructure, machine learning, and DevOps

WHAT YOU WILL DO
Design, build-up, implement, optimize and own the data/ETL pipeline with the rest of the Data Engineer team
Create and maintain the system pipeline and data documentation
Implement the system pipelines (Data Warehouse, Data Lake)
Engineer data platforms to automate/facilitate data related processes
Collaborate with business stakeholders, Data Analytics team, and AI/ML teams to build and implement deep learning models or algorithm focused data products (reusable assets) and solutions and deliver them right to the client
Work with external tech teams if any projects are needed Data Engineer team to join with

QUALIFICATIONS
3-4+ years of hands-on experience deploying production quality code
Experience with the following technologies: Python, Google Cloud Platform (included at least GCS, BigQuery), Airflow, DBT
Knowledge of JavaScript/ReactJS is a plus
Experience with Airflow or other pipeline orchestration software
Deep understanding of SQL and analytical Data Warehouses (BigQuery preferred)
Deep understanding, skills, and experience of deployment
Data Modelling for Data WarehousesData modeling skills - familiarity with major methodology i.e. Kimball, Inmon, Data Vault
Experience in working with Linux environment, Git
Experience and interest in Cloud platforms such as Google Platform, K8S, AWS, Azure or Databricks

WILL BE A PLUS
Experience in deployment data process CICD on Gitlab/Github/Bitbucket
Experience data-intensive projects in the AWS, GCP (AWS ecosystem, Hadoop ecosystem, K8S, GCS Data Lake)
Experience and knowledge in streaming ETL process are pluses (Kafka, Apache Spark, Pub/Sub, ‚Ä¶)
Experience with BI/data visualization tools
Business mindset

WHY YOU'LL LOVE WORKING HERE
Attractive compensation & benefits
13th-month salary bonus and yearly performance bonus
12 days annual leave, 10 days sick leave per year
Flexible working hours & working from home policy (12 days/year)
Great allowances (lunch, parking, birthday, happy hours....)
Salary review one time per year based on employee's performance and contribution
Personal learning budget, entertainment budget, team building budget
Premium health care insurance
Music school for: piano, guitar, vocal, cajon, dancing, etc
Sport club: running club, tennis club, soccer club...
Global focus: you‚Äôll work with people from 10+ countries on ideas that don‚Äôt have borders
Truly startup spirit: no bureaucracy, no hierarchy Everyone is a leader here, you have the freedom to pursue and achieve your goals
Other benefits as per stated in Vietnamese Labor Law"
3003494871|Senior Data Engineer|Ho Chi Minh City, Vietnam|Amanotes|Full-time ¬∑ Mid-Senior level|"About the job
ABOUT AMANOTES
We are Amanotes! A fast-growing startup in the music-tech industry. We seek to delight people with interactive music experiences. Since 2014, 30+ music games and mobile applications were published under our name with over 1 billion downloads worldwide and 95+ million monthly active users. In 2019, we were proudly listed as the #1 mobile apps publisher from Southeast Asia, the #1 music games publisher in the world, and one of the top 20 mobile apps publishers in the world across all categories.

If you love to work in a creative environment with music all around the corner, come join us!

Explore our products on Google Play and iOS App Store such as Magic Tiles 3, Dancing Ballz, and Tiles Hop.

OBJECTIVES
Every month we are proud to have millions of users around the world. When you join our company, you will contribute to our mission to give your best to all users. You will have the chance to work with top-class scientists, engineers, and domain experts and to drive the data science process of our technology end-to-end. We integrate the R&D workflow on state-of-the-art machine intelligence into product features and internal services aiming at understanding and personalizing the learning experiences of our users
The ideal candidate is an enthusiast of educational technologies with a background in software engineering and a skillset that blends cloud infrastructure, machine learning, and DevOps
WHAT YOU WILL DO
Design, build-up, implement, optimize and own the data/ETL pipeline with the rest of the Data Engineer team
Create and maintain the system pipeline and data documentation
Implement the system pipelines (Data Warehouse, Data Lake)
Engineer data platforms to automate/facilitate data related processes
Collaborate with business stakeholders, Data Analytics team, and AI/ML teams to build and implement deep learning models or algorithm focused data products (reusable assets) and solutions and deliver them right to the client
Work with external tech teams if any projects are needed Data Engineer team to join with
QUALIFICATIONS
3-4+ years of hands-on experience deploying production quality code
Experience with the following technologies: Python, Google Cloud Platform (included at least GCS, BigQuery), Airflow, DBT
Knowledge of JavaScript/ReactJS is a plus
Experience with Airflow or other pipeline orchestration software
Deep understanding of SQL and analytical Data Warehouses (BigQuery preferred)
Deep understanding, skills, and experience of deployment
Data Modelling for Data WarehousesData modeling skills - familiarity with major methodology i.e. Kimball, Inmon, Data Vault
Experience in working with Linux environment, Git
Experience and interest in Cloud platforms such as Google Platform, K8S, AWS, Azure or Databricks

WILL BE A PLUS
Experience in deployment data process CICD on Gitlab/Github/Bitbucket
Experience data-intensive projects in the AWS, GCP (AWS ecosystem, Hadoop ecosystem, K8S, GCS Data Lake)
Experience and knowledge in streaming ETL process are pluses (Kafka, Apache Spark, Pub/Sub, ‚Ä¶)
Experience with BI/data visualization tools
Business mindset

WHY YOU'LL LOVE WORKING HERE
Attractive compensation & benefits
13th-month salary bonus and yearly performance bonus
12 days annual leave, 10 days sick leave per year
Flexible working hours & working from home policy (12 days/year)
Great allowances (lunch, parking, birthday, happy hours....)
Salary review one time per year based on employee's performance and contribution
Personal learning budget, entertainment budget, team building budget
Premium health care insurance
Music school for: piano, guitar, vocal, cajon, dancing, etc
Sport club: running club, tennis club, soccer club...
Global focus: you‚Äôll work with people from 10+ countries on ideas that don‚Äôt have borders
Truly startup spirit: no bureaucracy, no hierarchy Everyone is a leader here, you have the freedom to pursue and achieve your goals
Other benefits as per stated in Vietnamese Labor Law"
3010384727|Data Engineer (All Level)|Hanoi, Hanoi, Vietnam|Edso Labs - Enterprise Digitalization Solution Labs|Full-time|"About the job
Responsibility:
‚Ä¢ Create and maintain optimal data pipeline architecture
‚Ä¢ Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability, etc.
‚Ä¢ Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS/GCP/Azure ‚Äòbig data‚Äô technologies. ‚Ä¢ Work with clients including the Executive, Product, Data, and Business teams to assist with datarelated technical issues and support their data infrastructure needs.
‚Ä¢ Work with data and analytics experts to strive for greater functionality in our data systems.

Qualification:
‚Ä¢ Experience in designing ETL pipeline
‚Ä¢ Business English
‚Ä¢ Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
‚Ä¢ Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
‚Ä¢ Understand various data structures and common methods in data transformation
‚Ä¢ Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
‚Ä¢ A successful history of manipulating, processing, and extracting value from large disconnected datasets.

Benefit and perk:
‚Ä¢ Salary: Max 40Mil to Mem, min 40Mil to Lead
‚Ä¢ Working time: 8:30-18:00 (off 1.5h from 12h to 13h30 for lunch) from Monday to Friday
‚Ä¢ Flat and hierarchy structure
‚Ä¢ Self-management is appreciated
‚Ä¢ Friendly, innovative, and supportive environment
‚Ä¢ Interesting projects
‚Ä¢ 13th month salary, annual heath-check, insurance under Vietnamese Labor Law, monthly teambuilding
‚Ä¢ B.I.C insurance package
‚Ä¢ Psychological safety; Your ideas are always welcomed
Contact the job poster
Rosie Vu 2nd
Human Resources Specialist at Edso Labs - Enterprise Digitalization Solution Labs
Job Poster Location
Hanoi Capital Region
Send InMail"
2949802590|Data Engineer|Ho Chi Minh City, Vietnam|Senspark|Full-time|"About the job
M√¥ t·∫£ c√¥ng vi·ªác:
X√¢y d·ª±ng c∆° s·ªü h·∫°n t·∫ßng c·∫ßn thi·∫øt ƒë·ªÉ tr√≠ch xu·∫•t, chuy·ªÉn ƒë·ªïi v√† t·∫£i d·ªØ li·ªáu t·ªëi ∆∞u t·ª´ nhi·ªÅu ngu·ªìn d·ªØ li·ªáu kh√°c nhau.
Ph√°t tri·ªÉn h·ªá th·ªëng c∆° s·ªü d·ªØ li·ªáu ph·ª•c v·ª• cho c√°c ho·∫°t ƒë·ªông Game Marketing v√† Game Product c·ªßa c√¥ng ty.
Ph·ªëi h·ª£p v·ªõi b·ªô ph·∫≠n Data Analyst, Marketing, Game Designer ƒë·ªÉ x√¢y d·ª±ng c√°c c√¥ng c·ª• h·ªó tr·ª£ c√¥ng vi·ªác b√°o c√°o.
T·ªëi ∆∞u v√† ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c, s·ª± ·ªïn ƒë·ªãnh v√† b·∫£o m·∫≠t c·ªßa d·ªØ li·ªáu.
Lu√¥n c·∫≠p nh·∫≠t t√¨nh h√¨nh c√°c th∆∞ vi·ªán h·ªó tr·ª£ l·∫•y d·ªØ li·ªáu (Firebase, Google Analytics, 3rd Party Ads API‚Ä¶).
C√°c c√¥ng vi·ªác kh√°c theo y√™u c·∫ßu c·ªßa c·∫•p tr√™n.
Y√™u c·∫ßu c√¥ng vi·ªác:
√çt nh·∫•t 3 nƒÉm kinh nghi·ªám v·ªÅ Data Engineer (∆∞u ti√™n c√≥ kinh nghi·ªám v·ªÅ m·∫£ng Game Mobile v√† Blockchain).
T·ªët nghi·ªáp ƒë·∫°i h·ªçc chuy√™n ng√†nh v·ªÅ Khoa h·ªçc m√°y t√≠nh, Th·ªëng k√™, Tin h·ªçc, H·ªá th·ªëng th√¥ng tin‚Ä¶ (∆∞u ti√™n t·ªët nghi·ªáp c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc Qu·ªëc gia).
S·ª≠ d·ª•ng th√†nh th·∫°o ng√¥n ng·ªØ l·∫≠p tr√¨nh Javascript, SQL, app scripts.
S·ª≠ d·ª•ng th√†nh th·∫°o c√°c c√¥ng c·ª• thu·ªôc h·ªá sinh th√°i Google nh∆∞: Google BigQuery, Google Sheets, Google App Scripts, Google Data Studio‚Ä¶
Kinh nghi·ªám x√¢y d·ª±ng v√† t·ªëi ∆∞u h√≥a c√°c ki·∫øn tr√∫c v√† t·∫≠p d·ªØ li·ªáu l·ªõn.
Kinh nghi·ªám x√¢y d·ª±ng c√°c quy tr√¨nh h·ªó tr·ª£ v√† chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu, c·∫•u tr√∫c d·ªØ li·ªáu, si√™u d·ªØ li·ªáu.
Kinh nghi·ªám v·ªÅ th·ª±c hi·ªán ph√¢n t√≠ch nguy√™n nh√¢n g·ªëc r·ªÖ tr√™n d·ªØ li·ªáu ƒë·ªÉ x√¢y d·ª±ng h·ªá th·ªëng ho√†n ch·ªânh.
Kinh nghi·ªám s·ª≠ d·ª•ng c√°c d·ªãch v·ª• ƒë√°m m√¢y Google Cloud, AWS, EC2 ..
X·ª≠ l√Ω c√¥ng vi·ªác ƒë·ªôc l·∫≠p v√† kh·∫£ nƒÉng l√†m vi·ªác nh√≥m t·ªët.
K·ªπ nƒÉng t∆∞ duy ph·∫£n bi·ªán, thuy·∫øt tr√¨nh t·ªët.
- ƒê·ªçc, hi·ªÉu t√†i li·ªáu ti·∫øng anh t·ªët.
Quy·ªÅn l·ª£i ƒë∆∞·ª£c h∆∞·ªüng:
L∆∞∆°ng: Upto 2000$.
K√®m bonus si√™u to: Th∆∞·ªüng KPI, qu√Ω, l·ªÖ,th√¢m ni√™n, d·ª± √°n, ƒë·∫∑t bi·ªát th∆∞·ªüng Bcoin si√™u hot.
Th∆∞·ªüng cu·ªëi nƒÉm theo HƒêKD (nƒÉm 2021: Th∆∞·ªüng l√™n ƒë·∫øn 08 th√°ng l∆∞∆°ng).
H·ªó tr·ª£ c∆°m tr∆∞a: 50.000 ƒë/ng√†y.
B·∫£o hi·ªÉm x√£ h·ªôi ƒë∆∞·ª£c c√¥ng ty ƒë√≥ng 100%.
15 ng√†y ph√©p nƒÉm, ƒë∆∞·ª£c ho√†n ti·ªÅn ph√©p d∆∞.
Mi·ªÖn ph√≠ g·ª≠i xe t·∫°i t√≤a nh√†.
C√°c b·ªØa ti·ªác h√†ng th√°ng, team building, du l·ªãch h√†ng nƒÉm, c√πng nhi·ªÅu s·ª± ki·ªán th√∫ v·ªã kh√°c ƒë·ªÉ g·∫Øn k·∫øt nh√¢n vi√™n.
Nhi·ªÅu khu gi·∫£i tr√≠ d√†nh cho b·∫°n x·∫£ stress: M√°y ch∆°i game Ps4, Bi L·∫Øc‚Ä¶ ho·∫∑c th·∫£ h·ªìn trong nh·ªØng khu v∆∞·ªùn th∆° m·ªông t·∫°i Farm Club Senspark.
S·∫µn s√†ng t·∫°o ƒëi·ªÅu ki·ªán, khai th√°c ti·ªÅm nƒÉng ƒë·ªÉ n√¢ng cao gi√° tr·ªã c·ªßa m·ªói nh√¢n vi√™n.
Contact the job poster
Linh Pham 2nd
HR at senspark
Job Poster Location
Ho Chi Minh City, Vietnam
Send InMail"
2987711564|Data Engineer|Ho Chi Minh City, Vietnam|REVER|Full-time|"About the job
Y√™u c·∫ßu:
1. C√≥ kinh nghi·ªám, am hi·ªÉu v·ªÅ Big Data, Data-Warehouse, BI, Analytics, Data Mining, Hadoop Ecosystems/tools.
2. C√≥ kh·∫£ nƒÉng l·∫≠p tr√¨nh chuy√™n s√¢u Java, Scala, Python.
∆Øu ti√™n:
o ·ª®ng vi√™n ƒë√£ th·ª±c h√†nh, c√≥ tr·∫£i nghi·ªám v·∫≠n h√†nh khai th√°c c√°c th√†nh ph·∫ßn trong Hadoop Ecosystem.
o C√≥ kinh nghi·ªám trong thi·∫øt k·∫ø, tri·ªÉn khai, t·ªëi ∆∞u nh·∫±m ƒë·∫£m b·∫£o t√≠nh s·∫µn s√†ng (HA) c·ªßa h·ªá th·ªëng/d·ªãch v·ª• v√† tƒÉng tr∆∞·ªüng (Scaling) h·ªá th·ªëng/d·ªØ li·ªáu .
o C√≥ ki·∫øn th·ª©c, k·ªπ nƒÉng c∆° b·∫£n v·ªÅ Th·ªëng k√™, ƒê·∫°i s·ªë tuy·∫øn t√≠nh v√† c√°c ph∆∞∆°ng ph√°p k·ªπ thu·∫≠t trong H·ªçc th·ªëng k√™ (Statistical Learning);
o C√≥ ki·∫øn th·ª©c, k·ªπ nƒÉng c∆° b·∫£n v·ªÅ Ph√¢n t√≠ch Kh√°m ph√° D·ªØ li·ªáu (Exploratory Data Analysis) v√† H·ªçc m√°y (Machine Learning, Deep Learning).
o C√≥ kh·∫£ nƒÉng l·∫≠p tr√¨nh v·ªÅ Java, Scala, R, Python (Pandas, Numpy, Scikit-learn).
o ·ª®ng vi√™n th√†nh th·∫°o c√¥ng c·ª• R, Python (Pandas, Numpy, Scikit-learn), chuy√™n s√¢u Scala/Java (Spark ML, Spark Streaming, H2O).
o ·ª®ng vi√™n s·ª≠ d·ª•ng/th·ª±c h√†nh c√°c ML Frameworks/tools (tensorflow, torch, pytorch, keras, ‚Ä¶)

Nhi·ªám v·ª•:
1. X√¢y d·ª±ng h·ªá th·ªëng thu th·∫≠p s·ªë li·ªáu, t·ªï ch·ª©c nh√† kho d·ªØ li·ªáu, x·ª≠ l√Ω streaming data.
2. Tham gia ph√°t tri·ªÉn, tri·ªÉn khai, v·∫≠n h√†nh c√°c d·ªãch v·ª•/gi·∫£i ph√°p tr√™n n·ªÅn t·∫£ng d·ªØ li·ªáu l·ªõn.
3. Tham t√≠ch h·ª£p, tri·ªÉn khai, v·∫≠n h√†nh, h·ªó tr·ª£ c√°c d·ªãch v·ª• khai th√°c s·ªë li·ªáu.
4. Thi·∫øt k√™ x√¢y d·ª±ng h·ªá th·ªëng ph√¢n t√≠ch s·ªë li·ªáu th√¥ng minh (Analytics, BI)
5. Nghi√™n c·ª©u, x√¢y d·ª±ng c√°c gi·∫£i ph√°p, c√°c m√¥ h√¨nh th·ª±c thi (d·ª± ƒëo√°n, ph√¢n l·ªõp, ph√¢n c·ª•m, v.v.) tr√™n n·ªÅn t·∫£ng BigData v√† Machine learning.
Contact the job poster
Qu·ª≥nh Nh∆∞ HR 2nd
Hirring E - Commerce and Communication
Job Poster Location
Ho Chi Minh City, Vietnam
Send InMail"
3007234883|Data Engineer|Ho Chi Minh City, Vietnam|EcoTruck - Ecosystem for Trucking|Full-time|"About the job
EcoTruck - a tech-driven logistics company focusing on first mile trucking. We are proud to be the leading ecosystem for trucking in Vietnam.
We are looking for people who is talented and hardworking to join our force to bring the efficiency to the industry through innovative business model and unique way of operating
What you will do in this role
Analyze requirements, design and develop a secure and standard data storage system.
Build data pipelines to convert and synthesize data from the company's existing system that can serve the queries and analysis quickly and easily.
Build a system to collect info from different sources that provide data for business analysis and development.
Collaborate with other software engineers, product owners, designers to build the product.
What we are looking for
Previous experience as a data engineer or in a similar role
Understanding Extract, Transform, and Load (ETL)
Familiar working with Restful API.
Familiar with Linux development environments.
Experience with SQL, NoSQL
Experience with queueing and messaging systems.
Knowledge about process developing feature
Nice-to-have
Experience with Elasticsearch.
Experience with Docker.
Benefit
Performance bonus
ESOP based on performance and contribution
Social insurance and health insurance (on 100% of gross salary)
Additional premium health care
Paid annual health checkup
Performance and salary review at least once a year
Monthly team building budget, which does NOT roll over
Birthday gift
Company trips and other team building activities (encouraged to do marathon or triathlon)
Office goodies including daily healthy snacks, good coffee and tea, healthy beverages, and a great office atmosphere
Contact the job poster
Tu Le 2nd
Senior Recruiter (Tech & Non-Tech)
Job Poster Location
Vietnam
Send InMail"
2990200707|Data Engineer ( Remote Full Time )|Vietnam|Nityo Infotech|Full-time|"About the job
*Job Description ( from 3+ YOE )
‚óè Implement, monitor, and maintain data pipelines for market, transaction, reference, and other
data.
‚óè Perform all needed data cleansing and transformation to improve data quality.
‚óè Work closely with traders and researchers to consume and analyze data faster and more
efficiently.
‚óè Deploy new data models that provide insightful and actionable analytics across the firm.
‚óè Manage the entire data processing system and advising of any necessary infrastructure changes.

*Requirement

Attributes
‚óè Thinks clearly, learns quickly, solves problems, and can work with no supervision.
‚óè Asks good questions. Communicates effectively.
‚óè Development experience in more than one programming language, preferably different (e.g.
strongly versus dynamically typed, functional versus object-oriented).
‚óè Familiarity with software development practices. Works well in a team.
‚óè Experience with databases and SQL.
‚óè Experience with stream processing.
Good to have
‚óè Knowledge of electronic trading and tick data
‚óè Knowledge of data modelling and database design.
‚óè Experience of data processing/ETL implementation.
‚óè Experience with distributed systems.
‚óè Experience with messaging middleware such as Solace or Kafka.
‚óè Experience with (NoSQL) databases such as Hadoop, Cassandra.

Must have:
‚óè Experience of data processing/ETL implementation.
‚óè Experience with messaging middleware such as Solace or Kafka.
‚óè Experience with (NoSQL) databases such as Hadoop, Cassandra.

*Benefit
Salary: Upto 3000$ Gross
What We Offer
As a growing firm with a tightly-knit team, we respect and listen to all our employees. You will get the
chance to make an impact by having your voice heard by everyone, including the management. Our
employees enjoy a high level of autonomy at work. We focus on substance, not form - as long as you
can perform, you will be recognized and rewarded.
‚óè 13th month salary & performance review
‚óè Governmental insurances based on labour law (after probation)
‚óè 100% of salary in the probation time (Included Personal income tax)
‚óè 15 days of annual leave apart from national holidays by law
‚óè Childcare leave:
o 2 days of childcare leave a year (With Grasshopper for at least 3 continuous months)
o 6 days of paid childcare leave per year, regardless of the number of children you have
(With Grasshopper for at least 1 year).
o Only be applicable for employees with children below 7 years old.
‚óè Marriage Leave
‚óè Maternity/Paternity leave: based on Labour law
‚óè Off in lieu:
o For working 4 hours or less on a weekend/non-trading day, you will be granted time
off in lieu of 4 hours on a working day.
o For working more than 4 hours on a weekend/non-trading day, you will be granted a
full day off on a working day.
‚óè Innovation leave: staff allowed to take up to 20% of their work time to work on innovation or
training. Innovation idea has to be posted on Innovation Board on Jira before taking of leave.
‚óè Out-patient and hospitalisation health insurance package (applicable also to spouse and/or
children where required)
‚óè Annual dental care package
‚óè Working equipment provided (laptop, extra monitor, etc)
‚óè Motorcycle parking fee allowance
‚óè Casual dress code
‚óè Flexible work time arrangement where applicable
‚óè Team building activities, happy-hour, etc.
‚óè An employee will be granted a Referral Bonus of VND 10,000,000 for every referral who is
hired and completes 12 months of employment.
‚óè Opportunity to work with talented colleagues to improve your knowledge. Professional &
English speaking working environment and more...
Contact the job poster
Ph·∫°m Th·ªã Thu Ph∆∞∆°ng 2nd
IT recruiter: Python, Full stack, Android, iOS,....
Job Poster Location
Vietnam
Send InMail"
3003435721|Data Engineer|Hanoi, Hanoi, Vietnam|Techcombank (TCB)|Full-time ¬∑ Mid-Senior level|"About the job
Objective
- The job holder is responsible for developing programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from disparate sources and implement complex business logic as needed with the available data processing tools.
- The job holder will be responsible for helping build a reliable, sustainable and scalable data processing platform, working with other tribe members to support data pipelines, convert models to machine learning codes and recommend Big Data reporting and visualization applications.
Key accountabilities
A. Data Architecture
Deliver functionality required for business and data analysts, data scientists and other business roles to advance the overall analytic performance and strategy of the bank
Assist in building best practices and strategies for data infrastructure to fulfill data analytic and utilization needs of the business with emerging latest technologies and capabilities.
- Collaborate with relevant teams on opportunities to manage data and provide solutions for complex data feeds within the bank.
- Maintain data integration processes into the data platform by building data pipelines and align with business representatives and business information needs.
- Review internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.
B. Data Integration
- Obtain and integrate data and information from various sources into the firm‚Äôs platforms, solutions and statistical models.
- Collaborate with Data Scientists to understand data requirements and create re-usable data assets to enable data scientists to build and deploy machine learning models faster.
- Write scripts and ingest raw data to build and maintain optimized data pipelines and ETL solutions as business support tools in providing analysis.
- Ensure data assets are organized and stored in an efficient way so that information is easy to access and retrieve.
Job Requirements
- Bachelor‚Äôs or Master‚Äôs degree in Statistics, Mathematics, Quantitative Analysis, Computer Science, Software Engineering or Information Technology
- 3+ years of relevant experience with developing, debugging, scripting and employing big data technologies (e.g. Hadoop, Spark, Flink, Kafka, Arrow, Tableau), database technologies (e.g. SQL, NoSQL, Graph databases), and programming languages (e.g. Python, R, Scala, Java, Rust, Kotlin) with preference towards functional/trait oriented
- Experience in designing and building dimensional data models, ETL processes, applied data warehouse concepts and methodologies, optimized data pipelines and assisted the architect as needed
- Experience monitoring complex system and solving data and systems issues having a consistent and algorithmic approach to resolving them
- Deep understanding of Information Security principles to ensure compliant handling and management of all data
- Experience working in Agile teams to support digital transformation projects, having a clear understanding of Agile principles, practices and Scrum methodologies
- Has some know-how and partial scripting and coding experience to set up, configure & maintain a machine learning model development environment
- Some experience architecting, coding and delivering high performance micro services and/or recommenders delivering recommendations to a large user-base
Contact the job poster
Di·ªáu Anh L√™ 2nd
Talent Acquisition (IT) at Techcombank
Job Poster Location
Hanoi Capital Region
Send InMail"
3008407724|Data Engineer|Ho Chi Minh City, Vietnam|CT Group Vietnam|Full-time ¬∑ Executive|"About the job
M√î T·∫¢ C√îNG VI·ªÜC
C√°c nhi·ªám v·ª• c√≥ t√≠nh chi·∫øn l∆∞·ª£c
- ƒê·ªÅ xu·∫•t, gi√∫p vi·ªác cho Gi√°m ƒë·ªëc/Ph√≥ Gi√°m ƒë·ªëc Ban CNTT, Tr∆∞·ªüng Ph√≤ng v√† ch·ªãu tr√°ch nhi·ªám trong c√°c nhi·ªám v·ª• ƒë∆∞·ª£c ph√¢n c√¥ng th·ª±c hi·ªán.
- ƒê·ªÅ xu·∫•t c√°c gi·∫£i ph√°p li√™n quan ƒë·∫øn n·ªÅn t·∫£ng d·ªØ li·ªáu nh·∫±m ƒë·∫°t ƒë∆∞·ª£c c√°c m·ª•c ti√™u qu·∫£n l√Ω.
ƒê·ªÅ xu·∫•t k·∫ø ho·∫°ch tri·ªÉn khai c√°c n·ªÅn t·∫£ng d·ªØ li·ªáu theo ƒë·ªãnh h∆∞·ªõng chung c·ªßa T·∫≠p ƒëo√†n.
C√¥ng t√°c chuy√™n m√¥n
- Ph√¢n t√≠ch, t·ªï ch·ª©c d·ªØ li·ªáu th√¥, ƒë·ªÅ xu·∫•t c√°c d·ªãch v·ª• d·ªØ li·ªáu th√≠ch h∆°p
- ƒê·ªÅ xu·∫•t, review, thi·∫øt k·∫ø ki·∫øn tr√∫c h·ªì d·ªØ li·ªáu (Data Lake)
- Th·ª±c hi·ªán c√°c t√°c v·ª• Extract, Transform, Load (ETL) v√† c√°c ho·∫°t ƒë·ªông t√≠ch h·ª£p d·ªØ li·ªáu.
- X√¢y d·ª±ng h·ªá th·ªëng d·ªØ li·ªáu, ph√°t tri·ªÉn c√°c ho·∫°t ƒë·ªông d·ªØ li·ªáu bao g·ªìm: pipelines, processing, storages, consuming ph√π h·ª£p v·ªõi c√°c m√¥ h√¨nh d·ªØ li·ªáu v√† y√™u c·∫ßu nghi·ªáp v·ª•
- Hi·ªán th·ª±c c√°c data adapter t·ª´ c√°c ngu·ªìn d·ªØ li·ªáu kh√°c nhau
C√¥ng vi√™Ã£c taÃÅc nghi√™Ã£p
- Tham gia c√°c cu·ªôc th·∫£o lu·∫≠n nh√≥m, kh√¥ng ng·ª´ng c·∫£i ti·∫øn quy tr√¨nh l√†m vi·ªác, th·ª±c hi·ªán s√°ng ki·∫øn m·ªõi ph√π h·ª£p.
- Kh·∫£o s√°t trao ƒë·ªïi l·∫•y y√™u c·∫ßu vi·∫øt c√°c t√†i li·ªáu y√™u c·∫ßu nghi·ªáp v·ª• theo ng√¥n ng·ªØ CNTT.
- L√† c·∫ßu n·ªëi gi·ªØa c√°c Ph√≤ng/Ban/ƒê∆°n v·ªã v√† nh√≥m l·∫≠p tr√¨nh trong qu√° tr√¨nh x√¢y d·ª±ng ph·∫ßn m·ªÅm.
- X√¢y d·ª±ng c√°c k·∫ø ho·∫°ch tri·ªÉn khai
- Duy tr√¨, tri·ªÅn khai, ƒë·∫£m b·∫£o h·ªá th·ªëng d·ªØ li·ªáu ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh, li√™n t·ª•c.
H·ªó tr·ª£ c√°c Ph√≤ng/Ban/ƒê∆°n v·ªã li√™n quan trong vi·ªác v·∫≠n h√†nh h·ªá th·ªëng qu·∫£n l√Ω d·ªØ li·ªáu c·ªßa b·ªô ph·∫≠n, vi·∫øt t√†i li·ªáu h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng, c√°c l·ªói th∆∞·ªùng g·∫∑p v√† h∆∞·ªõng x·ª≠ l√Ω nhanh.
V∆°ÃÅi ƒë√¢ÃÄu m√¥ÃÅi nghi√™Ã£p vuÃ£ IT taÃ£i caÃÅc ƒê∆°n viÃ£ thaÃÄnh vi√™n
- H∆∞∆°ÃÅng d√¢ÃÉn, ki√™Ãâm tra, ƒë√¥n ƒë√¥ÃÅc caÃÅc ƒë√¢ÃÄu m√¥ÃÅi nghi√™Ã£p vuÃ£ cuÃâa T·∫≠p ƒëo√†n th∆∞Ã£c hi√™Ã£n ƒëuÃÅng caÃÅc quy ƒëiÃ£nh v√™ÃÄ b·∫£o m·∫≠t th√¥ng tin d·ªØ li·ªáu.
- T∆∞ v·∫•n, h·ªó tr·ª£ k·ªãp th·ªùi v√† qu·∫£n l√Ω, ki·ªÉm so√°t vi·ªác th·ª±c hi·ªán t·∫°i c√°c ƒê∆°n v·ªã th√†nh vi√™n.

Y√äU C·∫¶U
1. ƒê·ªô tu·ªïi: 25 tu·ªïi tr·ªü l√™n.
2. Tr√¨nh ƒë·ªô: T·ªët nghi·ªáp ƒê·∫°i h·ªçc.
3. Chuy√™n ng√†nh: CNTT ho·∫∑c c√°c chuy√™n ng√†nh li√™n quan.
4. Kinh nghi·ªám: C√≥ √≠t nh·∫•t 03 nƒÉm kinh nghi·ªám ·ªü v·ªã tr√≠ t∆∞∆°ng ƒë∆∞∆°ng.
5. Ngo·∫°i ng·ªØ: KhaÃâ nƒÉng giao ti√™ÃÅp vaÃÄ ƒëoÃ£c hi√™Ãâu taÃÄi li√™Ã£u ti√™ÃÅng Anh chuy√™n ngaÃÄnh.
6. Tin h·ªçc: ThaÃÄnh thaÃ£o tin h·ªçc l·∫≠p tr√¨nh, k·ªπ thu·∫≠t, c√≥ kh·∫£ nƒÉng ph√°t tri·ªÉn c√°c ph·∫ßn m·ªÅm ·ª©ng d·ª•ng nh·ªè.
7. K·ªπ nƒÉng:
- C√≥ kinh nghi·ªám v·ªõi Python ho·∫∑c c√°c ng√¥n ng·ªØ l·∫≠p tr√¨nh t∆∞∆°ng t·ª±
- C√≥ kinh nghi·ªám v·ªõi c√°c d·ªãch v·ª• data (ingestion, storages, etc) tr√™n h·∫° t·∫ßng Cloud Azure
- C√≥ kinh nghi·ªám v·ªõi c√°c ng√¥n ng·ªØ truy v·∫•n d·ªØ li·ªáu (SQL)
- C√≥ kinh nghi·ªám s·ª≠ d·ª•ng c√°c ETL Tools
- K·ªπ nƒÉng t·ªï ch·ª©c ƒëi·ªÅu h√†nh c√¥ng vi·ªác.
- K·ªπ nƒÉng giao ti·∫øp, ph·ªëi h·ª£p v·ªõi c√°c ƒë·ªìng nghi·ªáp trong nh√≥m th·ª±c hi·ªán t·ªët c√¥ng vi·ªác.
- K·ªπ nƒÉng vi·∫øt t√†i li·ªáu quy tr√¨nh t·ªët.
8. Ki·∫øn th·ª©c li√™n quan:
- C√≥ ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ c√°c lƒ©nh v·ª±c li√™n quan ƒë·∫øn c√°c ch∆∞∆°ng tr√¨nh tri·ªÉn khai.
- Bi·∫øt c√°ch th·ª±c hi·ªán c√°c c√¥ng vi·ªác theo quy tr√¨nh m·ªôt c√°ch khoa h·ªçc.
9. C√°c t·ªë ch·∫•t c·∫ßn thi·∫øt kh√°c:
- Nhi·ªát t√¨nh, c√≥ tinh th·∫ßn c·∫ßu ti·∫øn.
- ƒê√°ng tin c·∫≠y, ch√¢n th√†nh, th·∫≥ng th·∫Øn, trung th·ª±c.
- CoÃÅ tinh th√¢ÃÄn traÃÅch nhi√™Ã£m cao, t√¢m huy√™ÃÅt, t√¢Ã£n tuÃ£y gƒÉÃÅn boÃÅ v∆°ÃÅi c√¥ng vi√™Ã£c.
- CoÃÅ khaÃâ nƒÉng laÃÄm vi√™Ã£c nhoÃÅm.
- Kh·∫£ nƒÉng th√≠ch ·ª©ng v√† linh ho·∫°t v·ªõi c√¥ng vi·ªác √°p l·ª±c cao.

CH√çNH S√ÅCH PH√öC L·ª¢I
- Th∆∞·ªüng nh√¢n c√°c ng√†y L·ªÖ/T·∫øt theo quy ƒë·ªãnh c·ªßa Nh√† n∆∞·ªõc.
- Th∆∞·ªüng th√†nh t√≠ch ƒë·ªãnh k·ª≥ v√† ƒë·ªôt xu·∫•t cho c√° nh√¢n ho·∫∑c t·∫≠p th·ªÉ.
- Th∆∞·ªüng s√°ng ki·∫øn c·∫£i ti·∫øn k·ªπ thu·∫≠t, n√¢ng cao hi·ªáu qu·∫£ ho·∫°t ƒë·ªông kinh doanh.
- Th∆∞·ªüng l∆∞∆°ng th√°ng 13.
- Th∆∞·ªüng th√†nh t√≠ch theo KPIs (t·ª´ 01 - 05 th√°ng l∆∞∆°ng v√† phi·∫øu an sinh 100.000.000 ƒë·ªìng).
- Th∆∞·ªüng th√¢m ni√™n: 01 l∆∞·ª£ng v√†ng SJC (Th∆∞·ªüng tr√™n m·ªói l·∫ßn ƒë·ªß 5 nƒÉm th√¢m ni√™n, c√°c m·ªëc 5, 10, 15, 20,‚Ä¶).
- Ch√≠nh s√°ch ∆∞u ƒë√£i mua cƒÉn h·ªô v·ªõi chi·∫øt kh·∫•u v√† qu√† t·∫∑ng ƒë·∫∑c bi·ªát cho CBNV.
- T·∫∑ng qu√† nh√¢n c√°c s·ª± ki·ªán ƒë·∫∑c bi·ªát c·ªßa CBNV: Sinh nh·∫≠t, qu√† cho CBNV n·ªØ nh√¢n ng√†y 8/3, 20/10;
- H·ªó tr·ª£ cho vay c√° nh√¢n ƒë·ªëi v·ªõi CBNV.
- C√°c kho·∫£n tr·ª£ c·∫•p: K·∫øt h√¥n, tang ch·∫ø, ·ªëm ƒëau, thai s·∫£n, c∆°m tr∆∞a, g·ª≠i xe, li√™n l·∫°c, xƒÉng, c√¥ng t√°c, giao t·∫ø, ƒë·ªìng ph·ª•c.
- T·ªï ch·ª©c xe ƒë∆∞a CBNV v·ªÅ qu√™ ƒÉn T·∫øt.
- Ch∆∞∆°ng tr√¨nh Caravan xuy√™n Vi·ªát h√†ng nƒÉm.
- ƒê∆∞·ª£c h∆∞·ªüng ch·∫ø ƒë·ªô ngh·ªâ d∆∞·ª°ng 1 l·∫ßn/nƒÉm (L√©man Cap V≈©ng T√†u).
- Nhi·ªÅu ho·∫°t ƒë·ªông vƒÉn h√≥a, vƒÉn ngh·ªá, th·ªÉ thao, x√£ h·ªôi d√†nh cho CBNV.
- C√°c ch∆∞∆°ng tr√¨nh chƒÉm lo cho con em CBNV: Ng√†y h·ªôi gia ƒë√¨nh (Family Day), h·ªó tr·ª£ ƒë√†o t·∫°o, khen th∆∞·ªüng con CBNV c√≥ th√†nh t√≠ch h·ªçc t·∫≠p t·ªët.
Contact the job poster
Ng·ªçc Tr∆∞∆°ng 2nd
Recruitment Executive
Job Poster Location
Vietnam
Send InMail"
2998341571|Data Engineer|Ho Chi Minh City, Vietnam|ManpowerGroup Vietnam|Full-time|"About the job
We are looking for an experienced Data Engineer to join the team.
You will use various methods to transform raw data into useful data systems. You‚Äôll also create algorithms and conduct statistical analysis. Overall, you‚Äôll strive for efficiency by aligning data systems with business goals.

To succeed in this role, you should have strong analytical skills and the ability to combine data from different sources. Highly skilled in several programming languages and learning machine methods.

If you are detail-oriented, with excellent organizational skills and experience in this field, we‚Äôd like to hear from you.

Key Skills and Qualifications
‚Ä¢ Bachelor or higher degree in Computer Science, Statistics, Informatics, Information Systems or equivalent
‚Ä¢ 3+ years of experience in a similar role. Experienced in building & optimizing Big Data pipelines, architectures, and data sets.
‚Ä¢ Technical expertise with data modelling, data mining, and segmentation techniques.
‚Ä¢ Experienced in ETL tools or data pipeline languages such as Python, Java, C#, C++, Scala, Cloud-based infrastructure (eg: AWS, GCP, Azure‚Ä¶); Workflow management tools such as Azkaban, Luigi, Airflow, etc.
‚Ä¢ Experienced in both relational databases, SQL and NoSQL databases (eg: MongoDB).
‚Ä¢ Fluent in English

APPLY TODAY hcmc.perm.trhf@manpower.com.vn for a chat.
Contact the job poster
Le Quoc Khuong (Kay)üí°üáªüá≥ Executive Search‚îÇ K Talent Hunt VN 2nd
üîéCluster MD|Startup CEO|VN GM|Deputy MD|General Counsel|CPO|CMO|CFO IPO|Government Relations Director|Data Engineer|VP SoftwareEngineering|InvestmentDirector|HeadofResearch Securities|PE VC Investment
Job Poster Location
Ho Chi Minh City, Vietnam
Send InMail"
3004746132|Sr. Data Engineer|Hanoi, Hanoi, Vietnam|Fortna|Full-time ¬∑ Associate|"About the job
Overview

The Data Engineer is a key member of the Fortna Warehouse Execution System (WES) data team that design usable data models and build robust & dependable data pipelines where both batch & streaming process are leveraged to meet the latency requirements for the business.This position plays a vital role in building the Data Platform, Business Intelligence, and Data product capability of the FortnaWES software product.

Responsibilities

Evaluate business and technical domains to produce representative logical and physical data models.
Build data models with the flexibility to change when business requirements change.
Reconcile multiple logical source models into a single, logically consistent enterprise model.
Develop and automate large scale, high-performance data processing systems (batch and/or streaming) to drive business growth and improve the product experience
Develop data stores, including warehouses, data lakes, data marts, etc., to support the BI and operational research initiatives.
Build scalable data pipelines leveraging orchestration framework
Improve data quality by researching, using & improving tools to automatically detect issues
Define modeling standards, guidelines, best practices and approved modeling techniques.
Employ initiative, professionalism, and self-discipline in daily interactions.

Qualifications

REQUIRED QUALIFICATIONS:

Five-plus years of relevant industry experience
Bachelor‚Äôs and/or master‚Äôs degree, preferably in Computer Science, or equivalent education and experience
Proven capability for managing data migrations between software products and custom apps
Experience with pipeline tools such as Nifi, Airflow
Experience in deploying dbt/airflow workflow is a plus
Experienced with Extract-Transform-Load (ETL), Extract-Load-Transform (ELT), and Discover-Access-Distill (DAD) processes
Extensive expertise in multidimensional data modeling, start schemas, snowflakes, normalized and de-normalized modes, and Kimball methodologies
Strong negotiation and consensus building abilities
Exceptional ability to communicate in a written, spoken, or visual manner at all personnel levels

DESIRED QUALIFICATIONS:

Demonstrated real-world execution implementing data warehouses and data lakes
Familiarity working with open-source Linux-based technologies
Verifiable record of building an enterprise analytics capability from greenfield
Fluent in Vietnamese and English
Able to travel internationally on an occasional basis

What We Do

About Us

Headquartered in Atlanta with locations globally, Fortna is an award-winning, end-to-end design-build firm whose expertise spans over seven decades of service. Founded in 1946, we provide strategy, automation design & systems integration, and warehouse execution software to the world‚Äôs most recognized brands.

What Sets Us Apart

At Fortna, our three mission-critical pillars connect our people across the globe and help distinguish us as a leader in the marketplace.

Our PEOPLE are at the heart of everything we do. We are guided by a set of business principles and ethics that are baked into the excellence we bring to each project from start to finish.
Our PASSION unites our Associates through our shared passion and commitment to integrity, hard work, and a collaborative approach. We love what we do, and it shows.
We PROMISE to be accountable, act with integrity, and deliver results for our clients. Our diverse team of global Associates work as ‚ÄúOne Team‚Äù to deliver on our promises to Clients.

What You Can Expect

Perks and benefits: At Fortna, our people are everything ‚Äì so the perks and benefits you‚Äôll receive from being part of the Fortna team are generous. From competitive compensation packages and health insurance offerings to Associate-led committees created to drive positive change, the employee experience at Fortna is truly unmatched.

Talent Development: We believe every Associate deserves the resources and support to grow and thrive. That‚Äôs why a career at Fortna comes with powerful professional development opportunities. Learn directly from the industry‚Äôs best and brightest. Our training, mentoring and on-the-job experiences are designed to enhance your skillset ‚Äì preparing you for increasingly challenging roles and accelerating your career."
2959134157|Data Engineer (Game/app)|Hanoi Capital Region|iKame Global|Full-time|"About the job
ABOUT IKAME
iKame ƒë∆∞·ª£c th√†nh l·∫≠p v√†o nƒÉm 2014 v·ªõi nh·ªØng con ng∆∞·ªùi nh·ªè c√≥ ∆∞·ªõc m∆° l·ªõn. Qua 7 nƒÉm iKame hi·ªán ƒëang ƒë·ª©ng Top 20 Global Game Studio, nh√¢n s·ª± ph√°t tri·ªÉn l√™n 100 th√†nh vi√™n. Trong su·ªët qu√° tr√¨nh ƒë√≥, ch√∫ng t√¥i lu√¥n h∆∞·ªõng t·ªõi s·ª± nhi·ªát huy·∫øt, s√°ng t·∫°o, trao cho nhau nh·ªØng gi√° tr·ªã, c√πng nhau ph√°t tri·ªÉn, c√πng h∆∞·ªüng l·ª£i √≠ch, v√† ƒë·∫∑c bi·ªát lu√¥n ƒë·∫∑t ""Con ng∆∞·ªùi"" l√† tr·ªçng t√¢m c·ªßa C√¥ng ty.
Mong ∆∞·ªõc hi·ªán t·∫°i c·ªßa iKame l√† ƒë∆∞·ª£c t·∫°o ra nh·ªØng s·∫£n ph·∫©m ch·∫•t l∆∞·ª£ng, c√≥ nhi·ªÅu ng∆∞·ªùi d√πng, v√† tr·ªü th√†nh c√¥ng ty Game h√†ng ƒë·∫ßu tr√™n th·∫ø gi·ªõi.
N·∫øu b·∫°n mong mu·ªën l√†m vi·ªác trong m·ªôt m√¥i tr∆∞·ªùng c·ªüi m·ªü, kh√¥ng kho·∫£ng c√°ch, n∆°i b·∫°n ƒë∆∞·ª£c th·ª≠ th√°ch, ƒë∆∞·ª£c s√°ng t·∫°o v√† ƒë∆∞·ª£c trao c∆° h·ªôi, th√¨ h√£y gia nh·∫≠p iKame!
H·ªá th·ªëng BI - Data System bi·∫øn data th√†nh chi·∫øn l∆∞·ª£c ch√≠nh l√† m·ªôt trong nh·ªØng y·∫øu t·ªë quy·∫øt ƒë·ªãnh ƒë∆∞a iKame ph√°t tri·ªÉn m·∫°nh m·∫Ω trong nh·ªØng nƒÉm g·∫ßn ƒë√¢y. V·ªõi s·ª± ph√°t tri·ªÉn quy m√¥ l·ªõn m·∫°nh h∆°n n·ªØa, ch√∫ng m√¨nh ƒëang t√¨m ki·∫øm 1 b·∫°n Data Engineer v·ªõi m√¥ t·∫£ nh∆∞ sau:

M√î T·∫¢ C√îNG VI·ªÜC
Thi·∫øt k·∫ø lu·ªìng d·ªØ li·ªáu, v·∫≠n h√†nh v√† t·ªï ch·ª©c h·ªá th·ªëng tr√™n n√™n t·∫£ng d·ªØ li·ªáu
X√¢y d·ª±ng c√°c API quan tr·ªçng ƒë·ªÉ ph·ª•c v·ª• n·ªôi ƒë·ªÉ truy v·∫•n d·ªØ li·ªáu v√† ph√¢n t√≠ch
Thu th·∫≠p , x·ª≠ l√Ω v√† l∆∞u tr·ªØ d·ªØ li·ªáu t·ª´ c√°c ngu·ªìn d·ªØ li·ªáu kh√°c nhau ƒë·ªÉ ph·ª•c v·ª• ph√¢n t√≠ch , th·ªëng k√™ v√† Machine Learning
Y√äU C·∫¶U
√çt nh·∫•t 1 nƒÉm kinh nghi·ªám ·ªü v·ªã tr√≠ t∆∞∆°ng ƒë∆∞∆°ng
Ti·∫øng Anh : ƒê·ªçc hi·ªÉu t√†i li·ªáu
C√≥ ki·∫øn th·ª©c t·ªët v·ªÅ C·∫•u tr√∫c D·ªØ li·ªáu v√† Gi·∫£i thu·∫≠t
T·ªët nghi·ªáp ƒë·∫°i h·ªçc chuy√™n ng√†nh: C√¥ng ngh·ªá th√¥ng tin, C√¥ng ngh·ªá ph·∫ßn m·ªÅm, ƒêi·ªán t·ª≠ vi·ªÖn th√¥ng, To√°n Tin, ..
S·ª≠ d·ª•ng th√†nh th·∫°o Python
Hi·ªÉu bi·∫øt c∆° b·∫£n v·ªÅ Google Cloud, Data Flow, Bigquery
T∆∞ duy logic t·ªët, c√≥ kh·∫£ nƒÉng ph√¢n t√≠ch, h·ªçc h·ªèi nhanh
Th√†nh th·∫°o SQL

C√°c k·ªπ nƒÉng l·ª£i th·∫ø
Th√†nh th·∫°o Google Cloud Platform
S·ª≠ d·ª•ng th√†nh th·∫°o App Script, App Engineer
QUY·ªÄN L·ª¢I
M·ª©c l∆∞∆°ng l√™n t·ªõi $1500/th√°ng, review l∆∞∆°ng 2 l·∫ßn/nƒÉm
C∆° h·ªôi tham gia v√† x√¢y d·ª±ng d·ª± √°n game casual, blockchain (NFT) ch·∫•t l∆∞·ª£ng ‚Äì c∆° h·ªôi ph√°t tri·ªÉn v√† thƒÉng ti·∫øn r·ªông m·ªü
C∆° h·ªôi ƒë∆∞·ª£c h·ªçc h·ªèi, ƒë∆∞·ª£c th·ª≠ sai, ƒë∆∞·ª£c ƒë∆∞a √Ω ki·∫øn ƒë·ªÉ r√®n luy·ªán b·∫£n th√¢n v√† trau d·ªìi kinh nghi·ªám th·ª±c chi·∫øn v·ªõi vi·ªác h·ªó tr·ª£ 30-100% chi ph√≠ c√°c kh√≥a h·ªçc m·ªçi k·ªπ nƒÉng
M√¥i tr∆∞·ªùng th√¢n thi·ªán, tr·∫ª trung, hi·ªán ƒë·∫°i, vƒÉn ph√≤ng ƒë·∫πp x·ªãn x√≤ view c·ª≠a k√≠nh to√†n th√†nh ph·ªë
Con ng∆∞·ªùi l√† s·ªë 1 - b·∫°n s·∫Ω ƒë∆∞·ª£c quan t√¢m t·ª´ b·ªØa ƒÉn x·∫ø chi·ªÅu, t·ªõi ch·ªó ng·ªß, t·ª´ t·ªß ƒë·∫ßy ƒë·ªì ƒÉn v·∫∑t t·ªõi b√†n bia, bi-l·∫Øc, PS4 x·∫£ n√£o, th∆∞ vi·ªán cho nh·ªØng t√¢m h·ªìn y√™u th√≠ch ƒë·ªçc s√°ch
C√°c ch·∫ø ƒë·ªô ƒë√£i ng·ªô kh√°c nh∆∞ kh√°m s·ª©c kh·ªèe, teambuilding, du l·ªãch... ƒë·ªÅu ƒë∆∞·ª£c ƒë·∫£m b·∫£o
Th∆∞·ªüng LINH HO·∫†T & H·∫§P D·∫™N: Th∆∞·ªüng l·ªÖ t·∫øt, Th∆∞·ªüng n√≥ng, th∆∞·ªüng hi·ªáu qu·∫£ kinh doanh qu√Ω theo doanh thu s·∫£n ph·∫©m v√† theo m·ª©c ƒë·ªô ƒë√≥ng g√≥p v√†o d·ª± √°n
Gi·ªù l√†m vi·ªác 8:30 - 18:00 t·ª´ th·ª© 2 t·ªõi th·ª© 6; ∆∞u ti√™n s·ª± linh ho·∫°t v√† ch·ªß ƒë·ªông qu·∫£n tr·ªã hi·ªáu su·∫•t; c√¢n b·∫±ng cu·ªôc s·ªëng - c√¥ng vi·ªác
C√≤n g√¨ n·ªØa? H√£y c√πng ch√∫ng m√¨nh kh√°m ph√° v√† c√πng x√¢y d·ª±ng vƒÉn h√≥a iKame ƒë·ªÉ ph√°t tri·ªÉn t·ª´ng c√° nh√¢n nh√©!

---
C√ÅCH TH·ª®C ·ª®NG TUY·ªÇN
üíå ·ª®ng vi√™n g·ª≠i CV v·ªÅ email: hr@ikameglobal.com
‚û°Hotline: 0948 147 999 | Ms. Nguy·ªát
‚û°VƒÉn ph√≤ng iKame: T·∫ßng 10, t√≤a Peak View, 36 Ho√†ng C·∫ßu, √î Ch·ª£ D·ª´a, ƒê·ªëng ƒêa, H√† N·ªôi
-------------------------------
* iKame lu√¥n ∆∞u ti√™n c√°c b·∫°n g·ª≠i ƒëƒÉng k√Ω s·ªõm v√† ch·ªß ƒë·ªông li√™n h·ªá n·∫øu CV c·ªßa b·∫°n ph√π h·ª£p
* Our Google Play Store:
Store 1: https://play.google.com/store/apps/dev?id=4764343509860143092&hl=en
Store 2: https://play.google.com/store/apps/dev?id=5891027934210113676&hl=en

* Ch∆∞∆°ng tr√¨nh Gi·ªõi thi·ªáu ·ª©ng vi√™n, th∆∞·ªüng l√™n t·ªõi 10 tri·ªáu ƒë·ªìng: https://ikameglobal.com/tuyen-dung/ikame-referral-bonus-2021.html
Contact the job poster
Nguyet Nguyen 2nd
HR Manager | iKame Mobi | Looking for talents who always strive for the better!
Job Poster Location
Hanoi Capital Region
Send InMail"
3003495593|Data Engineer|Ho Chi Minh City, Vietnam|Anfin (YC W22)|Full-time|"About the job
About Anfin

We are a fintech company in Vietnam with the mission to bring investment opportunities and financial literacy to everyone in Vietnam. We strongly believe in the power of the stock market to transform developing economies. Therefore, we‚Äôre building the most innovative product in wealth management, and brokerage to make that happen. We have successfully raised investment from global venture capital investors and are now expanding the team to develop our product.

About the team

We‚Äôre a close-knit group of start-up enthusiasts, diverse in free-time hobbies from outdoors activities to paintings, yet similar in values like integrity, teamwork, and ownership. If that speaks to you, come join us! The great financial future for the Vietnamese won‚Äôt come true without you!

What you will do
- Create and maintain optimal data pipeline architecture.
- Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
- Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
- Identify, design, and implement internal process improvements: automating manual processes, optimizing data query delivery, redesigning infrastructure for scalability.
- Build the Data Infrastructure required for optimal ETL (or ELT) framework from internal and external resources that meets the business requirement.
- Work with data analysts and business partners to build key important dashboards.

Your skills and experiences
- We are looking for a candidate with 1-3 years of experience in a Data Engineer role.
- Strong analytical skills related to working with unstructured datasets.
- Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases (MySQL, Postgresql, etc.)
- Experience building and optimizing ‚Äòbig data‚Äô data pipelines, architectures, and data sets using cloud services: GCP (preferred), AWS, Azure, etc.
- Experience with OOP languages: Python, Java, Scala, etc.
- Experience with data pipeline and workflow management tools (Luigi, Airflow, etc.)
- Experience with big data frameworks is a plus: Hadoop, Spark, Kafka.

Why you'll love working with us
- Very competitive package & 100% probation salary
- Potential for ESOP
- MacBook is provided
- Salary review: Twice per year
- 13th-month bonus
- Social Insurance, Premium Healthcare Insurance for employees
- Dynamic, fast-paced start-up work environment building exciting products
- Company trip once a year and many exciting activities for team building
- Free parking, coffee, and tea
- Opportunity to learn about financial literacy from industry experts to build your own wealth
- Opportunity to be mentored by a leadership team who has extensive entrepreneurship experience, successfully founding and exciting Tech companies
- Working hours: Monday to Friday (from 8:30 am to 5:30 pm)
Contact the job poster
Thi KyÃÄ 2nd
Talent Acquisition Lead @AnFin
Job Poster Location
Ho Chi Minh City, Vietnam
Send InMail"
3009904217|||||
3004980549|Senior Data Engineer (0809)|Ho Chi Minh City Metropolitan Area|Techcombank (TCB)|Full-time ¬∑ Associate|"About the job
Job Purpose
The job holder is responsible for designing and developing programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from disparate sources and implement complex business logic as needed with the available data processing tools.
The job holder will be responsible for integrating new data sources to increase throughput of existing systems, managing data pipelines that facilitate robust analysis, and sourcing v√† preparing data to ensure data completeness on metadata platforms.
Key Accountabilities (1)
Data Architecture
Deliver functionality required for business and data analysts, data scientists and other business roles to advance the overall analytic performance and strategy of the bank
Build the best practices and strategies for data infrastructure to fulfill data analytic and utilization needs of the business with emerging latest technologies and capabilities.
Proactively drive the effort of identifying opportunities to manage data and provide solutions for complex data feeds within the bank.
Evaluate various data architectures in the bank and utilize them to develop data solutions to meet business requirements.
Drive the delivery of data products and services into systems and business processes in compliance with internal regulatory requirements.
Oversee the review of internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.
Key Accountabilities (2)
Data Integration
Strategically obtain and integrate data and information from various sources into the firm‚Äôs platforms, solutions and statistical models.
Lead discussion with Data Scientists to understand the data requirements and create re-usable data assets to enable data scientists to build and deploy machine learning models faster.
Design, build, and maintain optimized data pipelines and ETL solutions as business support tools in providing analysis and real time analytics platform for critical decision making.
Ensure data assets are organized and stored in an efficient way so that information is high quality, reliable, flexible, and efficient.
Key Accountabilities (3)
Project Management
Manage project conflicts, challenges and dynamic business requirements to keep operations running at high performance.
Work with team leads to resolve people problems and project roadblocks, conduct post mortem and root cause analysis to help squads continuously improve their practices to ensure maximum productivity.
Talent Development
Mentor and coach junior fellows into fully competent Data Engineers.
Identify and encourage areas for growth and improvement within the team.
Key Relationships - Direct Manager
Team Lead, Data Engineering; Senior Manager, Data Engineering

Key Relationships - Direct Reports

Key Relationships - Internal Stakeholders
Teams within the Data Office and relevant departments in the Bank

Key Relationships - External Stakeholders
Partners providing professional services

Success Profile - Qualification and Experiences
Qualifications
Bachelor's or Master‚Äôs degree in Statistics, Mathematics, Quantitative Analysis, Computer Science, Software Engineering or Information Technology
Work Experience
7+ years of relevant experience with developing, debugging, scripting and employing big data technologies (e.g. Hadoop, Spark, Flink, Kafka, Arrow, Tableau), database technologies (e.g. SQL, NoSQL, Graph databases), and programming languages (e.g. Python, R, Scala, Java, Rust, Kotlin) with preference towards functional/trait oriented
English proficiency requirements are pursuant to Techcombank's policy
Deep experience in designing and building dimensional data models, ETL processes, applied data warehouse concepts and methodologies, optimized data pipelines and wore the architect hat in the past or worked with one extensively
Deep experience with monitoring complex system and solving data and systems issues having a consistent and algorithmic approach to resolving them
Deep understanding of Information Security principles to ensure compliant handling and management of all data
Experience working in Agile teams to lead successful digital transformation projects, having mastered Agile principles, practices and Scrum methodologies
Has the know-how and the scripting and coding prowess to set up, configure v√† maintain a machine learning model development environment
Experience architecting, coding and delivering high performance micro services and/or recommenders delivering recommendations to (tens of) millions of users"
2838245273|Data Engineer - QuantumBlack - Ho Chi Minh City Based|Ho Chi Minh City, Ho Chi Minh City, Vietnam|QuantumBlack, a McKinsey company|Full-time ¬∑ Entry level|"About the job
Qualifications
Degree in computer science, engineering, mathematics or equivalent experience
Previous commercial experience in a data-driven role
Ability to write clean, maintainable and robust code in Python, Scala, Java or similar languages
Knowledge of software engineering concepts and best practices
Familiarity with the latest OSS, cloud, container, query and database technologies as well as query languages
Confirmed experience building data pipelines in production and ability to work across structured, semi-structured and unstructured data
Experience preparing data for analytics and following a data science workflow
Commercial client-facing or senior stakeholders management experience
What You'll Do

You will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally.
Partner with our clients, from data owners and users to C-level executives, to understand their needs and build impactful analytics solutions
Design and build data pipelines to support data science projects following software engineering best practices
Use state of the art technologies to acquire, ingest and transform big datasets
Map data fields to hypothesis, curate, wrangle and prepare data to be used in advanced analytics models
Create and manage data environments in the cloud or on premise
Ensure information security standards are maintained at all time
Contribute to cross-functional problem-solving sessions with your team and deliver presentations to colleagues and clients
Be flexible to travel to our clients' offices to deliver presentations, gather information or share knowledge
Have the opportunity to contribute to R&D and internal asset development projects
Our tech stack

While we advocate for using the right tech for the right task, we often leverage the following technologies Python, PySpark, SQL, Airflow, Databricks, our own OSS called Kedro, container technologies such as Docker and Kubernetes, cloud solutions such as AWS, GCP or Azure, and more!

What You'll Benefit From
Real-World Impact ‚Äì No project is ever the same. We work with top-tier clients across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership ‚Äì We work with the latest technologies and methodologies and offer first class learning programmes at all levels.
Multidisciplinary Teamwork - Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture ‚Äì Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity ‚Äì With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.
Visit our Careers site to watch our video and read about our interview processes and benefits.

Who You'll Work With

You will be based in Ho Chi Minh City and be a part of a global data engineering community. You will work in cross-functional and Agile project teams alongside project managers, data scientists, machine learning engineers, other data engineers and industry experts.

You will work hand in hand with our clients, from data owners and users to C-level executives.

Who You Are

You are a highly collaborative individual and enjoy solving problems that focus on adding business value. You have a sense of ownership and enjoy hands-on technical work. Our values resonate with yours."
2940686536|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Ninja Van|Full-time ¬∑ Entry level|"About the job
Ninja Van is a tech-enabled logistics company on a mission to provide hassle-free delivery services for businesses of all sizes across Southeast Asia. Launched in 2014, we started operations in Singapore and have become the region's largest and fastest growing last-mile logistics company, partnering with over 35,000 merchants and delivering more than 1,000 parcels every minute across six countries.

At our core, we are a technology company that is disrupting a massive industry with cutting-edge software and operational concepts. Powered by algorithm-based optimisation, dynamic routing, end-to-end tracking and a data-driven approach, we provide best-of-class delivery services that delight both the shippers and end customers. But we are just getting started! We have much room for improvement and many ideas that will further shape the industry.

This role will be working on reporting and analytics infrastructure needs for Ninja Van Vietnam. He/She will be working with

various departments to support the mounting data needs, especially the data infrastructure and architecture in Ninja Van

Vietnam.

Responsibilities
Business Intelligence
Responsible for SQL and another relational database administrations and management (capacity planning,installation, backup, recovery, monitoring, optimizations, troubleshooting, etc)
Support development teams and production teams for database designs and implementations
Design and build tables, schema. Set up ETL or data pipelines to load data for end-users.
Review existing system architecture and contribute to improving on the future architecture for database stability and a maximum performance
Maintain and improve data integrity/quality
Create consumable data marts for BI analysts
Define and develop projects that reduce database operational costs and automate regular tasks
Research and develop new technologies and approaches for building highly available data persistence systems
Requirement
Experience: 1-2 years working as a data analytics professional.
Bachelor degree in Computer Science, Information System
Technical skills: SQL, Python, Spark, ETL tools
Familiarity with cloud data tools such as Airflow, Google Cloud Platform tools
Teamwork, data processing, data architecture
Submit a job application

By applying to the job, you acknowledge that you have read, understood and agreed to our Privacy Policy Notice (the ‚ÄúNotice‚Äù) and consent to the collection, use and/or disclosure of your personal data by Ninja Logistics Pte Ltd (the ‚ÄúCompany‚Äù) for the purposes set out in the Notice. In the event that your job application or personal data was received from any third party pursuant to the purposes set out in the Notice, you warrant that such third party has been duly authorised by you to disclose your personal data to us for the purposes set out in the the Notice."
2923254944|Senior Data Engineer|Ho Chi Minh City Metropolitan Area|Techcombank (TCB)|Full-time ¬∑ Associate|"About the job
Job Purpose
The job holder is responsible for designing and developing programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from disparate sources and implement complex business logic as needed with the available data processing tools.
The job holder will be responsible for integrating new data sources to increase throughput of existing systems, managing data pipelines that facilitate robust analysis, and sourcing v√† preparing data to ensure data completeness on metadata platforms.
Key Accountabilities (1)
Data Architecture
Deliver functionality required for business and data analysts, data scientists and other business roles to advance the overall analytic performance and strategy of the bank
Build the best practices and strategies for data infrastructure to fulfill data analytic and utilization needs of the business with emerging latest technologies and capabilities.
Proactively drive the effort of identifying opportunities to manage data and provide solutions for complex data feeds within the bank.
Evaluate various data architectures in the bank and utilize them to develop data solutions to meet business requirements.
Drive the delivery of data products and services into systems and business processes in compliance with internal regulatory requirements.
Oversee the review of internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.
Key Accountabilities (2)
Data Integration
Strategically obtain and integrate data and information from various sources into the firm‚Äôs platforms, solutions and statistical models.
Lead discussion with Data Scientists to understand the data requirements and create re-usable data assets to enable data scientists to build and deploy machine learning models faster.
Design, build, and maintain optimized data pipelines and ETL solutions as business support tools in providing analysis and real time analytics platform for critical decision making.
Ensure data assets are organized and stored in an efficient way so that information is high quality, reliable, flexible, and efficient.
Key Accountabilities (3)
Project Management
Manage project conflicts, challenges and dynamic business requirements to keep operations running at high performance.
Work with team leads to resolve people problems and project roadblocks, conduct post mortem and root cause analysis to help squads continuously improve their practices to ensure maximum productivity.
Talent Development
Mentor and coach junior fellows into fully competent Data Engineers.
Identify and encourage areas for growth and improvement within the team.
Key Relationships - Direct Manager
Team Lead, Data Engineering; Senior Manager, Data Engineering

Key Relationships - Direct Reports

Key Relationships - Internal Stakeholders
Teams within the Data Office and relevant departments in the Bank

Key Relationships - External Stakeholders
Partners providing professional services

Success Profile - Qualification and Experiences
Qualifications
Bachelor's or Master‚Äôs degree in Statistics, Mathematics, Quantitative Analysis, Computer Science, Software Engineering or Information Technology
Work Experience
7+ years of relevant experience with developing, debugging, scripting and employing big data technologies (e.g. Hadoop, Spark, Flink, Kafka, Arrow, Tableau), database technologies (e.g. SQL, NoSQL, Graph databases), and programming languages (e.g. Python, R, Scala, Java, Rust, Kotlin) with preference towards functional/trait oriented
English proficiency requirements are pursuant to Techcombank's policy
Deep experience in designing and building dimensional data models, ETL processes, applied data warehouse concepts and methodologies, optimized data pipelines and wore the architect hat in the past or worked with one extensively
Deep experience with monitoring complex system and solving data and systems issues having a consistent and algorithmic approach to resolving them
Deep understanding of Information Security principles to ensure compliant handling and management of all data
Experience working in Agile teams to lead successful digital transformation projects, having mastered Agile principles, practices and Scrum methodologies
Has the know-how and the scripting and coding prowess to set up, configure v√† maintain a machine learning model development environment
Experience architecting, coding and delivering high performance micro services and/or recommenders delivering recommendations to (tens of) millions of users"
2978419854|Data Engineer - RPO 2022|Hanoi, Hanoi, Vietnam|Adecco|Full-time ¬∑ Mid-Senior level|"About the job
Job Summary
Possess an in-depth understanding of the data structures and governance
Fundamental knowledge of modern cloud computing platforms and concepts
Design, create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional/non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Cloud technologies
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs
Able to work in a fast-paced, multi-site location, team-oriented environment
Job Responsibilities
Possess an in-depth understanding of the data structures and governance
Fundamental knowledge of modern cloud computing platforms and concepts
Design, create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional/non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Cloud technologies
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs
Able to work in a fast-paced, multi-site location, team-oriented environment
Experience Requirements
5+ years experience in a developer role
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience with data warehousing architecture and data modeling
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experienced in manipulating, processing and extracting data from various source systems.
Experienced in implementing concepts such as Slowly Changing Dimension (SCD Type) and Change Data Capture (CDC) functionality in both an OLTP (Relational Modeling) and OLAP (Dimensional Modeling) environments.
Able to work independently with minimum supervision.
Experience with testing methodologies with the stated major development language(s)/technology
Education requirements
Bachelor‚Äôs degree in computer science, engineering, mathematics, or a related technical discipline.
Contact Person
Van Vu
Adecco"
2976792149|Senior Data Engineer|C·∫ßu Gi·∫•y, Hanoi, Vietnam|SV Technologies JSC|Full-time|"About the job
Job Descriptions:

Data Architecture
- Deliver functionality required for business and data analysts, and other business roles to advance the overall analytic performance and SVTECH strategy
- Build the best practices and strategies for data infrastructure to fulfill data analytic and utilization needs of the business with emerging latest technologies and capabilities.
- Proactively drive the effort of identifying opportunities to manage data and provide solutions for complex data feeds with customers‚Äô demands.
- Evaluate various data architectures and utilize them to develop data solutions to meet customers‚Äô requirements.
- Drive the delivery of data products and services into systems and business processes in compliance with internal regulatory requirements.

Data Integration
- Strategically obtain and integrate data and information from various sources into the customer‚Äôs platforms, solutions and statistical models.
- Design, build, and maintain optimized data pipelines and ETL solutions as business support tools in providing analysis and real time analytics platform for critical decision making.
- Ensure data assets are organized and stored in an efficient way so that information is high quality, reliable, flexible, and efficient

Job Requirements:

- Bachelor's or Master‚Äôs degree in Statistics, Mathematics, Quantitative Analysis, Computer Science, Software Engineering or Information Technology
- 5+ years of relevant experience with developing, debugging, scripting, and employing big data technologies (e.g. Hadoop, Spark, Flink, Kafka, Arrow, Tableau), database technologies (e.g. SQL, NoSQL, Graph databases), and programming languages (e.g. Python, R, Scala, Java, Rust, Kotlin) with a preference towards functional/trait oriented
- Deep experience in designing and building dimensional data models, ETL processes, applied data warehouse concepts, and methodologies, optimized data pipelines, and wore the architect hat in the past or worked with one extensively
- Priority :
¬∑ Experience in Enterprise Data Architecture, Data Integration and Data Modeling.
¬∑ In-depth knowledge and expertise for Information Management in areas of Data Warehousing, Business Intelligence, Data Governance and Data Analysis
¬∑ Deep experience with monitoring complex system and solving data and systems issues having a consistent and algorithmic approach to resolving them
- Good English communication

Click done ‚Äì Happy come:
- Clear roadmap for development and promotion with a well-trained training plan.
- The training budget is up to $5000 / year, including the cost of funding studying & exam international certificates.
- Enjoy competitive salary, attractive bonus directly from the company's profits (minimum commitment of 14 months salary / year).
- Health Insurance Package for yourself and your family up to $3000 / person.
- Working in a professional, friendly environment with 4 core values: Trust, Teamwork, Knowledge & Creativity, Customer.
- Live & work in balance with 4 values: Heath, Heart, Mind, Spirit with flexible working policy.
- The companionship between boss & employee. The company is the second home where members live and work together with an enthusiastic, sincere heart and the spirit of constant learning.
- Plentiful cultural and entertainment activities: Team building, Sports Club, music, Sun-flower program, Happy Hour ...
Interested candidates please send your CV to recruitment@svtech.com.vn . We really want to receive information from candidates who are capable and aspire to success and happiness.


Contact the job poster
Trang Thu 2nd
Looking for Sales (Telco) Service Sales, PM (Telco), Database
Job Poster Location
Hanoi, Hanoi, Vietnam
Send InMail"
3001876090|Junior/Senior Data Engineer (ETL, SQL, BI)|Ho Chi Minh City, Ho Chi Minh City, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and data analytics to build dashboards and business data insight. Key responsibilities: * In collaboration with architect, implement data solutions that solve business problems * Design conceptual, logical and physical data models * Implement effective and scalable end-to-end data pipeline solutions * Optimize SQL queries for scale * Possess a comprehensive understanding of products and services General requirements: * At least intermediate level of English level * Likely having 3+ years of experience depending on how fast of your learning and developing technical capability * Ability to obtain deep knowledge of the project technologies and work independently with minimum guidance * Ability to self-learn and adapt to new technologies quickly Technical requirements: * Fluency in SQL and experience in Extract, Transform, and Load (ETL) development in SQL * Good knowledge and hands-on experience of using popular ETL tools such as: SSIS, Talend or Pentaho * Experience one of the following programming languages: Java, Javascript, C# or Groovy * Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry * Interested in data business analysis to build metrics and reports Nice to have: * Experience with reporting and BI tools such as SSRS, PowerBI * Basic knowledge or experience of using cloud platform (AWS/Azure/GCP) * Working in one of the Best Places to Work in Vietnam * Building large-scale & global software products * Working & growing with Passionate & Talented Team * Diverse careers opportunities with Software Outsourcing, Software Product Development, IT Solutions & Consulting * Attractive Salary and Benefits * Two performance appraisals every year * Onsite opportunities: short-term and long-term assignments in North American (U.S, Canada), Europe, Asia. * Flexible working time * Various training on hot-trend technologies, best practices and soft skills * Premium healthcare insurance for you and your loved ones * Company trip, big annual year-end party every year, team building, etc. * Fitness & sport activities: football, tennis, table-tennis, badminton, yoga, swimming... * Joining community development activities: 1% Pledge, charity every quarter, blood donation, public seminars, career orientation talks,... * Free in-house entertainment facilities (foosball, ping pong, gym...), coffee, and snack (instant noodles, cookies, candies...) And much more, join us and let yourself explore other fantastic things!"
3006952057|[Remote] Data Engineer (middle/senior)|Vietnam|Carro|Full-time|"About the job
Responsibilities
Ownership of designing, developing, building, testing and maintaining our next generation data ETL platform
Champion the effort to continuously improving the efficiency and flexibility of the platform and services
Build highly reusable components across the platform
Troubleshooting and debugging to optimise the performance
Write scripts to process structured and unstructured data.
Take charge to proactively recommend and deploy methods to improve our data reliability, quality and efficiency
Qualifications
Bachelor in Computer Science or any quantitative discipline
At least 3 years of handson working experience in data/software engineering in a highly scalable production environment
Good knowledge of architecting largescale data infrastructure in the cloud platform
Good knowledge of Big Data technologies like Hadoop,Hive,Spark or other realtime streaming
Good knowledge of serverside programming languages (preferably Python,R), and Javascript.
Excellent communication skills (oral, written and presentation skills) to work with various stakeholders (technical and non technical) including presentation of insights reports to business/product owners
Good English communication
Last but not least, you love cars and maybe even more than us!
Prefer if candidate have
Handson experience in DevOps tools like Docker and Kubernetes is advantageous
Experience working with a productbased organization, ecommerce, automotive is advantageous
Benefits
Opportunities to gain handson experience in cuttingedge technologies.
Fasttracked career opportunities to lead teams as Carro scales
Group Health Insurance
Transportation Allowance
MacBook Pro provided (once they passed probation)
Staff Welfare Allowance (Recreational Allowance)
SelfLearning Development Fund, AWS. Sponsor/subsidize course fee. Workrelated courses
Annual performance review
14 Days Annual Leave
Pantry, Social Gathering
Professional, dynamic and open working environment
*Please note that we are a Singaporean company so we won't be able to cover the social insurance for you"
3011677823|Data Engineer|Ho Chi Minh City, Vietnam|VINA GROUP|Full-time|"About the job
Job Description:
JOB SUMMARY:
Data powers all the decisions we make at Snapmart. You will be responsible for designing, building and optimizing our analytic initiatives, as well as utilizing them to support business to make well-informed, logical and efficient decisions.
JOB RESPONSIBILITIES:
Build, maintenance, monitor data system, which is a mandatory data product for BI associates and other stakeholder users, provide an efficient way for data science and business teams to explore the data.
Working with stakeholders to define system specifications, plan and design the system architecture, to select appropriate software & solutions.
Taking lead on technical best practices and internal research. Be positive energy and influence among your co-workers.
Be a mentor to your co-workers, and always learn from where you can
REPORTING RELATIONSHIP
Reporting to: Data Product Manager
Direct Reports: none
Requirement:
Education:
Bachelor‚Äôs degree in Mathematics, Economics, Computer Science, Information Management, Statistics, Business Analytics or Business Information Systems
Experience:
Experience using visual analytic tools (e.g. Qlik, Tableau, PowerBI), big data frameworks (e.g. Hadoop, Spark, Kafka‚Ä¶) and data warehousing architectures (data lake, data warehouse, datamart).
3+ years of relevant work experience in data engineering, with knowledge of marketplace operations, logistics, transportation, supply chain or last-mile delivery preferably.
Working experience in a well-established logistics or e-commerce company is a plus
A track record of building performance dashboards and data pipeline to support consumer business
Technical Skills:
Good knowledge of SQL, database systems, and distributed database systems such PostgreSQL, MongoDB, Amazon, Redis‚Ä¶
Expert with programming, ideally Scala, Java or Python, & experience with ETL tools such Apache Nifi, Apache Airflow‚Ä¶
Experience with cloud services, primarily: AWS (EC2, S3, EMR, ‚Ä¶), GCP (GCS, BigQuery, ‚Ä¶)
Good at problem solving, algorithms, data structures, functional programming, design patterns.
Experience in deploying Machine learning models and a good understanding of EC2 and virtual machine
Sensitivity to figures, knowledge of quantitative analysis, able to find problems, making and verifying assumptions from data.
Able to communicate effectively in verbal and written English with confidence.
Soft Skills:
Detail-oriented, careful manner.
Highly energetic, independent & ability to thrive in a fast-paced start-up environment.
Demonstrated ability to learn fast, handle multiple tasks, prioritize objectives to meet deadlines.
Benefit:
Salary: Upto $2000 Gross
2-month probation period.
Health card upon regularization.
Working equipment to be provided depending on requirements of work.
Bonus: Employees areencouraged physically and mentally when they have achievements in their work oraccording to the Company‚Äôs Policies.
Salary Increment: According to the Company's salarypolicy.
Time of Rest: According to theState's regulations.
Time working: From Monday to Friday, 8am - 6pm.
Work remote until the end of the Epidemic
Interview: 2 Rounds.

You know the job poster
Reach out to let them know you‚Äôre interested
Sala Truong 1st
Technical Recruiter at VINA GROUP
Job Poster Location
Ho Chi Minh City, Vietnam
Message"
2931811630|Fresher Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Officience|‚Ç´7/month - ‚Ç´12/month ¬∑ Full-time|"About the job
This job is sourced from a job board. Learn more
Be a member of a dedicated team Program new scripts to crawl new sites, new strategies to overcome technical difficulties (IP blocked, encrypted data,..) Keep on optimizing crawling process Communicate with clients on innovations or improvements. Research machine learning model, visualize data (language, number) Other works according to project requirements Qualifications From 4 - 6 months experience as developer; knowledge about web Familiar with Linux OS , Crawling Data from the website Basic knowledge on SQL, mySQL databases. Basic knowledge on Python/Javascript/Bash cripting Data mining or have interested in Data Science Teamwork spirit, responsibility and good in English It would be a plus point if you have been familiar with Shell/ Bash scripting. If not, don‚Äôt worry, you will be trained by our Senior Developer. It would be a plus point if you have been familiar with Shell/ Bash scripting. If not, don‚Äôt worry, you will be trained by our Senior Developer. General information Level: Fresher-Junior Type of the position: Full-time permanent Cluster: IT Craft (Autobiz) Working time: 9:00 AM - 6:00 PM (flexible) Working location: F-Central; 16A Le Hong Phong, Ward 12, Dist. 10, HCMC Monthly salary: $400-600 USD Other benefits: 13th month salary Tet bonus Trade Union gifts Lunch served right at pantry Premium healthcare package Annual healthcare check up at international clinic Free training classes with diverse topics Innovative salary review process 22 leaves per year Laptop policy if any Parking-free Onsite opportunities to France upon Client‚Äôs request"
2996804958|Data Engineer|Vietnam|Joon Solutions|Full-time|"About the job
We are looking for a candidate with 1+ years of experience in a Data Engineer role. Having a degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field is a plus. They should also have experience using some of the following software/tools/platforms:
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS/GCP/Azure cloud services.
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‚Äòbig data‚Äô data pipelines, architectures, and data sets.
Able to understand various data structures and common methods in data transformation
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‚Äòbig data‚Äô data stores.
Contact the job poster
Jonathan Barrett 2nd
üë®üèª‚Äçüíª‚òÅÔ∏èüìàü§ñüöÄ
Job Poster Location
San Diego, California, United States
Send InMail"
2821132094|(Senior) Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|ShopBack|Full-time ¬∑ Associate|"About the job
About Us

ShopBack : Better Shopping, Every Day.

The ShopBack Group is Asia-Pacific‚Äôs leading shopping and rewards platform, serving over 30 million shoppers across ten markets. Growing from a team of six back in 2014 to over seven hundred today, ShopBackers across the region come together with a singular mission: to make shopping rewarding, delightful, and accessible for all.

Joining forces with leading buy now, pay later (BNPL) player hoolah and with the launch of ShopBack Pay, the Group now offers shoppers a responsible and convenient payment option at checkout.

More than half a billion shopping trips start with ShopBack each year. The Group powers over US$3.5 billion in annual sales for over 10,000 online and in-store merchant partners, across categories ranging from fashion, beauty, F&B, electronics, travel and more. If you are passionate about building and scaling up businesses in this fast-growing landscape, come and join our growing ShopBack team!

Responsibilities

Build, maintain ETL pipelines from business database to data warehouse/ lake
Build, maintain internal data platform services that support Analytics and Data Science
Enhance and optimize existing data platform services
Translate business requirements into data solutions

Requirements

Welcome the experience for gross level, for senior-level minimum 3 years working experience in data management domains
Experience working in data, ETL, data security, and databases
Strong coding skills in Python or Java/Scala, SQL
Good knowledge of data technologies: Spark, Airflow, Hive
Strong ability to reason about data structures, complexity, and possible engineering approaches to a problem

Nice to have

Understanding of containerization technologies with Docker & Kubernetes
Stream processing experience with Kafka, KafkaStreams or Flink.
Experience working with Cloud Platforms, preferably AWS
Experience in building end-to-end platforms/ solutions using both open source components and cloud vendor products"
2964696264|Software/ Data Engineer|Hanoi, Hanoi, Vietnam|Techcombank (TCB)|Full-time ¬∑ Mid-Senior level|"About the job
M·ª•c ti√™u / Objective
- The job holder is responsible for developing programs, algorithms and automated processes to cleanse,
integrate and evaluate large datasets from disparate sources and implement complex business logic as
needed with the available data processing tools.
- The job holder will be responsible for helping build a reliable, sustainable and scalable data processing
platform, working with other tribe members to support data pipelines, convert models to machine learning
codes and recommend Big Data reporting and visualization applications.
Tr√°ch nhi·ªám ch√≠nh / Key accountabilities
A. Data Architecture
Deliver functionality required for business and data analysts, data scientists and other business roles to
advance the overall analytic performance and strategy of the bank
Assist in building best practices and strategies for data infrastructure to fulfill data analytic and utilization
needs of the business with emerging latest technologies and capabilities.
- Collaborate with relevant teams on opportunities to manage data and provide solutions for complex data
feeds within the bank.
- Maintain data integration processes into the data platform by building data pipelines and align with
business representatives and business information needs.
- Review internal and external business and product requirements for data operations and activity and
suggests changes and upgrades to systems and storage to accommodate ongoing needs.
B. Data Integration
- Obtain and integrate data and information from various sources into the firm‚Äôs platforms, solutions and
statistical models.
- Collaborate with Data Scientists to understand data requirements and create re-usable data assets to
enable data scientists to build and deploy machine learning models faster.
- Write scripts and ingest raw data to build and maintain optimized data pipelines and ETL solutions as
business support tools in providing analysis.
- Ensure data assets are organized and stored in an efficient way so that information is easy to access and
retrieve.
Y√™u c·∫ßu/ Requirements
B·∫±ng c·∫•p, Kinh nghi·ªám/ Qualification and experiences
- Bachelor or Master‚Äôs degree in Statistics, Mathematics, Quantitative Analysis, Computer Science,
Software Engineering or Information Technology
- 2 to 4 years of relevant experience with developing, debugging, scripting and employing big data
technologies (e.g. Hadoop, Spark, Flink, Kafka, Arrow, Tableau), database technologies (e.g.
SQL, NoSQL, Graph databases), and programming languages (e.g. Python, R, Scala, Java, Rust,
Kotlin) with preference towards functional/trait oriented
- English proficiency requirements are pursuant to Techcombank's policy
- Experience in designing and building dimensional data models, ETL processes, applied data
warehouse concepts and methodologies, optimized data pipelines and assisted the architect as
needed
- Experience monitoring complex system and solving data and systems issues having a consistent
and algorithmic approach to resolving them
- Deep understanding of Information Security principles to ensure compliant handling and
management of all data
- Experience working in Agile teams to support digital transformation projects, having a clear
understanding of Agile principles, practices and Scrum methodologies
- Has some know-how and partial scripting and coding experience to set up, configure & maintain
a machine learning model development environment
- Some experience architecting, coding and delivering high performance micro services and/or
recommenders delivering recommendations to a large user-base
Contact the job poster
Nguyet Tran ‚òÜ 2nd
Passionate about helping people and companies achieve their dreams!
Job Poster Location
Vietnam
Send InMail"
2963340019|Data Engineer|Ho Chi Minh City, Vietnam|New Ocean IS Co., Ltd.|Full-time|"About the job
Job Description
Learn and analyze data sources of systems in the Company.
Modeling, analyzing, designing and implementing data integration systems.
Exploit, analyze and process from source data to synthesize data warehouse.
Analyze data quality related issues, research and propose methods to optimize data output and transformation.
Build and upgrade BI/Data Lake system and data systems.
Research and offer new technology solutions in line with the Company's goals and strategies.
Participate in the implementation of projects.
Your Skills and Experience
*** Technical skills:
Graduated from university majoring in IT: Data Science, Computer Science, Software Technology, Information Systems‚Ä¶.
Having knowledge in developing BI/Data Lake/Data Warehouse systems.
Having good knowledge about RDBMS, BigData, Data Warehouse, Data lake, Data model, OLTP, OLAP.
Proficient in using one of the database management systems: Oracle, SQL Server, PostgreSQL
Knowledge of Hbase, Hive, Hadoop, Yarn
Proficient in data processing languages: SQL, Python, C#
Knowledge of Kafka, Flink, Spark technologies.
Proficient in using one of the ETL Tools: Sqoop, Airflow, SSIS
Knowledge of BI tools: PowerBI (required), Google Data Studio, Tableau
*** Personal skills:
English: reading and understanding specialized documents, TOEIC > 500
Good communication skills
Ability to work in a team in a fast-paced, high-pressure environment
Good logical thinking, hard working and responsible in work.
Why You'll Love Working Here
Insurance and Salary
Vietnam labor regulations
Healthy Insurance
Competitive and high salary
Review salary twice a year (April and October (exceptional))
13th month-salary
Reward of the end the year
Raised on for achieving English and Technical certificates
Training and Onsite
Onsite opportunity (Singapore or Australia)
Trained to achieve MCP/MCSA/MCSD to follow Microsoft Learning Path: Application Development, Cloud Platform.
Trained soft skills every week via courses.
Dedicated MSDN account provided, and $150 monthly Azure credit
Career Path
Clear Career Path
Projects in many domain
Everyone is willing to support each other.
Activities
Office happy hours, Teambuilding, Company trip, Wedding, Birthday, ‚Ä¶
Sport clubs: soccer, badminton, games, ‚Ä¶
RECRUITMENT PROCESS
Only one ‚Äì round: about 60 minutes (HR and Technical Department);
Interview in person or online via Microsoft Teams

Contact the job poster
Duong Phan
Human Resources at New Ocean IS Co., Ltd.
Job Poster Location
Vietnam
Send InMail"
2950826069|[ETM5] 2022 - Data Engineer (Fresher accepted)|T√¢n B√¨nh, Binh Duong, Vietnam|Bosch Group|Full-time ¬∑ Entry level|"About the job
- Design stable, reliable and effective databases
- Optimize and maintain legacy systems
- Modify databases according to requests and perform tests
- Solve database usage issues and malfunctions
- Liaise with developers to improve applications and establish best practices
- Gather user requirements and identify new features
- Develop technical and training manuals
- Provide data management support to users
- Ensure all database programs meet company and performance requirements



Qualifications

- Bachelor degree in IT/ Computer Science or relevant background
- Final-year students or Fresh Graduate are welcome to apply
- Source Control Tools: GIT, sourcetree..
- Good knowledge in data warehouse
- Experience with SQL Developer.
- Knowledge of Agile methodologies
- Knowledge of oracle database development.
- Strong experience with oracle functions, procedures, triggers, packages & performance tuning,
- Hands on development using SQL, PL/SQL
- Good English communication skills



Additional Information

Why BOSCH?

Because we don't just follow trends, we create them.

Because together we turn ideas into reality, working every day to make the world of tomorrow a better place. Do you have high standards when it comes to your job? So do we. At Bosch, you will discover more than just work.

Benefits and Career Opportunities for Internship

Monthly Internship Allowance + Support allowance (Meal & Parking)
Good benefits of Trade Union activities, team building and company trip.
Opportunity to work in global projects of fast developing company and being a part of innovation team contributing initiative ideas to the hi-tech world.
Engage in our diverse training programs which surely help strengthen both your personal and professional skills
Benefits and Career Opportunities for Fresh Graduate

13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal
100% monthly basic salary and mandatory social insurances in 2-month probation
Onsite opportunities: short-term and long-term assignments
15++ days of annual leave + 1 day of birthday leave
Premium health insurance for employee and 02 family members
Flexible working time
Lunch and parking allowance
Various training on hot-trend technologies/ foreign language (English/Chinese/Japanese) and soft-skills
Fitness & sport activities: football, badminton, yoga, Aerobic
Free in-house entertainment facilities and snack
Join in various team building, company trip, year-end party, tech talks and a lot of charity events"
2969405468|Data Engineer|Hanoi, Hanoi, Vietnam|C√¥ng Ty C·ªï Ph·∫ßn Gi√°o D·ª•c V√† C√¥ng Ngh·ªá H√πng V∆∞∆°ng|‚Ç´14,000,000/month - ‚Ç´25,000,000/month ¬∑ Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
H·∫†N CU·ªêI: 31/3/2022 M√¥ t·∫£ c√¥ng vi·ªác X√¢y d·ª±ng database kh√°ch h√†ng, qu·∫£n l√Ω ch·∫•t l∆∞·ª£ng v√† s·ª± an to√†n Thi·∫øt k·∫ø, x√¢y d·ª±ng v√† kh·ªüi ch·∫°y c√°c quy tr√¨nh tr√≠ch xu·∫•t, chuy·ªÉn ƒë·ªïi v√† t·∫£i d·ªØ li·ªáu m·ªõi Ph·ª• tr√°ch nghi√™n c·ª©u c√°c c√¥ng c·ª• ƒë·ªÉ ph√°t tri·ªÉn t√≠nh nƒÉng cho ph·∫ßn m·ªÅm d·ªØ li·ªáu h·ªó tr·ª£ c√¥ng vi·ªác/ k·ªπ nƒÉng ki·∫øn th·ª©c v·ªÅ ph√¢n t√≠ch Ph·ªëi h·ª£p v·ªõi ƒë·ªôi CNTT n·ªôi b·ªô ƒë·ªÉ l√†m r√µ c√°c y√™u c·∫ßu v·ªÅ ki·∫øn tr√∫c t√≠ch h·ª£p d·ªØ li·ªáu. Khai th√°c, ph√¢n t√≠ch v√† x·ª≠ l√Ω t·ª´ d·ªØ li·ªáu ngu·ªìn ƒë·ªÉ t·ªïng h·ª£p v·ªÅ kho d·ªØ li·ªáu. Tri·ªÉn khai v√† qu·∫£n l√Ω c√¥ng vi·ªác, chi ph√≠ theo k·∫ø ho·∫°ch CRM ƒë√£ x√¢y d·ª±ng (bao g·ªìm ch∆∞∆°ng tr√¨nh chƒÉm s√≥c kh√°ch h√†ng, c√°c k√™nh th√¥ng tin tr·ª±c ti·∫øp t·ªõi kh√°ch h√†ng qua sms, email, telesales ). C√°c c√¥ng vi·ªác ph√°t sinh kh√°c theo y√™u c·∫ßu c·ªßa qu·∫£n l√Ω Y√™u c·∫ßu ·ª©ng vi√™n - Y√™u c·∫ßu v·ªÅ k·ªπ nƒÉng - chuy√™n m√¥n V·ªÅ database: Th√†nh th·∫°o v·ªÅ c√°c ng√¥n ng·ªØ x·ª≠ l√Ω d·ªØ li·ªáu nh∆∞: SQL, NOSql, MongoDB, Big Query Ki·∫øn th·ª©c v·ªÅ qu·∫£n l√Ω c∆° s·ªü d·ªØ li·ªáu v√† khai th√°c d·ªØ li·ªáu. C√≥ kh·∫£ nƒÉng l√†m vi·ªác v·ªõi CRM. Kh·∫£ nƒÉng ph√¢n t√≠ch, giao ti·∫øp, l√†m vi·ªác nh√≥m t·ªët Kh·∫£ nƒÉng c·ªông t√°c v·ªõi Qu·∫£n l√Ω hi·ªáu su·∫•t ƒë·ªÉ hi·ªÉu v√† ph√¢n t√≠ch d·ªØ li·ªáu v·ªÅ hi·ªáu su·∫•t c·ªßa c√° nh√¢n v√† nh√≥m -Y√™u c·∫ßu v·ªÅ Tr√¨nh ƒë·ªô vƒÉn ho√° T·ªët nghi·ªáp ƒê·∫°i h·ªçc chuy√™n ng√†nh: c√¥ng ngh·ªá th√¥ng tin, khoa h·ªçc m√°y t√≠nh, ph√¢n t√≠ch t√†i ch√≠nh, To√°n kinh t·∫ø ho·∫∑c c√°c lƒ©nh v·ª±c li√™n quan. -Y√™u c·∫ßu v·ªÅ kinh nghi·ªám / th√¢m ni√™n c√¥ng t√°c T·ªëi thi·ªÉu 1 nƒÉm kinh nghi·ªám v·ªÅ x·ª≠ l√Ω, ph√¢n t√≠ch s·ªë li·ªáu Quy·ªÅn l·ª£i ƒë∆∞·ª£c h∆∞·ªüng M·ª©c thu nh·∫≠p h·∫•p d·∫´n t·ª´ 14-25 tri·ªáu/th√°ng (c√≥ th·ªÉ th∆∞∆°ng l∆∞·ª£ng trong bu·ªïi ph·ªèng v·∫•n) Review l∆∞∆°ng h·∫±ng nƒÉm, l∆∞∆°ng th√°ng th·ª© 13, c√°c kho·∫£n bonus d·ª±a tr√™n hi·ªáu qu·∫£ c√¥ng vi·ªác K√Ω H·ª£p ƒë·ªìng lao ƒë·ªông v√† c√°c ch·∫ø ƒë·ªô b·∫£o hi·ªÉm theo lu·∫≠t lao ƒë·ªông C√°c ho·∫°t ƒë·ªông Teambuilding c·ªßa c√¥ng ty C∆° h·ªôi h·ªçc h·ªèi v√† ph√°t tri·ªÉn khi l√†m vi·ªác v·ªõi nh·ªØng ƒë·ªìng nghi·ªáp t√†i nƒÉng, ti·∫øp c·∫≠n ·ª©ng d·ª•ng c√°c c√¥ng ngh·ªá m·ªõi. M√¥i tr∆∞·ªùng l√†m vi·ªác tr·∫ª trung, ƒë·∫£m b·∫£o s·ª± tho·∫£i m√°i, t·ª± do s√°ng t·∫°o, c∆° h·ªôi thƒÉng ti·∫øn cao"
2987708679|Data Engineer|Ho Chi Minh City, Vietnam|BeepBeep!|Full-time|"About the job
‚Ä¢ Bachelor's or advanced degree in IT/ Statistics/ Math or related fields.
‚Ä¢ More than 3 years of experience in data technology.
‚Ä¢ Knowledgeable and experience in both relational databases and NoSQL databases (eg: MongoDB).
‚Ä¢ Experience in ETL tools or data pipeline languages such as Python, Scala, cloud-based infrastructure (eg: AWS, GCP, Azure‚Ä¶).
‚Ä¢ Experience with visualization tools such as Tableau, PowerBI.
‚Ä¢ Knowledge in business analysis and data modeling.
‚Ä¢ Fluent in English speaking/ writing with excellent interpersonal skills.
‚Ä¢ Team player with good management skills.

What are great to have:
‚Ä¢ Familiar with software development process and culture.
‚Ä¢ Experience with Big data and data warehouse concepts and methodologies
‚Ä¢ Experience with third party libraries and APIs.
‚Ä¢ Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc

Salary: Negotiable
Contact the job poster
Uyen Tran 2nd
Product Ops & BI Lead at BeepBeep!
Job Poster Location
Vietnam
Send InMail"
2975692664|Data Engineer|Ho Chi Minh City, Vietnam|Movi Vietnam|Full-time|"About the job
Design, further development, and implementation of ETL processes / BI system according to the architecture definition.
Ensures monitoring and quality assurance within the responsible processes.
Provides data for analytics roles (data scientist and BI analyst) from source systems via ETL in data store.
Maintain/Operate a deployment pipeline for machine learning team.
Ensure that DWH, Data mart, BI tools work stably as the final data keeper by proactively working with other data source keepers if any issue, thru aligned business/ system/ and data processes.
Manage and enhance DWH, Data mart, BI system as a whole, in term of Database Management/ Data Set/ Data Models/ BI Tools/ Standard Dashboards & Reports/ System & Data Processes.
------
Bachelor‚Äôs degree in Economics, Finance, Statistic, IT or related field.
2+ years experience in ETL tool (Pentaho, Python, dbt‚Ä¶) and BI system (Pentaho BI, Metabase, Power BI, ‚Ä¶).
Expert handling of data from source systems and databases (MySQL, Redshift) and Analytical tool (R, Python, ‚Ä¶)
English: acceptable
Contact the job poster
Ng·ªçc Hu·ª≥nh 2nd
Movi Viet Nam is hiring Data Engineer
Job Poster Location
Ho Chi Minh City, Vietnam
Send InMail"
2973951675|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Liquid|Full-time ¬∑ Entry level|"About the job
Responsibilities
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies.
Build analytics and visualisation tools that use the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Marketing, Accounting, Design and Data teams to assist with data-related technical issues and support their data infrastructure needs.
Build Tableau dashboards to provide real time insights into our market and customer activities for a wide range of stakeholders.
Build and automate reports using Python and SQL on PostgreSQL, to provide to each team the data required for their operations..
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Qualifications
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases including Postgres.
Experience building and optimizing 'big data' data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Knowledge of data warehouse modeling techniques and core concepts
Experience of optimizing complex sql queries to enhance performance
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Experience with building and maintaining reporting dashboards using Tableau
Experience with Python, including numpy and pandas
Fluent English"
2999772152|Data Engineer, KMS Solutions|Ho Chi Minh City, Ho Chi Minh City, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Entry level|"About the job
This job is sourced from a job board. Learn more
As a key member of our Consulting team within Service Delivery, the position will be the data engineer that helps guide our customers through their data product implementation. Working directly with customers, a team of data product managers, solution architects and engineers drive requirements gathering, the project design, and the QA process. You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and will data analytics to build dashboard and business data insight. Key responsibilities * In collaboration with architect, implement data solutions that solve business problems * Design conceptual, logical and physical data analytics solutions * Implement effective and scalable end-to-end data pipeline solutions * Script Optimized SQL queries for scale * Possess a comprehensive understanding of products and services * At least 2+ years of work experience * Experience in SQL scripting. * Understanding of dimensional and normalized database models * Understanding Extract, Transform, and Load (ETL) * Having a programming mentality and problem-solving skills * Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry * Interested in data business analysis to build metrics and reports * Understanding of the concept of cloud-based SaaS platforms * Experience with the programming language, Scripting language, REST APIs is a plus * Be flexible on technology Thinking of joining KMS Solutions? Yes, you deserve it! Progressive Career Development * Role-based training foundation * Active role at the global client-side * Continuous professional certification * Simple goals - achievable success Attractive compensation * Up to 15 months salary/year * Performance review twice a year * Premium healthcare insurance * 18+ paid leave/year Engagement workplace * Flexi mode, modern work environment * Well-being centric Impactful community organization * Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,... /Join us and let yourself explore other fantastic things!/"
2999775080|Data Engineer, KMS Solutions|ƒê√† Nang, Da Nang City, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Entry level|"About the job
This job is sourced from a job board. Learn more
As a key member of our Consulting team within Service Delivery, the position will be the data engineer that helps guide our customers through their data product implementation. Working directly with customers, a team of data product managers, solution architects and engineers drive requirements gathering, the project design, and the QA process. You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and will data analytics to build dashboard and business data insight. Key responsibilities * In collaboration with architect, implement data solutions that solve business problems * Design conceptual, logical and physical data analytics solutions * Implement effective and scalable end-to-end data pipeline solutions * Script Optimized SQL queries for scale * Possess a comprehensive understanding of products and services * At least 2+ years of work experience * Experience in SQL scripting. * Understanding of dimensional and normalized database models * Understanding Extract, Transform, and Load (ETL) * Having a programming mentality and problem-solving skills * Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry * Interested in data business analysis to build metrics and reports * Understanding of the concept of cloud-based SaaS platforms * Experience with the programming language, Scripting language, REST APIs is a plus * Be flexible on technology Thinking of joining KMS Solutions? Yes, you deserve it! Progressive Career Development * Role-based training foundation * Active role at the global client-side * Continuous professional certification * Simple goals - achievable success Attractive compensation * Up to 15 months salary/year * Performance review twice a year * Premium healthcare insurance * 18+ paid leave/year Engagement workplace * Flexi mode, modern work environment * Well-being centric Impactful community organization * Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,... /Join us and let yourself explore other fantastic things!/"
2999004912|Data Engineer|Ho Chi Minh City, Vietnam|POC Pharma|Full-time ¬∑ Mid-Senior level|"About the job
About us

POC Pharma is a startup that digitizes the pharmaceutical industry in emerging markets and helps pharmaceutical companies leverage data to grow their sales. Come join the coolest team and contribute to an exciting and fast-moving industry, using the best technologies!

Why do we want YOU?

Because as a Data Engineer, you will help us:
‚Ä¢ Be a subject matter expert in analyzing and presenting data that provides important insights into customers behaviors and usage patterns
‚Ä¢ Work with both developers and business stakeholders from diverse teams to understand business needs and determine optimal solutions while constantly evaluating the risks & dependencies
‚Ä¢ Write and maintain sophisticated SQL queries to meet complex needs
‚Ä¢ Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
‚Ä¢ Create processes to quickly test the accuracy of the generated datasets & reports
‚Ä¢ Communicate regularly and directly with stakeholders and executive sponsors
‚Ä¢ Develop business requirements documentation, process workflow diagrams, functional specifications, user acceptance test scripts and other supporting documentation for BI initiatives

Because you have what it takes to win and grow with us:
‚Ä¢ 3+ years of experience in a Data Engineer role, who has attained a Graduate degree in ‚Ä¢ Computer Science, Statistics, Informatics, Information Systems or another quantitative field
‚Ä¢ Experience with relational SQL and NoSQL databases, including MSSQL, with strong experience in building sophisticated SQL queries
‚Ä¢ Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. or other technologies (e.g.: matching algorithm, Analytics Framework, etc.)
‚Ä¢ Knowledge of business process management best practices & business intelligence concepts
‚Ä¢ Ability to dive into technical details and design analytics solutions to meet business needs
‚Ä¢ Experience with (one or more) BI/reporting tools and data storage platforms
‚Ä¢ Experience with handling multiple projects in an open environment
‚Ä¢ Exceptional verbal, written communication and presentation skills
‚Ä¢ Experience in supporting and working with cross-functional teams in a dynamic environment.

Why do you have to join US?

‚Ä¢ Because SaaS and Pharma are hot spots and great experiences for you
‚Ä¢ Because you want to work in a global environment with the potential for an international career, supported by an experienced leadership team
‚Ä¢ Because you have ambitions and are not afraid of taking more responsibilities
‚Ä¢ Because you want to see the impact your job has on your team & company
Contact the job poster
Ga√´l B√©ron
CTO at POC Pharma ‚Ä¢ We help Pharma Companies digitize their Go-to-Market
Job Poster Location
Singapore
Send InMail"
3009062358|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|DIGI-TEXX|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
M√¥ t·∫£ c√¥ng vi·ªác * In this role, you will:- Together with other team members, design & implement base system for Big Data, including but not limited to: HDFS, YARN, Map-Reduce, Spark, etc.- Operate Big Data System, ensure system reliability and create the base for SysOps/MLOps.- Operate & manage, ensure the reliability of DBMSs including MongoDB, PostgreSQL, MySQL, Redis, Elasticsearch, etc.- Design and operate backup methods and plan; ensure the usability of backups following the backup policy.Backup & ensuring the usability of backups following the backup policy.- Monitor the measurements of DBMS performance and make sure to keep them following SLA. Propose for justification and new SLA based on the requirements system and production.- Support developers on optimizing queries, data structure, and the usage of DBMSs.- Report assigned tasks to Line Manager or Head of Department* Our benefits:- Attractive salary, commensurate with capacity- Open and honest company.- Annual bonus, target bonus.- Premium healthcare package.- Company‚Äôs labor policy completely pursuant to Vietnamese labor legislation.- Full weekend off, traditional vacation off- Many opportunities for personal and professional growth.- Exciting leisure: sport events, company trips and parties,‚Ä¶- Friendly and professional working European environment.- Trained in job-related skills- Flexible working time Kinh nghi·ªám / K·ªπ nƒÉng chi ti·∫øt - Degrees in Computer Science/Mathematic or related majors or certificates related to Network, System, Database- Experience in Big Data System (HDFS/YARN/Map-Reduce/Spark, etc.)- Experience related to System Administration & Database System Administration- Can write and optimize complex queries- Have experience in programming and good programing mindset (any languages)- Have experience with Agile methodology- Good English is preferred"
2949867472|Shopee Xpress - Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Shopee|Full-time ¬∑ Entry level|"About the job
Jobs Description
Work closely with Business Intelligence Analysts to turn data into information that can be used to make sound business decisions
Responsible for the full life cycle development, implementation, support of self-serve data products
Design data mart or intermediate table structures and populate those structures with data from internal and external sources
Improve business processes by enabling automated data collection and generation
Liaise with regional Data Engineering team and Business Intelligence team on data availability and retrieval
Review and grant user access right as per data privacy policy
Review and automate manual processes if possible

Requirement
Bachelor's Degree in Computer Science or Information Systems or any related field
3+ years of relevant working experience in Data Engineering
Knowledge of Database Architecture and Design
Proficient in SQL and Python
Ability to work in a fast-paced agile development environment"
2873551726|Data Engineer|Hanoi, Hanoi, Vietnam|VinBigData|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
M√î T·∫¢ C√îNG VI·ªÜC Job OverviewWe are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company‚Äôs data architecture to support our next generation of products and data initiatives.Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, AWS ‚Äòbig data‚Äô technologies and on-premse data-center.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems. Y√äU C·∫¶U C√îNG VI·ªÜC Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‚Äòbig data‚Äô data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.Strong analytic skills related to working with unstructured datasets.Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‚Äòbig data‚Äô data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 2+ years of experience in a Data Engineer role, who has attained a
Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:o Experience with big data tools: Hadoop, Spark, Kafka, Flink, etc.o Experience with relational SQL and NoSQL databases, including MySQL, Oracle, Postgres.o Experience with data pipeline and workflow management tools: Airflow, NiFi.o Experience with AWS cloud services: EC2, EMR, RDSo Experience with stream-processing systems: Flink, Spark-Streaming, etc.o Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc. ƒê·ªäA ƒêI·ªÇM L√ÄM VI·ªÜC Century Tower, Minh Khai, Vinhomes Times City, Vinh Tuy, Hai B√† Tr∆∞ng District, Hanoi, Vietnam"
2985484238|Data Engineer (Web Scraping)|Ho Chi Minh City, Ho Chi Minh City, Vietnam|ekino Vietnam|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
Job description As a Web Scraping focused Data Engineer, your primary responsibility is using specialized software and web crawling tools to extract data from websites, adding insights for businesses to make valuable decisions. You will ensure and manage data accuracy and quality via owning the creation process of scraping web content. Build and manage targeted web scrapers, including but not limited to writing scrapers and troubleshooting issues of these tools; Manage the pipeline and storage for the extracted data defined by business; Handle challenging tasks related to the credits of the pictures/content; Improve crawl/ scrape analysis, reports and data management; Analyze and deliver obtained data in the required output format. Desired Skills and Experience Bachelor's Degree in Computer Science or a related field Understand Web Scraping activities (Scrapy, pandas, SQL, BeautifulSoup, etc) Excellent verbal and written communication skills in English (French is a plus) Hands on Python, Linux/UNIX, HTTP, HTML, Javascript and Networking protocols Have a firm knowledge of Web page structures, data pipeline engineering Self-starter, customer-focused, detail-oriented Strong system thinking and problem-solving skills Nice-to-have skills: Experience with system monitoring/administration tools Experience with version control, open-source practices, and code review Experience with applications designed to display archived web content"
2964690729|Software/ Data Engineer|Ho Chi Minh City, Vietnam|Techcombank (TCB)|Full-time ¬∑ Mid-Senior level|"About the job
M·ª•c ti√™u / Objective
- The job holder is responsible for developing programs, algorithms and automated processes to cleanse,
integrate and evaluate large datasets from disparate sources and implement complex business logic as
needed with the available data processing tools.
- The job holder will be responsible for helping build a reliable, sustainable and scalable data processing
platform, working with other tribe members to support data pipelines, convert models to machine learning
codes and recommend Big Data reporting and visualization applications.
Tr√°ch nhi·ªám ch√≠nh / Key accountabilities
A. Data Architecture
Deliver functionality required for business and data analysts, data scientists and other business roles to
advance the overall analytic performance and strategy of the bank
Assist in building best practices and strategies for data infrastructure to fulfill data analytic and utilization
needs of the business with emerging latest technologies and capabilities.
- Collaborate with relevant teams on opportunities to manage data and provide solutions for complex data
feeds within the bank.
- Maintain data integration processes into the data platform by building data pipelines and align with
business representatives and business information needs.
- Review internal and external business and product requirements for data operations and activity and
suggests changes and upgrades to systems and storage to accommodate ongoing needs.
B. Data Integration
- Obtain and integrate data and information from various sources into the firm‚Äôs platforms, solutions and
statistical models.
- Collaborate with Data Scientists to understand data requirements and create re-usable data assets to
enable data scientists to build and deploy machine learning models faster.
- Write scripts and ingest raw data to build and maintain optimized data pipelines and ETL solutions as
business support tools in providing analysis.
- Ensure data assets are organized and stored in an efficient way so that information is easy to access and
retrieve.
Y√™u c·∫ßu/ Requirements
B·∫±ng c·∫•p, Kinh nghi·ªám/ Qualification and experiences
- Bachelor or Master‚Äôs degree in Statistics, Mathematics, Quantitative Analysis, Computer Science,
Software Engineering or Information Technology
- 2 to 4 years of relevant experience with developing, debugging, scripting and employing big data
technologies (e.g. Hadoop, Spark, Flink, Kafka, Arrow, Tableau), database technologies (e.g.
SQL, NoSQL, Graph databases), and programming languages (e.g. Python, R, Scala, Java, Rust,
Kotlin) with preference towards functional/trait oriented
- English proficiency requirements are pursuant to Techcombank's policy
- Experience in designing and building dimensional data models, ETL processes, applied data
warehouse concepts and methodologies, optimized data pipelines and assisted the architect as
needed
- Experience monitoring complex system and solving data and systems issues having a consistent
and algorithmic approach to resolving them
- Deep understanding of Information Security principles to ensure compliant handling and
management of all data
- Experience working in Agile teams to support digital transformation projects, having a clear
understanding of Agile principles, practices and Scrum methodologies
- Has some know-how and partial scripting and coding experience to set up, configure & maintain
a machine learning model development environment
- Some experience architecting, coding and delivering high performance micro services and/or
recommenders delivering recommendations to a large user-base
Contact the job poster
Nguyet Tran ‚òÜ 2nd
Passionate about helping people and companies achieve their dreams!
Job Poster Location
Vietnam
Send InMail"
2969582998|Data Engineer|Ho Chi Minh City, Vietnam|Propzy|Full-time|"About the job
DUTIES & RESPONSIBILITIES:

Analyze and understand business requirements and data models.
Develop data pipelines/processing/storages/consuming to align with the business requirements and data models.
Develop reports, applications, and data queries to display data insights with high performance and within the scheduled time.
Document technical designs, reports, data queries, data models.
Continue to provide improvements and optimizations on data pipelines/processing/storages/consumption.
DESIRED SKILLS & EXPERIENCE
Bachelor's degree in mathematics, statistics, computer science or related field.
Strong math and analytical skills are essential to complete job requirements successfully.
At least 2 years in working as a Data Engineer.
Experienced with data ingestion/storage such as AWS Kinesis, MySQL, AWS S3, AWS DynamoDB, AWS Redshift, etc.
Experienced with data querying such as AWS Glue, Airflow, etc.
Experienced with data processing such as EMR, Spark, Lambda, etc.
Experienced with data-lake, data warehouse, data mart.
Experienced with data querying such as Athena, SQL, etc.
Experienced with BI/DA tools such as AWS Quicksights, PowerBI, Tableau, etc.
Experienced with Programing languages: Python, Scalar, Java, etc.
Ability to work independently, proactive problem solver.
Ability to communicate effectively in English both written and verbally.
Experienced with PropTech data is a big plus.

Contact the job poster
Nh∆∞ L√¢m 2nd
IT RECRUITER
Job Poster Location
Vietnam
Send InMail"
2853334486|||||
2932802000|Data Engineer (Remote)|APAC|Virtually Human|Full-time ¬∑ Entry level|"About the job
Virtually Human Studios (VHS) is exploring the fringes of entertainment delivery for the next generation. Founded in 2019, Virtually Human is a gaming and entertainment blockchain startup and proud creators of the viral NFT gaming platform of its time ZED RUN.

VHS has partnered with some of the most innovative and leading gaming and sports giants around the world, including Unikrn and Atari just to name a few. VHS is a fully remote-first organisation focused on building a high performance culture.

See what we have planned this year - Virtually Human Studio Product Roadmap 2022

We are looking for a certified Data Engineer to join and contribute to the delivery of our Blockchain entertainment product, working within a medium size team and supported by the CTO.

You have at least 3 years of experience working in a similar position, ideally within blockchain. You are a team player who can get up to speed quickly, and can influence and motivate them for alignment with key business objectives.

You have the flexibility required to work with a globally distributed development team across multiple time zones along with a good internet connection at all times to allow for easy facilitation of group video calls.

Requirements
Proven ability to take raw data and transform it in ways to best capture its value and insights;
Experience building and optimising ‚Äòbig data‚Äô data pipelines, architectures and data sets;
Strong experience writing SQL queries for analysing data and transforming it according to business requirements;
Experience with big data tools: Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and MongoDB;
Experience with cloud services such as Redshift and BigQuery;
Experience with building and managing data warehouses and data lakes;
Experience with data pipeline and workflow management tools: dbt, Luigi, Airflow, etc;
Experience with both batch and real time data processing;
Demonstrated experience using Python, GIT, SQL, Visualisation Tools, Data Notebooks (e.g. jupyter) and Linux;
Google cloud experience is desirable but not essential.

Why Work For VHS?
A supportive friendly environment of dedicated and passionate co-workers
Remote First - Flexible work from home arrangement
Exposure to the new aged world of Blockchain and NFT‚Äôs
Unlimited leave
Maternity/Paternity Leave
$1000 USD Remote work allowance
Brand new work laptop
Employee referral program ($4000 USD for each employee who is successfully referred to the company)

To be considered for this position please provide a copy of your resume and cover letter and/or digital video resume outlining and addressing the selection criteria.

VHS values transparency, accountability, support, simplicity, and courage. We look forward to working with someone who embraces these traits and our start-up culture. Join VHS today and take the next step in your career.

Find out more about us and what we value - About Virtually Human

VHS is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability"
2992724782|Data Engineer, KMS Solutions(Ha Noi)|Hanoi, Hanoi, Vietnam|KMS Solutions|Full-time ¬∑ Mid-Senior level|"About the job
As a key member of our Consulting team within Service Delivery, the position will be the data engineer that helps guide our customers through their data product implementation. Working directly with customers, a team of data product managers, solution architects and engineers drive requirements gathering, the project design, and the QA process. You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and will data analytics to build dashboard and business data insight.

Key responsibilities

In collaboration with architect, implement data solutions that solve business problems
Design conceptual, logical and physical data analytics solutions
Implement effective and scalable end-to-end data pipeline solutions
Script Optimized SQL queries for scale
Possess a comprehensive understanding of products and services

Qualifications

At least 2+ years of work experience
Experience in SQL scripting.
Understanding of dimensional and normalized database models
Understanding Extract, Transform, and Load (ETL)
Having a programming mentality and problem-solving skills
Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry
Interested in data business analysis to build metrics and reports
Understanding of the concept of cloud-based SaaS platforms
Experience with the programming language, Scripting language, REST APIs is a plus
Be flexible on technology

Additional Information

Thinking of joining KMS Solutions? Yes, you deserve it!

Progressive Career Development

Role-based training foundation
Active role at the global client-side
Continuous professional certification
Simple goals - achievable success
Attractive compensation

Up to 15 months salary/year
Performance review twice a year
Premium healthcare insurance
18+ paid leave/year
Engagement workplace

Flexi mode, modern work environment
Well-being centric
Impactful community organization

Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Join us and let yourself explore other fantastic things!"
2977284236|Data Engineer|Ho Chi Minh City Metropolitan Area|Aloha Consulting Group|Full-time ¬∑ Mid-Senior level|"About the job
Our client is leading MNC hedge fund and quantitative investment management firm who is looking for top-notch talents to join their firm.
Design, implement, and support Data Models, ETLs that provide structured and timely access to large datasets
Collaborate with developers, data scientists and researchers to implement the data transformations for large datasets
Develop data processing pipelines
Work with other internal development teams to integrate with other company systems in order to provide end-to-end functionality
Work with infrastructure team to manage and deploy internal business applications on supported workload automation frameworks
Requirements
At least 3 years of experience in Data Engineering/ Developer
Major/Minor studies (BEng, MSc and PhD) from a top university in a field, such as: Mathematics, Computer Science, Physics, Electrical engineering or equivalent
Expert knowledge of design, engineering, and operations of market data infrastructures
Cloud/AWS experience
Programming skills ‚Äì C++ and Python predominantly, but newer skills welcomed too.
Experience in cloud computing (AWS) and big data (Spark) is a plus
Highly skilled and analytical problem solver with logical thought process and quantitative aptitude
Strong communication skills in English ‚Äì including both written and verbal As a plus:
Strong record of research achievement ‚Äì examples include scientific publications, conference presentations, grants or industry awards
Benefits
Performance bonus: 2-4 months"
2996206099|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|AdStart Media|Full-time ¬∑ Entry level|"About the job
We are offering an immediate opening for an experienced Data Engineer based in our Ho Chi Minh office. As part of a dedicatedly agile team, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection.

You should have excellent communication skills to work with product owners to understand data requirements, and to build ETL procedures to ingest the data into the data lake. You should be an expert at designing, implementing, and operating stable, scalable, low-cost solutions to flow data from production systems into the data lake.

If you are self-directed and comfortable supporting the data needs of multiple teams, systems and products, we would like to meet you.

Your Main Duties
Manage and expand our existing AWS big data infrastructure
Build ETL processes within the AWS environment
Perform data extraction, cleaning, transformation, and flow
Design, build, launch and maintain efficient and reliable large-scale batch and real-time data pipelines with data processing frameworks
Integrate and collate data silos in a manner which is scalable, compliant and cost efficient
YOUR ATTRIBUTES: *
English proficiency is a must
2+ years of experience in designing and developing solutions using AWS services such as Lambda, Glue, Athena, etc.
Good knowledge of programming Python is a must
Hands on working knowledge of Relational / NoSQL databases such as MySQL, PostgreSQL
Experience with DB administration in a production environment; performance/scaling concepts and tuning best practices
Experience working in agile development teams using Scrum methodologies
Able to work autonomously and within a team
Must be organized, efficient, and have good attention to details
Must be able to show initiative to get a job done with little / no supervision
What We Offer
English speaking multi-cultural environment
Flexible working time
Competitive salary and benefits
Premium medical insurance package (option to extend to family members)
Annual employee‚Äôs health-check
Generous annual leave days and paid sick leave days
Bi-Annual Performance Review
English classes / Toastmasters Clubs
Various trainings on soft-skills and best practices
Annual company trips, year end party and periodic team-building activities"
2996201807|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|AdStart Media|Full-time ¬∑ Entry level|"About the job
We are offering an immediate opening for an experienced Data Engineer based in our Ho Chi Minh office. As part of a dedicatedly agile team, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection.

You should have excellent communication skills to work with product owners to understand data requirements, and to build ETL procedures to ingest the data into the data lake. You should be an expert at designing, implementing, and operating stable, scalable, low-cost solutions to flow data from production systems into the data lake.

If you are self-directed and comfortable supporting the data needs of multiple teams, systems and products, we would like to meet you.

Your Main Duties
Manage and expand our existing AWS big data infrastructure
Build ETL processes within the AWS environment
Perform data extraction, cleaning, transformation, and flow
Design, build, launch and maintain efficient and reliable large-scale batch and real-time data pipelines with data processing frameworks
Integrate and collate data silos in a manner which is scalable, compliant and cost efficient
YOUR ATTRIBUTES: *
English proficiency is a must
2+ years of experience in designing and developing solutions using AWS services such as Lambda, Glue, Athena, etc.
Good knowledge of programming Python is a must
Hands on working knowledge of Relational / NoSQL databases such as MySQL, PostgreSQL
Experience with DB administration in a production environment; performance/scaling concepts and tuning best practices
Experience working in agile development teams using Scrum methodologies
Able to work autonomously and within a team
Must be organized, efficient, and have good attention to details
Must be able to show initiative to get a job done with little / no supervision
What We Offer
English speaking multi-cultural environment
Flexible working time
Competitive salary and benefits
Premium medical insurance package (option to extend to family members)
Annual employee‚Äôs health-check
Generous annual leave days and paid sick leave days
Bi-Annual Performance Review
English classes / Toastmasters Clubs
Various trainings on soft-skills and best practices
Annual company trips, year end party and periodic team-building activities"
2981318582|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|URBOX - C√îNG TY C·ªî PH·∫¶N TI·∫æP TH·ªä S·ªê T√î QU√Ä|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
M√î T·∫¢ C√îNG VI·ªÜC Design/ maintain/develop the ETL process to complete data migration from another platform to our cloud DWH ( Build on AWS redshift) Develop procedures & scripts to optimize the ETL process Design, structure & develop data marts that support BI & analytics purpose Work with internal stakeholders to generate data mapping document, data dictionary Coordinate with internal stakeholders to ensure data quality & improve data flow by business operation Assist in technical direction for internal data model Other tasks as an assignment Y√äU C·∫¶U C√îNG VI·ªÜC 2+ years experience as Data Engineer, working with databases, coding to intake, clean, transforming data Proficient working with

SQL Server/MySQL/MongoDB/Cloud AWS database Proficient use ETL tool as SSDT/Airflow Proficient python/Ubuntu Experience developing automation tool to automate data migration Proactive, adaptable, detail-oriented & well organize Ability to work under pressure in a fast-paced environment"
2980163156|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|AdStart Media Pte. Ltd|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
We are offering an immediate opening for an experienced Data Engineer based in our Ho Chi Minh office. As part of a dedicatedly agile team, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection. You should have excellent communication skills to work with product owners to understand data requirements, and to build ETL procedures to ingest the data into the data lake. You should be an expert at designing, implementing, and operating stable, scalable, low-cost solutions to flow data from production systems into the data lake. If you are self-directed and comfortable supporting the data needs of multiple teams, systems and products, we would like to meet you.

YOUR MAIN DUTIES: Manage and expand our existing AWS big data infrastructure Build ETL processes within the AWS environment Perform data extraction, cleaning, transformation, and flow Design, build, launch and maintain efficient and reliable large-scale batch and real-time data pipelines with data processing frameworks Integrate and collate data silos in a manner which is scalable, compliant and cost efficient

YOUR ATTRIBUTES: English proficiency is a must 2+ years of experience in designing and developing solutions using AWS services such as Lambda, Glue, Athena, etc. Good knowledge of programming Python is a must Hands on working knowledge of Relational / NoSQL databases such as MySQL, PostgreSQL Experience with DB administration in a production environment; performance/scaling concepts and tuning best practices Experience working in agile development teams using Scrum methodologies Able to work autonomously and within a team Must be organized, efficient, and have good attention to details Must be able to show initiative to get a job done with little / no supervision

WHAT WE OFFER: English speaking multi-cultural environment Flexible working time Competitive salary and benefits Premium medical insurance package (option to extend to family members) Annual employee‚Äôs health-check Generous annual leave days and paid sick leave days Bi-Annual Performance Review English classes / Toastmasters Clubs Various trainings on soft-skills and best practices Annual company trips, year end party and periodic team-building activities"
2961278230|Data Engineer, KMS Solutions|Qu√¢n Phuong Ha Trai, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Entry level|"About the job
This job is sourced from a job board. Learn more
As a key member of our Consulting team within Service Delivery, the position will be the data engineer that helps guide our customers through their data product implementation. Working directly with customers, a team of data product managers, solution architects and engineers drive requirements gathering, the project design, and the QA process. You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and will data analytics to build dashboard and business data insight. Key responsibilities * In collaboration with architect, implement data solutions that solve business problems * Design conceptual, logical and physical data analytics solutions * Implement effective and scalable end-to-end data pipeline solutions * Script Optimized SQL queries for scale * Possess a comprehensive understanding of products and services * At least 2+ years of work experience * Experience in SQL scripting. * Understanding of dimensional and normalized database models * Understanding Extract, Transform, and Load (ETL) * Having a programming mentality and problem-solving skills * Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry * Interested in data business analysis to build metrics and reports * Understanding of the concept of cloud-based SaaS platforms * Experience with the programming language, Scripting language, REST APIs is a plus * Be flexible on technology Thinking of joining KMS Solutions? Yes, you deserve it! Progressive Career Development * Role-based training foundation * Active role at the global client-side * Continuous professional certification * Simple goals - achievable success Attractive compensation * Up to 15 months salary/year * Performance review twice a year * Premium healthcare insurance * 18+ paid leave/year Engagement workplace * Flexi mode, modern work environment * Well-being centric Impactful community organization * Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,... /Join us and let yourself explore other fantastic things!/"
2995108608|Data Engineer|Ho Chi Minh City, Vietnam|SoftwareONE|Full-time ¬∑ Entry level|"About the job
Job Function
Cloud & Software Services
Why SoftwareONE?
SoftwareONE is a leading global provider of end-to-end software and cloud technology solutions , headquartered in Switzerland . With an IP and technology-driven services portfolio , it enables companies to holistically develop and implement their commercial, technology and digital transformation strategies. This is achieved by moderniz ing applications and migrate critical workloads on public clouds , while simultaneously managing and optimizing the related software and cloud assets and licensing. SoftwareONE‚Äôs offerings are connected by PyraCloud , its proprietary digital platform, which provides customers with data-driven, actionable intelligence . With around 7,700 employees and sales and service delivery capabilities in 90 countries, SoftwareONE provides around 65,000 business customers with software and cloud solutions from over 7,500 publishers . SoftwareONE‚Äôs shares (SWON) are listed on SIX Swiss Exchange. For more information, please visit https://www.softwareone.com/e .
SoftwareONE Holding AG, Riedenmatt 4, CH-6370 Stans
The role
Responsibilities
¬∑ Analyze and organize raw data.
¬∑ Build data systems and pipelines.
¬∑ Evaluate business needs and objectives.
¬∑ Interpret trends and patterns.
¬∑ Conduct complex data analysis and report on results
¬∑ Prepare data for prescriptive and predictive modeling.
¬∑ Build algorithms and prototypes.
¬∑ Combine raw information from different sources
¬∑ Explore ways to enhance data quality and reliability.
¬∑ Identify opportunities for data acquisition.
¬∑ Develop analytical tools and programs.
¬∑ Collaborate with data scientists and architects on several projects.
Requirements
What we need to see from you
¬∑ Previous experience as a data engineer or in a similar role (3+ years)
¬∑ Technical expertise with data models, data mining, and segmentation techniques.
¬∑ Knowledge of programming languages (e.g. Java and Python).
¬∑ Hands-on experience with SQL database design.
¬∑ Knowledge of Azure Data Platform is a plus.
¬∑ Knowledge of Apache Spark, Apache Kafka, Databricks is a plus.
¬∑ Great numerical and analytical skills.
¬∑ Degree in Computer Science, IT, or similar field; a Master‚Äôs is a plus.
What You Should Really Know About Us.
Strip away everything. Strip away our brand, strip away our buildings, strip away our offices. What are we left with? Our people. This is what makes SoftwareONE successful.
Passionate people who live and breathe our values every day, who delight our customers, every day, and who go above and beyond, every day. Our culture is unique, and I believe that having the right people, and empowering them to succeed, is the absolute key to our success.
Patrick Winter, Founder.
What We Expect From Our Employees
Success at SoftwareONE is not defined by what you do for yourself, but by what you deliver for our customers, the business and for the employees around you. SoftwareONE employees are energized, agile and are laser focused on delivering world class Customer Satisfaction and results. Our leaders motivate and inspire their teams and provide a working environment that delivers incredible levels of Employee Satisfaction. We are Humble, have a very high degree of Integrity and are simply not interested in politics.
Our leaders operate with a high levels of Discipline but are able to work at Speed manage change in a global economy.
‚ÄúSoftwareONE is an equal opportunity employer. With employee satisfaction as one of our core values, we are passionate about diversity and are committed to creating an inclusive environment for all of our employees. We want every employee to have the greatest experience of their career.‚Äù
Contact the job poster
Neelam Kedare
Onsite Talent Acquisition Partner@SoftwareONE APAC & ANZ at WhiteCrow Research
Job Poster Location
Mumbai, Maharashtra, India
Send InMail"
2978420134|Senior Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|GLOBAL FASHION GROUP SGP SERVICES PTE LTD.|Full-time ¬∑ Mid-Senior level|"About the job
Global Fashion Group (GFG) is the leading fashion and lifestyle retail destination in Asia Pacific, Latin America and CIS. We connect over 10,000 global, local and own brands to a market of more than one billion consumers through four established e-commerce platforms: THE ICONIC, ZALORA, dafiti and lamoda. Through an inspiring and seamless customer experience enabled by our own technology ecosystem and operational infrastructure, we are dedicated to being the #1 fashion and lifestyle destination in our markets. With 17 offices and 10 fulfilment centres across four continents, GFG proudly employs a dynamic and diverse team with deep local knowledge and expertise. In 2019, GFG delivered more than 34 million orders to over 13 million active customers.

About The Function

At GFG, technology is core to long-term success and is a crucial enabler of a great customer experience. We are a mix of experts in fashion, logistics, data analytics, marketing and design, guided by business consultants and tech geniuses - everyone contributes to the success of GFG.

We are looking for a Senior Data Engineer to join our team:

About The Role
Work daily to scale machine learning problems. For this purpose, you are expected to be involved in the process of collecting, storing, processing, and analyzing data generated from our database, in addition to joining our data scientists in the design of machine learning models.
Work in a diverse, international setting with teammates who are experts in various topics. We often conduct workshops to improve our individual skill sets, and to improve our workflow as a team. The role is based in our Vietnam office.

THE IMPACT YOU‚ÄôLL MAKE

Data at GFG never stops growing and the team also never stops learning, innovating and expanding so that we can bring in or build the latest and best tools and technologies. In this role, you will be able to create strategic data models, develop and maintain data architecture used to power high-impact business initiatives that contribute to the overall growth and strategy for GFG.

What Will You Bring To The Team
Bachelor or Master degree in Computer Science or a related technical discipline

Be familiar with:
Data structures & algorithms
Data modelling
Basic machine learning algorithms
Following languages: SQL, Python, R, Java/Scala
Any of the following databases: MySQL, PostgreSQL, MongoDB, HBase, Cassandra, Redshift
Cloud technologies: AWS, GCP (BigQuery)
Be knowledgeable in:
Object oriented design and design patterns
Large-scale distributed systems
Hadoop, Spark and Pandas or similar processing engines
Jupyter Notebook or Zeppelin
Apache Airflow, Apache Superset
Good to have:
Knowledge of data visualization
Good background in statistics
Knowledge in data analysis, data mining, or machine learning
Experience working with big data

What We Offer You
The unique opportunity to have a serious impact on a growing organisation;
A dynamic working environment shaping the face of fashion e-commerce in growth markets
Significant career growth opportunities in a fast-growing business, gain working exposure in the 20+ countries across the group
Work closely with a global talent pool with international mindset

Apply today and join GFG in this exciting role shaping the face of fashion e-commerce!

Global Fashion Group embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements.

Apply today and join GFG in this exciting role shaping the face of fashion e-commerce!

Global Fashion Group embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements.

Powered by JazzHR

QlH4kC9ERn"
2955979461|Data Engineer|Ho Chi Minh City, Vietnam|Flash Grocery Viet Nam|Full-time|"About the job
About Us
BeepBeep‚Äôs here to make your life more convenient with quality groceries, essentials and so much more delivered to your doorstep in minutes. We are driven by the communities we serve to provide quality, speed & variety, and with this we aim to redefine what grocery shopping means to you and ultimately change your lives for the better. Whether it‚Äôs your favorite local baker, artisanal products or fresh produce, we will bring together unique selections from various partners to satisfy every type of shopper out there. Convenience & selections in minutes. We went live in Singapore from Nov 2021, with cool expansion plans in the pipeline.
We have an exhilarating journey lined up - get on board now to change the grocery delivery game in Asia with us!
The Role
As we are expanding rapidly and ambitiously to reach our milestones, we are looking for a Data Engineer who is self-leading, confident with great experience in retail and e-commerce industry to be one of the foundations of our Data Analytics team. This person is in charge of technical challenges along with managing members of a fast-growing and diverse team.
Responsibilities
Work closely with the developer team to help build up data solutions for BeepBeep.
Review existing system architecture and design, evaluate, implement and maintain the data infrastructure of the company for future stability.
Obtain strategically and integrate data and information from various sources such as API, flat files, databases ‚Ä¶ into the firm's platforms, solutions and statistical models.
Analyze the need of data analytics for stakeholders and provide a proper data pipeline solution which is measurable and scalable. Maintain and improve data integrity/ quality.
Improve and optimize the workloads, processes to ensure that performance levels can support continuous accurate, reliable, and timely delivery of data products.
Provide suitable training for the team.
Requirements
What are needed for the job:
Bachelor's or advanced degree in IT/ Statistics/ Math or related fields.
More than 3 years of experience in data technology.
Knowledgeable and experience in both relational databases and NoSQL databases (eg: MongoDB).
Experience in ETL tools or data pipeline languages such as Python, Scala, cloud-based infrastructure (eg: AWS, GCP, Azure‚Ä¶).
Experience with visualization tools such as Tableau, PowerBI.
Knowledge in business analysis and data modeling.
Fluent in English speaking/ writing with excellent interpersonal skills.
Team player with good management skills.
What are great to have:
Familiar with software development process and culture.
Experience with Big data and data warehouse concepts and methodologies
Experience with third party libraries and APIs.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc
Benefits and Perks
Sharpen your skills with your own-built dream team.
Competitive remuneration package.
Young, dynamic startup environment with diverse teams in Asia (Singapore, Thailand, Malaysia‚Ä¶).
Health Insurance and 15 annual paid days off.
Snacks, healthy food provided.
Apply Now!
If you are interested in the position, please reach us out at
Email:careers.vn@beepbeepmart.com,
Mobile Phone: 0934 74 5885
Working place: 26 Huynh Khuong Ninh, Districe 1, HCM City
Contact the job poster
Anh Tran
Recruitment Specialist at Flash Grocery Viet Nam
Job Poster Location
Ho Chi Minh City, Vietnam
Send InMail"
3012680248|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|SoBanHang|Full-time ¬∑ Mid-Senior level|"About the job
Finan is a Singapore - registered technology startup and the owner of the SoBanHang application.

Founded by management executives from leading e-commerce businesses in Vietnam, including Lazada, Zalora (Rocket Internet), Topica Edtech Group, OneMountGroup... SoBanHang enables nano and micro-businesses to manage cash flow better with digital bookkeeping apps and increase sales through a hyperlocal online storefront.

After 6 months of experiencing hypergrowth, SoBanHang is the market leader and doing the mission of helping thousands of small businesses go online

So Ban Hang has been invested by leading investment funds such as FFEBE Ventures, Class 5, Kevin P.Ryan ‚Äì founder of Gilt Groupe, Business Insider and MongoDB.

By 2025, SoBanHang will become the trusted partner of 1 million businesses, helping them serve 100 million customers and generate $100 billion in sales.

With that hyper-growth, we look for talented teammates to join our rocketship as Senior Data Engineer. This plays a critical role in building a solid tech foundation for hundreds of millions of users.

Job Description
Work with data to solve business problems, building and maintaining the infrastructure to answer questions and improve processes.
Help streamline our data science workflows, adding value to our product offering and building out our customer lifecycle and retention models.
Work closely with the data science and business intelligence teams to develop data models and pipelines for research, reporting, and machine learning.
Be an advocate for best practices and continued learning.
Develop API using Python framework for internal transfer data.
Job Requirements
3 or more years of experience with Python, SQL, and data visualization/exploration tools
Knowledge of programming languages like SQL Baisc, Postgres, BigQuery, and Python.
Familiarity with the AWS ecosystem specifically Kubernetes Engine.
Technical proficiency regarding database design development, data models, techniques for data mining, and segmentation.
Experience in handling programming ETL frameworks, databases.
Problem-solving, teamwork, verbal and written communication skills.
Comfort working in a dynamic, research-oriented team with concurrent projects.
Our Benefits
Create impactful technology products to bring value to society, especially to those who are underserved.
Work with tech-giant partners in Vietnam and the region: Vietjet, Savico, Facebook, Google‚Ä¶ and have access to the world's leading investment funds.
Young, dynamic start-up environment with knowledgeable and experienced leaders
Hone your skills through the new challenges, have your say in contribution towards the common goals.
Competitive remuneration package.
Have opportunities to become a co-founding member with an attractive ESOP policy.
Cool office, work time & location flexibility, other perks include snacks, coffee, and healthy food provided daily...
How To Apply

Please send your CV to our email: hrtalent@sobanhang.com. Subject: Your Name_Apply for [Position] (Example: Nguyen Van A_Apply for Data Engineer)

More information about us and other career opportunities: https://join.sobanhang.com/

Recruitment Process

Suitable applications will be contacted within 3 days of submission. Candidates who pass Interview 1, Interview 2 will be notified within 3 working days."
2956059310|Senior Data Engineer|Hanoi, Hanoi, Vietnam|F88|Full-time ¬∑ Mid-Senior level|"About the job
This job is sourced from a job board. Learn more
M√î T·∫¢ C√îNG VI·ªÜC
Participate in the data lake project as a member to design ETL and data pipeline to load data from local data sources to cloud databases.
Continues design and maintain data lake, data marts on cloud ecosystems and use ETL tools to manage all ETL flows.
Work with data analysts to enrich data lake, data marts and to fulfill data requirements from business teams.
In aliasing with data scientist to create data pipeline and to push machine learning pipeline to production.
Document data mapping, metadata of developed data ecosystem to ensure consistency and transparency of data and business logic. Team development:
Mentor and coach junior data engineer into competent senior data engineer
Identify and encourage areas of growth and improvement within the team Self-development:
Willing to explore new tools and skillsets in the market or industries to apply to the team and the company. Y√äU C·∫¶U C√îNG VI·ªÜC Must have:
A data driven and detail-oriented mindset.
3+ year experience as a data engineer.
2+ year experience of create ETL flow on relational databases, design data marts, data warehouse or data lake.
Expertise in setting up infrastructure for BI tools as well as related security and permission matters.
Comprehensive knowledge of relational databases such as MSSQL, PostgreSQL, MySQL/Oracle
Experience with one of the cloud platforms (AWS, Google Cloud, Azure).
Fluent with either Python or Java and comfortable using bash script.
Experience with one of the ETL, data pipeline management tools such as Airflow, Luigi or similar tools. Nice to have:
Batchelor degree in tech-related fields such as Computer Science, Software Engineering as well as data related fields Data Science, Managing Information Systems.
Experience with one of the data streaming platforms such as Kafka, Spark, Storm."
2990261472|Data Engineer (ETL, SQL, BI), based in Da Nang|ƒê√† Nang, Da Nang City, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Mid-Senior level|"About the job
You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and data analytics to build dashboards and business data insight.

Key responsibilities:

In collaboration with architect, implement data solutions that solve business problems
Design conceptual, logical and physical data models
Implement effective and scalable end-to-end data pipeline solutions
Optimize SQL queries for scale
Possess a comprehensive understanding of products and services

Qualifications

General requirements:

At least intermediate level of English level
Likely having 1+ years of experience depending on how fast of your learning and developing technical capability
Ability to obtain deep knowledge of the project technologies and work independently with minimum guidance
Ability to self-learn and adapt to new technologies quickly
Technical requirements:

Fluency in SQL and experience in Extract, Transform, and Load (ETL) development in SQL
Good knowledge and hands-on experience of using popular ETL tools such as: SSIS, Talend or Pentaho
Experience one of the following programming languages: Java, Javascript, C# or Groovy
Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry
Interested in data business analysis to build metrics and reports
Nice to have:

Experience with reporting and BI tools such as SSRS, PowerBI
Basic knowledge or experience of using cloud platform (AWS/Azure/GCP)
Familiar with Agile development methodologies (Scrum, XP, Kanban)

Additional Information



Working in one of the Best Places to Work in Vietnam
Building large-scale & global software products
Working & growing with Passionate & Talented Team
Diverse careers opportunities with Software Outsourcing, Software Product Development, IT Solutions & Consulting
Attractive Salary and Benefits
Two performance appraisals every year
Onsite opportunities: short-term and long-term assignments in North American (U.S, Canada), Europe, Asia.
Flexible working time
Various training on hot-trend technologies, best practices and soft skills
Premium healthcare insurance for you and your loved ones
Company trip, big annual year-end party every year, team building, etc.
Fitness & sport activities: football, tennis, table-tennis, badminton, yoga, swimming‚Ä¶
Joining community development activities: 1% Pledge, charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Free in-house entertainment facilities (foosball, ping pong, gym‚Ä¶), coffee, and snack (instant noodles, cookies, candies‚Ä¶)
And much more, join us and let yourself explore other fantastic things!"
2995738155|Data Engineer (Based in HCMC)|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Amanotes|Full-time|"About the job
Objectives

As an Amanotes‚Äô data engineer you will be leveraging on hundreds terabytes of data from 2+ billion users to create real business values through practical data solutions

What You Will Do

Design, build-up, implement, optimize and own the data/ETL pipeline with the rest of the Data Engineer team
Create and maintain the system pipeline and data documentation
Implement the system pipelines (Data Warehouse, Data Lake)
Engineer data platforms to automate/facilitate data related processes
Collaborate with business stakeholders, Data Analytics team, and AI/ML teams to build and implement deep learning models or algorithm focused data products (reusable assets) and solutions and deliver them right to the client
Work with external tech teams if any projects are needed Data Engineer team to join with

Qualifications

3-4+ years of hands-on experience deploying production quality code
Must have:
Experience with the following technologies: Python, Google Cloud Platform (included at least GCS, BigQuery), Airflow, DBT
Knowledge of JavaScript/ReactJS is a plus
Experience with Airflow or other pipeline orchestration software
Deep understanding of SQL and analytical Data Warehouses (BigQuery preferred)
Deep understanding, skills, and experience of deployment
Data Modelling for Data WarehousesData modeling skills - familiarity with major methodology i.e. Kimball, Inmon, Data Vault
Experience in working with Linux environment, Git
Experience and interest in Cloud platforms such as Google Platform, K8S, AWS, Azure or Databricks

Will be a plus

Experience in deployment data process CICD on Gitlab/Github/Bitbucket
Experience data-intensive projects in the AWS, GCP (AWS ecosystem, Hadoop ecosystem, K8S, GCS Data Lake)
Experience and knowledge in streaming ETL process are plus (Kafka, Apache Spark, Pub/Sub, ‚Ä¶)
Experience with BI/data visualization tools
Business mindset

About Amanotes

We are Amanotes! A fast-growing startup in the music-tech industry. We seek to delight people with interactive music experiences. Since 2014, 30+ music games and mobile applications were published under our name with over 2 billions downloads worldwide and 120+ million monthly active users. In 2019, we were proudly listed as the #1 mobile apps publisher from Southeast Asia, the #1 music games publisher in the world, and one of the top 20 mobile apps publishers in the world across all categories.

If you love to work in a creative environment with music all around the corner, come join us!

Explore our products on Google Play and iOS App Store such as Magic Tiles 3, Dancing Ballz, and Tiles Hop.

How To Apply?

Click the button or contact us at talents@amanotes.com."
2961319044|Senior Data Engineer, KMS Solutions|Qu√¢n Phuong Ha Trai, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
As a part of our Engineering team under KMS Solutions, the position is to research data tools to solve customers' requirements, provide solutions, estimation and implement tools, integration. * Work with clients and development team to understand business needs, estimate and develop data solutions for medium/large applications, tools, integration. * Design conceptual, logical and physical data models * Analyze and implement data solutions that solve business problems such as ETL, data warehouse, data cleansing, data integration, data visualization and reporting. * Lead small/medium development teams, ensure the understanding and compliance of offshore engineers to the business requirements, and technical direction Key requirements: * Good understanding of dimensional and normalized database models. * Fluency in SQL and experience in Extract, Transform, and Load (ETL). * Have experience or high understanding in data modelling. * Having a programming mentality and problem-solving skills * Be flexible on technology * Be able to research new tools, technologies quickly to solve client's need. * Can communicate with clients in English * Have the ability to evaluate and provide solutions for business cases/ issues * Have knowledge/experience in data quality, data integration, big data, data analytics, visualization Nice to have * Experience in the Business Intelligence (BI) / Data Warehousing (DW) industry * IT consulting skills and experience * Experience with cloud based SaaS platforms * Understanding DaaS (Data as a Service) * Experience working in professional services organization * Experience with columnar databases * Experience in coding script Thinking of joining KMS Solutions? Yes, you deserve it! Progressive Career Development * Role-based training foundation * Active role at the global client-side * Continuous professional certification * Simple goals - achievable success Attractive compensation * Up to 15 months salary/year * Performance review twice a year * Premium healthcare insurance * 18+ paid leave/year Engagement workplace * Flexi mode, modern work environment * Well-being centric Impactful community organization * Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,... /Join us and let yourself explore other fantastic things!/"
2976958411|Remote (Full-time) - Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Fetch Technology|$1,000/month - $2,500/month ¬∑ Full-time ¬∑ Mid-Senior level|"About the job
This job is sourced from a job board. Learn more
INTRODUCTION a. About Fetch: Fetch Technology Vietnam is a comprehensive global provider of HR and Talent Acquisition Services, focusing primarily in the technology fields. Founded in 2016, Fetch Technology Vietnam helps foreign companies of all types and sizes reach their potential by providing the talent and support to efficiently build and scale a high-performing, distributed workforce in Vietnam. Our mission is to offer Vietnam‚Äôs most talented technologists a platform to connect with some of the world‚Äôs leading tech companies and build their expertise on a global scale. Over 4 years, Fetch has built a good reputation and is trusted by many Vietnamese and foreign companies; And Fetch will continue its good work to bridge the divide between the World and the Vietnam Tech sector. b. About our client At this company, they believe that the future of healthcare is online and at home rather than in the clinic or in the pharmacy. They run two specialised digital health brands that make good healthcare accessible and affordable for all. Meet A and B ‚Äî the telemedicine platforms of the 21st century. About A & B A is Singapore‚Äôs first digital men‚Äôs health platform. It‚Äôs an inclusive, discreet space that provides treatment for stigmatized yet common conditions in sexual health, aesthetics, and overall well-being. B is a supportive and judgment-free platform that empowers women to take charge of their overall well-being, including everything from sexual health to aesthetics, hair and mental health.
RESPONSIBILITIES Analyze and organize raw data. Build data systems and pipelines. Evaluate business needs and objectives. Interpret trends and patterns. Conduct complex data analysis and report on results. Prepare data for prescriptive and predictive modeling. Build algorithms and prototypes. Combine raw information from different sources. Explore ways to enhance data quality and reliability. Identify opportunities for data acquisition. Develop analytical tools and programs.
REQUIREMENT Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field. From 2+ years experience, proven experience as a Data Engineer, Software Developer, or similar. Skill and knowledge in Python, Java/Scala, and SQL. Good understanding of data management- data lineage, metadata, data governance. Have an understanding of big data and big data platforms. Knowledge with Hadoop, S3/GCP, Spark, Jupyter, Docker, Kybernetes, Airflow, Kafka, Debezium, ElasticSearch,‚Ä¶ Knowledge of DevOps/ DevSecOps. Skills in task and time management, proactive problem solver. A knack for independence and group work. Scrupulous approach to duties. Capacity to successfully manage a pipeline of duties with minimal supervision. A Master's degree in a relevant field is advantageous.
WHY YOU‚ÄòLL LOVE WORKING HEREThey are made up of a bunch of creatives, entrepreneurs and tech-driven individuals. They‚Äôre far from the straightlaced corporates that you might imagine pulling the strings behind healthcare companies. They represent a new breed of healthcare companies, at the forefront of revolutionizing how people receive medical treatment. They were founded in the midst of COVID19, and in a matter of 6 months, they've grown to thousands of patients and hit over 7 figures in Annual Run Rate. They have also been featured on Augustman, FM91.3, Vulcan Post, e27, etc. They see themselves continuing to grow to all new heights and therefore are looking for someone with the skills to help us meet the technological demands that come with it. You will be joining a young startup in a growth phase and you will also be working remotely (they don't intend to get an office anytime soon). This means a couple of things: Flexible schedule. You will have a more flexible schedule but you will also have to be prepared to fight fires at odd hours when you least expect. Pull your own weight.There'll be no hand-holding and they expect you to pull your own weight like everyone else. Things get messy. There's no sugarcoating this. Things are unstructured and processes might be lacking. They're not where they want to be but they're getting there. You must be able to thrive in ambiguous situations (see point above). You are willing to put in the time to get the most out of any opportunity. Building a strong team is key in our ambition to thrive as a company, as co-workers, and as individuals. Therefore, they are looking for someone similarly dedicated and passionate, willing to put their best foot forward (go all stakes in) and take pride in what they do, because they do too. If you are interested in joining us at this point in our journey and are someone who enjoys sticking their hands in the dirt and putting in the work to see something grow, then you‚Äôre one of us."
2992173553|Senior Data Engineer, KMS Solutions|Ho Chi Minh City, Ho Chi Minh City, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
As a part of our Engineering team under KMS Solutions, the position is to design innovative data solution to solve customers' business challenges, to provide requirements, solutions, estimation and implement tools, integration. * Work with clients and development team to understand client business model & business needs, estimate and develop data solutions for medium/large data pipeline, integrate data tools to fit the client requirement. * Design conceptual, logical and physical data models * Analyze and implement data solutions that solve business problems such as ELT, data warehouse, data cleansing, data integration, data visualization and reporting. * Technical lead small/medium development teams, ensure the understanding and compliance of offshore engineers to the business requirements, and technical direction * Be the trusted technical consultant for clients Key requirements: * Good understanding of dimensional and normalized database models. * Fluency in SQL and experience in Extract, Load, and Transform (ELT). * Have experience or a high understanding of data modeling. * Have experience in tuning and optimizing data pipeline and data queries * Having a programming mentality and problem-solving skills * Be flexible on technology * Be able to research new tools, technologies quickly to solve client's needs. * Can communicate with clients in English * Have the ability to evaluate and provide solutions for business cases/ issues * Have knowledge/experience in data quality, data integration, big data, data analytics, visualization Nice to have: * Experience in the Business Intelligence (BI) / Data Warehousing (DW) industry * Capacity to listen, consult with clients and understand business models to provide the right solution to clients * Data consulting skills and experience * Experience with cloud-based SaaS platforms * Understanding DaaS (Data as a Service) * Capacity to be flexible, working on a different project, and prioritize the task * Have strong customer obsession skills * Experience working in the professional services organization * Experience with columnar databases * Experience in coding script Thinking of joining KMS Solutions? Yes, you deserve it! Progressive Career Development * Role-based training foundation * Active role at the global client-side * Continuous professional certification * Simple goals - achievable success Attractive compensation * Up to 15 months salary/year * Performance review twice a year * Premium healthcare insurance * 18+ paid leave/year Engagement workplace * Flexi mode, modern work environment * Well-being centric Impactful community organization * Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,... /Join us and let yourself explore other fantastic things!/"
2983153562|Senior Data Engineer|Ho Chi Minh City, Vietnam|KMS Solutions, Inc.|Full-time|"About the job
Job Description

As a part of our Engineering team under KMS Solutions, the position is to design innovative data solution to solve customers' business challenges, to provide requirements, solutions, estimation and implement tools, integration.
Work with clients and development team to understand client business model & business needs, estimate and develop data solutions for medium/large data pipeline, integrate data tools to fit the client requirement.
Design conceptual, logical and physical data models
Analyze and implement data solutions that solve business problems such as ELT, data warehouse, data cleansing, data integration, data visualization and reporting.
Technical lead small/medium development teams, ensure the understanding and compliance of offshore engineers to the business requirements, and technical direction
Be the trusted technical consultant for clients
Key requirements:
Good understanding of dimensional and normalized database models.
Fluency in SQL and experience in Extract, Load, and Transform (ELT).
Have experience or a high understanding of data modeling.
Have experience in tuning and optimizing data pipeline and data queries
Having a programming mentality and problem-solving skills
Be flexible on technology
Be able to research new tools, technologies quickly to solve client's needs.
Can communicate with clients in English
Have the ability to evaluate and provide solutions for business cases/ issues
Have knowledge/experience in data quality, data integration, big data, data analytics, visualization

Contact the job poster
Kiet Lam
Senior Data Engineer at KMS Solutions, Inc.
Job Poster Location
Vietnam
Send InMail"
3008488622|Junior/Senior Data Engineer (ETL, Python, Azure)|Ho Chi Minh City, Ho Chi Minh City, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Executive|"About the job
Support data architecture roadmap by managing data models, data store/warehouse, information management, and advanced data analytics.
Utilize tools and techniques for data management and data quality.
Support DataOps deployments, configurations, and complex data architectures, ensuring documentation meets current and forecasted needs.
Collaborate and work with data stakeholders to ensure that data and reports meet their business needs.
Develop logical and physical data models for complex projects using both relational and other modeling techniques and approaches.
Developing ETL specifications and mappings to support data conversion and integration from a wide variety of source systems.
Stay up to date with emerging data technologies and provide an understanding of how to adopt and apply new patterns.
Lead and provide technical guidance for design and implementation of data storage and governance systems.
Engage in technical evaluations of solution and design approaches.

Qualifications

General requirements:

At least intermediate level of English level
Likely having 3+ years of experience depending on how fast of your learning and developing technical capability
Ability to obtain deep knowledge of the project technologies and work independently with minimum guidance
Ability to self-learn and adapt to new technologies quickly
Passion with data engineering, data technologies.
Technical requirements:

Fluent in SQL and experience ETL process: Extract, Transform and Load data.
Experience with Python programming language and Azure cloud platform
Experience with Devops tools such as Terraform, GitHub

Additional Information

Want to be the Best? Join KMS!
It‚Äôs positive to claim we‚Äôre one of the top IT companies in Vietnam:

From Vietnam, we have crafted brilliant products for millions of global users.
We build awesome global products to conquer the world from Vietnam: QASymphony, Kobiton, Katalon, Witurn, Sprynkl and many more to come.
We‚Äôre committed to investing in our people and building a workplace you‚Äôll love coming to every day.
Perks you 'll love at KMS:

Working in one of the Best Places to Work in Vietnam
Building large-scale & global software products
Working & growing with Passionate & Talented Team
Diverse careers opportunities with Software Outsourcing, Software Product Development, IT Solutions & Consulting
Attractive Salary and Benefits
Performance appraisals twice a year and Performance bonus
Onsite opportunities: short-term and long-term assignments in U.S, Europe, Asia.
Flexible working time
Various training on hot-trend technologies, best practices and soft skills
Premium healthcare insurance for you and your loved ones
Company trip, big annual year-end party every year, team building, etc.
Fitness & sport activities: football, tennis, table-tennis, badminton, yoga, swimming‚Ä¶
Joining community development activities: 1% Pledge, charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Free in-house entertainment facilities (foosball, ping pong, gym‚Ä¶), coffee (latte, cappuccino, espresso) and snack (instant noodles, cookies, candies‚Ä¶)
And much more, join us and let yourself explore other fantastic things!"
3012936252|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|KNOREX|Full-time ¬∑ Mid-Senior level|"About the job
About Knorex

Established in 2010, Knorex is a cutting edge advertising technology MNC with offices across USA, Australia, China, Singapore, Vietnam, India, Thailand and Malaysia. Knorex provides Precision Performance Marketing products and solutions to the world‚Äôs leading brands and media agencies. With its full-stack platform, Knorex XPO‚Ñ¢ (https://xpo.knorex.com) supplies the technology platform to deliver the right marketing message to the right audience at the right moment and right place, underpinned by a multi-layered data-driven approach. Knorex XPO shields its customers from dealing with the complexity and fuss while delivering immersive, dynamic and personalized marketing experiences that connects with their users. Knorex also provides managed services to complement its offering.

Why Knorex

We are constantly on the lookout to recruit the best and the brightest - from engineering to sales to account management to operations and HR.

Knorex offers you many different opportunities to scale your ambition and creativity far and beyond. We embrace a dynamic and pragmatic way of doing things, setting ourselves up for long term achievement yet relentlessly focused on delivering the short term goals. If you love the joy of building stuffs and seeing them grow, growing yourself and others in the process, and challenging yourself to do stuffs that you once thought impossible, we invite you to explore a career with us.

Key Responsibilities
Develop clever algorithms and pragmatic solutions to our data analytics problems.
Develop metrics to measure the outcome/impact of your introduced solutions.
Develop and maintain API to support other teams in retrieving the metrics
Work with other members to implement and integrate into our existing systems.
Document and improve the solutions over time.
Evaluate and identify new technologies for implementation.
Communicate with our business and technical teams to understand the analytics requirements.
Respond and follow up to incorporate feedback and draw new insights.
Prioritize tasks to meet multiple deadlines.

Requirements
3 - 4 years of experience for similar positions
Must be proficient in either Python, Scala, Spark or NodeJS
Proficiency in multiple languages listed above is a plus
Knowledge in MongoDB is nice to have
Good knowledge of algorithms and data structures
Experience with ad serving, ad tracking and optimization is a plus
Strong in analytics and problem solving technique
Willingness to learn and able to pick up new technology or new concepts fast;
Able to work independently as well as in collaborative mode with minimum supervision;
Work productively even under pressure;
Possess good work ethic, attitude with good follow-through;
Excellent communication in written and spoken English.

Benefits
Attractive salary, 13rd month salary
Quarterly bonus scheme
W3F fund for learning and development
SHUI & Bao Viet Health care insurance
Macbook provided
Ample opportunities to grow. You get to propose your own ideas and see it through.
Work with passionate, talented and driven colleagues who get things done!
Opportunity to work cross-country and with variety of projects of different nature.
Challenging and exciting problems that await you to solve.
Comprehensive Health Insurance Coverage.
Personal Development Fund for courses and materials."
2977586452|Senior Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Global Fashion Group|Full-time ¬∑ Associate|"About the job
Global Fashion Group (GFG) is the leading fashion and lifestyle retail destination in Asia Pacific, Latin America and CIS. We connect over 10,000 global, local and own brands to a market of more than one billion consumers through four established e-commerce platforms: THE ICONIC, ZALORA, dafiti and lamoda. Through an inspiring and seamless customer experience enabled by our own technology ecosystem and operational infrastructure, we are dedicated to being the #1 fashion and lifestyle destination in our markets. With 17 offices and 10 fulfilment centres across four continents, GFG proudly employs a dynamic and diverse team with deep local knowledge and expertise. In 2019, GFG delivered more than 34 million orders to over 13 million active customers.

ABOUT THE FUNCTION

At GFG, technology is core to long-term success and is a crucial enabler of a great customer experience. We are a mix of experts in fashion, logistics, data analytics, marketing and design, guided by business consultants and tech geniuses - everyone contributes to the success of GFG.

We are looking for a Senior Data Engineer to join our team:

ABOUT THE ROLE

Work daily to scale machine learning problems. For this purpose, you are expected to be involved in the process of collecting, storing, processing, and analyzing data generated from our database, in addition to joining our data scientists in the design of machine learning models.
Work in a diverse, international setting with teammates who are experts in various topics. We often conduct workshops to improve our individual skill sets, and to improve our workflow as a team. The role is based in our Vietnam office.
THE IMPACT YOU‚ÄôLL MAKE

Data at GFG never stops growing and the team also never stops learning, innovating and expanding so that we can bring in or build the latest and best tools and technologies. In this role, you will be able to create strategic data models, develop and maintain data architecture used to power high-impact business initiatives that contribute to the overall growth and strategy for GFG.

WHAT WILL YOU BRING TO THE TEAM

Bachelor or Master degree in Computer Science or a related technical discipline
Be familiar with:

Data structures & algorithms
Data modelling
Basic machine learning algorithms
Following languages: SQL, Python, R, Java/Scala
Any of the following databases: MySQL, PostgreSQL, MongoDB, HBase, Cassandra, Redshift
Cloud technologies: AWS, GCP (BigQuery)
2. Be knowledgeable in:

Object oriented design and design patterns
Large-scale distributed systems
Hadoop, Spark and Pandas or similar processing engines
Jupyter Notebook or Zeppelin
Apache Airflow, Apache Superset
3. Good to have:

Knowledge of data visualization
Good background in statistics
Knowledge in data analysis, data mining, or machine learning
Experience working with big data
WHAT WE OFFER YOU

The unique opportunity to have a serious impact on a growing organisation;
A dynamic working environment shaping the face of fashion e-commerce in growth markets
Significant career growth opportunities in a fast-growing business, gain working exposure in the 20+ countries across the group
Work closely with a global talent pool with international mindset
Apply today and join GFG in this exciting role shaping the face of fashion e-commerce!


Global Fashion Group embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements."
2962432816|Big Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Trusting Social|Full-time ¬∑ Entry level|"About the job
We are an AI Fintech company specialized in assessing credit profiles of consumers in emerging markets combining pioneering AI with large alternative data sources. In 2020 we reached our ambitious milestone of credit profiling 1bn consumers spanning 4 countries - Vietnam, Indonesia, India & the Philippines - and building a platform for the wider industry and the financial services industry in particular to provide the 'un & under' served access to credit. At the core of this initiative has been our strict and unwavering adherence to the norms of consumer data privacy and consumer data rights.

But we're not satisfied as we embark on the next leg of our journey to deliver 100 million credit lines to consumers in the markets where we operate. Although this goal is ambitious, we truly believe that by harnessing the power of AI & Big Data we can deliver financial access at unprecedented scale.

As a firm, we're audacious problem solvers motivated by our impact on society. We deeply espouse the values of ownership - of our actions and initiatives, integrity in all we do and agility in execution.

We place great importance on doing what is right, what is best and what is innovative. And we are seeking people to champion these values and beliefs as we grow. Trusting Social is looking for 2 Big Data Engineers. If you are smart, driven and want to make a difference in the world with the most advanced and fascinating technology, come join our team. We can satisfy your desire to explore new territory and give you the runway to really make an impact.

What You Will Do
A Data engineer in TrustingSocial works on the data pipeline infrastructure that is veritably the backbone of our business. In a day's job you would be writing elegant functional SCALA code to crunch TBs of data on Hadoop clusters, mostly using Spark. In a week's job, you would be owning a data pipeline deployment to clusters : on-prem or on-cloud (AWS or GCP or more). In a month's job, you would be managing Hadoop clusters right from security to reliability to HA. Did we mention we are building a pluggable,unified data-lake from scratch? Time to time you have new challenges for automating and scaling tasks for Data science team. We constantly look to improve our framework and pipelines, hence learning on the job is sort of a given. This is the big picture of our big data system.
Our expertise and requirements include but are not limited to Spark, Scala, HDFS, Yarn, Hive, Kafka, Distributed Systems, Python, Datastores (Relational and NoSql) and Airflow.
What You Need To Have
Experienced with Java/Scala (Python is a plus).
Experienced with Big Data stacks: Hadoop, Spark (Must have), etc.
Knowledge of various ETL techniques and frameworks, such as Spark, Yarn, Airflow, Oozie, etc.
Understanding of distributed computing principles
Experience with NoSQL databases.
Experience with various messaging systems, such as Kafka or RabbitMQ
What You Will Get
Opportunity to work and learn from one of the best and brightest technology teams in Vietnam
Be part of a winning team with exponential growth regionally, experience recruiting world-class talents
Top market rate pay
Generous benefits: health insurance package for family, Free Food at the office - All Day, Grab for work allowance
Learn More About Us Here

Additional Info

https://www.youtube.com/watch?v=inAEDGvOcL8&t=29s"
2996028785|||||
2992172669|Senior Data Engineer, KMS Solutions|ƒê√† Nang, Da Nang City, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
As a part of our Engineering team under KMS Solutions, the position is to research data tools to solve customers' requirements, provide solutions, estimation and implement tools, integration. * Work with clients and development team to understand business needs, estimate and develop data solutions for medium/large applications, tools, integration. * Design conceptual, logical and physical data models * Analyze and implement data solutions that solve business problems such as ETL, data warehouse, data cleansing, data integration, data visualization and reporting. * Lead small/medium development teams, ensure the understanding and compliance of offshore engineers to the business requirements, and technical direction Key requirements: * Good understanding of dimensional and normalized database models. * Fluency in SQL and experience in Extract, Transform, and Load (ETL). * Have experience or high understanding in data modelling. * Having a programming mentality and problem-solving skills * Be flexible on technology * Be able to research new tools, technologies quickly to solve client's need. * Can communicate with clients in English * Have the ability to evaluate and provide solutions for business cases/ issues * Have knowledge/experience in data quality, data integration, big data, data analytics, visualization Nice to have * Experience in the Business Intelligence (BI) / Data Warehousing (DW) industry * IT consulting skills and experience * Experience with cloud based SaaS platforms * Understanding DaaS (Data as a Service) * Experience working in professional services organization * Experience with columnar databases * Experience in coding script Thinking of joining KMS Solutions? Yes, you deserve it! Progressive Career Development * Role-based training foundation * Active role at the global client-side * Continuous professional certification * Simple goals - achievable success Attractive compensation * Up to 15 months salary/year * Performance review twice a year * Premium healthcare insurance * 18+ paid leave/year Engagement workplace * Flexi mode, modern work environment * Well-being centric Impactful community organization * Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,... /Join us and let yourself explore other fantastic things!/"
2997945393|Data Engineer, KMS Solutions|Ho Chi Minh City, Ho Chi Minh City, Vietnam|KMS Solutions|Full-time ¬∑ Mid-Senior level|"About the job
As a key member of our Consulting team within Service Delivery, the position will be the data engineer that helps guide our customers through their data product implementation. Working directly with customers, a team of data product managers, solution architects and engineers drive requirements gathering, the project design, and the QA process. You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and will data analytics to build dashboard and business data insight.

Key responsibilities

In collaboration with architect, implement data solutions that solve business problems
Design conceptual, logical and physical data analytics solutions
Implement effective and scalable end-to-end data pipeline solutions
Script Optimized SQL queries for scale
Possess a comprehensive understanding of products and services

Qualifications

At least 2+ years of work experience
Experience in SQL scripting.
Understanding of dimensional and normalized database models
Understanding Extract, Transform, and Load (ETL)
Having a programming mentality and problem-solving skills
Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry
Interested in data business analysis to build metrics and reports
Understanding of the concept of cloud-based SaaS platforms
Experience with the programming language, Scripting language, REST APIs is a plus
Be flexible on technology

Additional Information

Thinking of joining KMS Solutions? Yes, you deserve it!

Progressive Career Development

Role-based training foundation
Active role at the global client-side
Continuous professional certification
Simple goals - achievable success
Attractive compensation

Up to 15 months salary/year
Performance review twice a year
Premium healthcare insurance
18+ paid leave/year
Engagement workplace

Flexi mode, modern work environment
Well-being centric
Impactful community organization

Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Join us and let yourself explore other fantastic things!"
2948653661|Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Quincus|Full-time ¬∑ Entry level|"About the job
‚ÄúMake every logistics journey your best one yet‚Äù - Quincus

The Company

At Quincus, our technology is designed to ease shipping issues‚Äîwherever in the world they may be. We commit ourselves in designing the most effective total end to end supply chain solutions through a dedicated technology ecosystem. This offers our users a personalized experience that bypasses traditional and expensive logistics options. By combining advanced technology, data analytics, and hands-on experience, we eliminate traditional and expensive logistics options.

The Opportunity

We are looking for a Data Engineer to not only build data pipelines but also extend the next generation of our data tools. As a Data Engineer, you will develop a clear sense of connection with our organization and leadership - as Data Engineering is the eyes through which they see the product.

This is a partnership-heavy role. As a member of Quincus Research Data Engineering, you will belong to a centralized Data Science/Data Engineering team who partners closely with teams in Quincus' organization. Through the research-nature of our team, you will contribute to a variety of projects and technologies, depending on where science leads us. Projects include analytics, ML modeling, RL modeling, tooling, and more. The broad range of innovation equates to a broad range of projects and deliverables: ML Models, datasets, measurements, services, tools and process.

Your day to day
Partner with leadership, engineers, program managers and data scientists to understand data needs.
Lead, influence and set direction on domain areas as a subject matter expert to drive solutions on complex and strategic problems.
Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.
Educate your partners: Use your data and analytics experience to ‚Äòsee what‚Äôs missing‚Äô, identifying and addressing gaps in their existing logging and processes.
Leverage data and business principles to solve large scale web, mobile and data infrastructure problems.
Contribute to shared Data Engineering tooling and standards to improve the productivity and quality of output for Data Engineers across the company.
Actively mentor and identify rising talent, and serve as a positive leader across the scope of the organization.

What you will bring
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
7+ years of Python development experience.
7+ years of SQL experience.
5+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).
7+ years experience with Data Modeling.
Communications skills.
Experience understanding requirements, analyzing data, discovering opportunities, addressing gaps and communicating them to multiple individuals and stakeholders.
7+ years experience in custom ETL design, implementation and maintenance.
Experience working with cloud or on-prem Big Data/MPP analytics platform(i.e. Snowflake, AWS Redshift, Google BigQuery, Azure Data Warehouse, Netezza, Teradata, or similar).

Preferred Qualifications (Nice To Have)
Experience with more than one coding language.
Experience with designing and implementing real-time pipelines.
Experience with data quality and validation.
Experience with SQL performance tuning and E2E process optimization.
Experience with anomaly/outlier detection.
Experience with notebook-based Data Science workflow.
Experience with Airflow.
Experience querying massive datasets using Spark, Presto, Hive, Impala, etc."
2961089396|Senior Data Engineer|Ho Chi Minh City, Vietnam|Fossil Group, Inc.|Full-time ¬∑ Mid-Senior level|"About the job
About Fossil
FOSSIL Vietnam (formerly Misfit) is one of 59 offices under FOSSIL Group worldwide. Before joining FOSSIL, Misfit was a US high-tech company creating wearables and smart-home products, with R&D and operations office based in Vietnam. In November 2015, Misfit got acquired and has since then become part of the FOSSIL Group's portfolio of brands, standing aside world-renowned brands including FOSSIL, Michael Kors, Burberry, Emporio Armani, Diesel, Adidas, DKNY and among others.
As one of the top 3 largest watchmakers in the world, FOSSIL Group is selling over 50 million watches and accessories a year in more than 150 countries. With the presence of Misfit, FOSSIL will be working towards offering a broader spectrum of connected devices that target fashion-conscious consumers and aiming at leading the convergence of style and technology.
Technology-forward Strategy
FOSSIL Vietnam positions itself as the Center of Excellence for Cloud & App Innovation and Development of FOSSIL Group and will power a wider array of connected devices.
At FOSSIL Group, people are our most valuable asset. With that mission at hand, we will remain a place where innovation flourishes, where world-class talents get leveraged, and where people come together to make greater products and tell greater stories.

WHAT YOU'LL DO
Build, deploy and maintain big data solutions that can adequately handle the needs of a
rapidly growing data.
Build out scalable and reliable ETL, data pipelines and processes to ingest data from a
large number and variety of data sources.
Work with other teams to provide relevant reports, optimize the server cost efficiency.
Maintain and optimize the performance of our data analytics infrastructure to ensure
accurate, reliable and timely delivery of key insights for decision making.
Take lead on technical best practices and guide internal research.
Coach other junior team members to help them reach their maximum potential.
Build a good team culture of humility, commitment, humor and customer service
WHAT WE NEED
Knowledge of programming languages such as Python, Java, Scala.
Strong experience in designing data-intensive systems with Lambda / Kappa / Data Lake Architecture.
At least 4 years mastering with big data stacks mentioned above.
Experience with workflow management systems such as Airflow, Luigi, AWS Data Pipeline.
Knowledge of data warehouse/data modeling and SQL is a plus.
Knowledge of event-driven systems is a plus.
Huge plus: strong English communication skills.
Experience working with cloud service providers such as Amazon Web Services or Google Cloud.
Good reputation on the open-source community GitHub, GitLab is a big plus.
Good leadership and effective communication in both verbal and nonverbal are preferred.
IN RETURN WE OFFER
‚óè Competitive salary (100% salary during probation)
‚óè Bonus:
13th-month salary paid in December
Performance bonus
‚óè Insurance:
Social Insurance on full salary starts from probation
Premium health insurance for employees and family, even in probation
‚óè Annual leave: up to 15 days/year (and plus Volunteer time off, and plus Summer
hours...) Enjoy!
‚óè Gift and Care:
Welcome watch after probation
Monthly mobile cards: 500,000 VND
Silver membership at Getfit Gym & Yoga Center downstairs
Free lunch and free dinner (if you work after 20:00)
‚óè All tools you need: Mac/Windows, iOS/Android, Testing devices/State-of-the-art
wearables, you name it.
‚óè Opportunities to work with Tech giants, multinational offices and develop
yourself through training programs, language classes,...
‚óè Employee engagement activities: From team building, sports competition,
Halloween to Christmas to Year-end-parties to the Lunar new year... Yah, we work
hard, we play hard!
Contact the job poster
Chanh Tran 2nd
Talent Acquisition Specialist (Engineering) @Fossil Group, Inc.
Job Poster Location
Ho Chi Minh City, Vietnam
Send InMail"
2971079635|Lead Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|GLOBAL FASHION GROUP SGP SERVICES PTE LTD.|Full-time ¬∑ Mid-Senior level|"About the job
Global Fashion Group (GFG) is the leading fashion and lifestyle retail destination in Asia Pacific, Latin America, and CIS. We connect over 10,000 global, local, and own brands to a market of more than one billion consumers through four established e-commerce platforms: THE ICONIC, ZALORA, dafiti and lamoda. Through an inspiring and seamless customer experience enabled by our own technology ecosystem and operational infrastructure, we are dedicated to being the #1 fashion and lifestyle destination in our markets. With 17 offices and 10 fulfilment centres across four continents, GFG proudly employs a dynamic and diverse team with deep local knowledge and expertise. In 2019, GFG delivered more than 34 million orders to over 13 million Active Customers.

About The Data Team

Our vision to bring affordable and sustainable fashion to customers in our markets is powered by technology and data. The GFG Data Team is an integral part of GFG and is essential to enabling a data-driven decision-making culture.

About The Role

As the Lead Data Engineer in the Data team, you will be working on all aspects of Data, from Platform and Infra build out to pipeline engineering and writing tooling/services for augmenting and fronting the core platform. You will be responsible for building and maintaining the state-of-the-art data Life Cycle management platform, including acquisition, storage, processing and consumption channels. The team works closely with Data Scientists, Data Analytics, Business Intelligence and business stakeholders across the GFG in understanding and tailoring the offerings to their needs.

THE IMPACT YOU‚ÄôLL MAKE
Build and manage the data asset using some of the most scalable and resilient open source big data technologies like Airflow, Spark, Kafka, etc
Build and manage a highly scalable, efficient Data and ML Infrastructure by adopting microservices driven design and architecture with proper DevOps principles and practices
Design and deliver the next-gen data lifecycle management suite of tools/frameworks, including ingestion and consumption on the top of the data lake to support real-time as well as batch use cases
Help the team in integrating various data sources across GFGs group vertical
Build and expose metadata catalog for the Data Lake for easy exploration, profiling as well as lineage requirements

What Will You Bring To The Team
At least 3+ years of relevant experience in developing scalable, secured, fault tolerant, resilient & mission-critical Big Data platform.
Able to maintain and monitor the ecosystem with high availability.
Must have sound understanding for all Big Data components & Administration Fundamentals. Hands-on in building a complete data platform using various open source technologies.
Must have good fundamental hands-on knowledge of Linux and building big data stack on top of AWS/GCP using Kubernetes.
Strong understanding of big data and related technologies like HDFS, Spark, Presto, Airflow, Kafka, Apache Atlas etc.
Good knowledge of Complex Event Processing systems like Spark Streaming, Kafka, Apache Flink, Beam etc.
Able to drive devops best practices like CI/CD, containerization, blue-green deployments, secrets management etc in the Data ecosystem.
Able to develop an agile platform with auto scale capability up & down as well vertically and horizontally.
Able to develop an observability and monitoring ecosystem for all the components in use in the data ecosystem.
Proficiency in at least one of the programming languages Java, Scala, Python or Go.

What We Offer You
The unique opportunity to have a serious impact on a growing organisation
A dynamic working environment shaping the face of fashion e-commerce in growth markets
Significant career growth opportunities in a fast-growing business, gain working exposure in the 20+ countries across the group
Work closely with a global talent pool with international mindset

Apply today and join GFG in this exciting role shaping the face of fashion e-commerce!

Global Fashion Group embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements.

Apply today and join GFG in this exciting role shaping the face of fashion e-commerce!

Global Fashion Group embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements.

Powered by JazzHR

fRkZLUsVAf"
2997942781|Data Engineer, KMS Solutions(Da Nang)|ƒê√† Nang, Da Nang City, Vietnam|KMS Solutions|Full-time ¬∑ Mid-Senior level|"About the job
As a key member of our Consulting team within Service Delivery, the position will be the data engineer that helps guide our customers through their data product implementation. Working directly with customers, a team of data product managers, solution architects and engineers drive requirements gathering, the project design, and the QA process. You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and will data analytics to build dashboard and business data insight.

Key responsibilities

In collaboration with architect, implement data solutions that solve business problems
Design conceptual, logical and physical data analytics solutions
Implement effective and scalable end-to-end data pipeline solutions
Script Optimized SQL queries for scale
Possess a comprehensive understanding of products and services

Qualifications

At least 2+ years of work experience
Experience in SQL scripting.
Understanding of dimensional and normalized database models
Understanding Extract, Transform, and Load (ETL)
Having a programming mentality and problem-solving skills
Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry
Interested in data business analysis to build metrics and reports
Understanding of the concept of cloud-based SaaS platforms
Experience with the programming language, Scripting language, REST APIs is a plus
Be flexible on technology

Additional Information

Thinking of joining KMS Solutions? Yes, you deserve it!

Progressive Career Development

Role-based training foundation
Active role at the global client-side
Continuous professional certification
Simple goals - achievable success
Attractive compensation

Up to 15 months salary/year
Performance review twice a year
Premium healthcare insurance
18+ paid leave/year
Engagement workplace

Flexi mode, modern work environment
Well-being centric
Impactful community organization

Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Join us and let yourself explore other fantastic things!"
2977116019|Data Engineer|Qu·∫≠n 12, Ho Chi Minh City, Vietnam|AdStart Media|Full-time ¬∑ Mid-Senior level|"About the job
We are offering an immediate opening for an experienced Data Engineer based in our Ho Chi Minh office. As part of a dedicatedly agile team, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection.

You should have excellent communication skills to work with product owners to understand data requirements, and to build ETL procedures to ingest the data into the data lake. You should be an expert at designing, implementing, and operating stable, scalable, low-cost solutions to flow data from production systems into the data lake.

If you are self-directed and comfortable supporting the data needs of multiple teams, systems and products, we would like to meet you.

YOUR MAIN DUTIES:

Manage and expand our existing AWS big data infrastructure

Build ETL processes within the AWS environment

Perform data extraction, cleaning, transformation, and flow

Design, build, launch and maintain efficient and reliable large-scale batch and real-time data pipelines with data processing frameworks

Integrate and collate data silos in a manner which is scalable, compliant and cost efficient



Qualifications

English proficiency is a must

2+ years of experience in designing and developing solutions using AWS services such as Lambda, Glue, Athena, etc.

Good knowledge of programming Python is a must

Hands on working knowledge of Relational / NoSQL databases such as MySQL, PostgreSQL

Experience with DB administration in a production environment; performance/scaling concepts and tuning best practices

Experience working in agile development teams using Scrum methodologies

Able to work autonomously and within a team

Must be organized, efficient, and have good attention to details

Must be able to show initiative to get a job done with little / no supervision



Additional Information

WHAT WE OFFER:

English speaking multi-cultural environment

Flexible working time

Competitive salary and benefits

Premium medical insurance package (option to extend to family members)

Annual employee‚Äôs health-check

Generous annual leave days and paid sick leave days

Bi-Annual Performance Review

English classes / Toastmasters Clubs

Various trainings on soft-skills and best practices

Annual company trips, year end party and periodic team-building activities"
2948279433|(Senior) Data Engineer - Seller Center|Ho Chi Minh City, Ho Chi Minh City, Vietnam|TIKI|Full-time ¬∑ Associate|"About the job
About Tiki

Tiki is Vietnam‚Äôs most trusted e-commerce platform. We are the first in the country to offer 2-hour delivery. Tiki has the highest NPS score amongst all e-commerce platforms in Vietnam. Customer trust and satisfaction are at the heart of everything we do. Harmony and learning is the core foundation of our culture.

In an already fast-growing Vietnam eCommerce market, Tiki is experiencing exceptional growth. With growth comes interesting and unique problems. Vietnam market with its diverse and emerging seller base, densely populated city logistics, and growing consumer spending online - not only for products but also for services, presents unique product and technology building opportunities. We are in a heavy technology investment mode with many new things to build. In that context --- Tiki indeed provides career-building, full lifecycle innovation product building opportunities.

Our Culture
Customer-first, open-minded, data-informed culture
Motivated, knowledge-hungry colleagues
Many opportunities to use next-gen technologies to solve interesting problems
Stock options and healthcare
Modern, upbeat, open plan workspace
About TIKI Seller Center System: The Seller Center is the place where thousands of sellers interact with the TIKI System to operate. The Seller Center opens the door of the TIKI System. It provides a friendly user interface and an extendable system based on various micro-services. Sellers can do all their business at Seller Center, from signing up/signing up to creating the product, processing orders, analyzing reports to optimize sales.

Responsibilities:
Build data processing infrastructure for the Marketplace team.
Create framework so that our data scientists can easily analyse seller data.
Building storage/compute/scheduler for big data processing running on Google Cloud Platform (GCP)
Building data factory platform where users can contribute to the data lake by adding more meaningful datasets.
Designing a large scale distributed system
Requirements:
3+ years of Software Engineering with focus on data engineering
Proficiency in SQL & programming languages like Java, Python
Bachelor of computer science or related analytical field
Good at problem-solving
Understanding of design for large scalability, performance, and reliability
Experiences with Apache big data ecosystem. (spark, kafka, airflow)
Experience working with ETL tasks.
Benefits

Inside our engineering team:
We iterate constantly. There‚Äòs no such thing as the best version of anything, just a constant stream of improvements and tests.
We move fast, really fast. Major changes can be executed in a few days, many times just a few hours.
We have a data-informed mindset. We try to use data to inform our decision as much as possible.
We are independent. Most of the time, your team will not need technical assistance from other teams.
We take risks. We‚Äòre not afraid to challenge ""best practices"".
Our attractive offers include:
Open communication with passionate and experienced members.
Challenging working environment.
Easy access to the library with tons of startup, product, UX, coding... books.
Private healthcare insurance.
Annual health check-ups.
Special internal programs for Tikiers when shopping on Tiki.vn (free ship TikiNow service, discount...).
New & beautiful office with a pantry room (with bar), entertainment & gymnastic equipment, yoga rooms, a library, and an open space facilitating cross-department communication.
Competitive salary and performance review, 13th-month pay based on performance."
2976628040|Senior Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Robert Walters|Full-time ¬∑ Associate|"About the job
An exciting Senior Data Engineer role has become available at a unicorn food-delivery software company in HCMC.

About The Senior Data Engineer Role

In this critical role, you will be in data services team. You will be responsible for building and maintaining data infrastructure of the company.

Key Responsibilities
Work closely with data engineering teams to help to build data solutions
Design, evaluate and implement framework, platform and architecture that can adequately handle the needs of a rapidly growing data driven company
Design and build both batch and real-time data pipelines for various data sources: API, flat files, databases, etc.
Prepare data and work with Data Scientist for projects and design and build scalable / low latency AI-powered systems
Build, maintain, optimise and working with other teams to continuously improve the data warehouse, infrastructure cost to keep it at the reasonable level
To succeed in this role, you need to have cooperative, open, and data driven mind. Considering their start-up and international environment, it is a bonus point if you are flexible and open for new challenges.

Key Requirements
At least three years of solid experience in data engineers
Knowledge of various topics in the data domain (e.g. platforms, analysis, ML, etc)
Strong programming skill (e.g. Python‚Ä¶)
Knowledge and experience in cloud-base infrastructure (e.g. AWS, GCP); relational database and NoSQL database (e.g. MongoDB)
Open mindset on learning, problem-solving
Good English communication
This business results in a dynamic, fun and fast pace with strong commitment to bring the best values. The scope of the offer, the size of the business, the freedom and autonomy to drive your career forward all add up to a great place to work.

If you are driven, determined and want to take the next step in your career, this is the role for you. Great career progression opportunities await the right person in this exciting job.

Apply today or contact me to discuss this new opportunity.



Due to the high volume of applications we are experiencing, our team will only be in touch with you if your application is shortlisted."
2917721074|Senior Data Engineer|Ho Chi Minh City, Vietnam|Ch·ª£ T·ªët|Full-time ¬∑ Mid-Senior level|"About the job
Cho Tot technology foundation is growing and expanding to power our next level of growth, serving ten of millions of Vietnamese via our digital products. Our engineering team are building robust platform, automations and data engineering pipeline that enabling continuous explorations in product innovations.

Join us to build systems that serve more than hundred of millions requests and build and put to use of data pipeline having more than billion of messages passing through daily. You will be solving big scale and fast data problem in a fast pace agile software development for internet digital product. You will have very competitive remuneration with exposure to regional travel within Singapore, Malaysia, Myanmar for collaboration workshop as well as specific sharing conferences.

Scope of works:
Join in and responsible for the development and execution of highly complex and large scale data structures and pipelines to organize, collect and standardize data to generate insights and addresses reporting and advance analytic needs.
Writes highly complex ETL processes, designs database systems and develops tools for real-time and offline analytic processing.
Designs and modifies components of new and existing systems to promote an integral data operations process that enable a distributed BI across multiple data driven business operations.
Collaborates cross-functionally to build and convert algorithms and data models into production systems to support new product innovations.
Leverages edge technologies and programming skills in Python, Java and SQL to creatively solve complex business problems.
Design and implement custom packages to answer challenging analytical problems. Applies knowledge of systems and products to advise on analytical works across different business units.

Requirements:
3+ years of related experience in building data engineering pipeline.
Knowledge in Spark, data streaming architectures, experience using and optimizing services such AWS Redshift, BigQuery, Dataflow, Dataproc, Airflow pipelines and framework.
Expertise in SQL, Python or Java with experience in bash shell scripts, UNIX utilities.
Experience in data engineering work supporting ML vision and NLP is a plus.
Proven ability to leverage multiple tools and programming languages to analyze and manipulate large data sets from disparate data sources and build innovative solutions.
A team player having superior ability to communicate technical ideas and results to non-technical partners in written and verbal form.
Self-motivated, detail oriented and responsible.
BSc, MSc degree in Computer Science related fields.

Thank you for taking your time to read our job description and thank you in advance if you decide to apply for this position. Shortlisted candidates will be contacted within 2 weeks since application, otherwise we might meet when another chance arises.
Contact the job poster
Le Truc Huynh 2nd
Attended Foreign Trade University
Job Poster Location
Ho Chi Minh City, Ho Chi Minh City, Vietnam
Send InMail"
2973968326|Mid/Senior Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|BAEMIN Vietnam (Woowa Bros.)|Full-time ¬∑ Associate|"About the job
BAEMIN is a rising tech unicorn invested by Woowa Brothers, Korea's number 1 food delivery on the business world's map of FoodTech. As we are expanding and ambitious to reach our new milestones, we are acquiring talents who are self-leading, confident and outstanding to accompany us on this journey.

PURPOSE OF JOB:
Responsible for building and maintaining the data infrastructure of the company.
Derive and carry out technical challenges and manage members of the data services team.

Data Engineering:
Work closely with engineering teams to help to build data solutions for Baemin;
Design, evaluate and implement framework, platform and architecture that can adequately handle the needs of a rapidly growing data driven company;
Work with Data Scientist to design and build scalable / low latency AI-powered systems.
Design and build both batch and real-time data pipelines for various data sources: API, flat files, databases, etc.;
Build and maintain the data warehouse for the company;
Improve and optimize the workloads, processes to ensure that performance levels can support continuous accurate, reliable, and timely delivery of data products;
Prepare data for Data Science projects;
Monitor and optimize the data infrastructure cost to keep it at the reasonable level.
Remain up-to-date with industry standards and technological advancements to ensure the data infrastructure are both scalable and reliable;
Work with other teams to continuously improve the company's data infrastructure, data warehouse;
Coach junior team member;
Provide suitable training for other teams.

Experience

Your Skills and Experience
3+ years of experience, preferably in big data infrastructure;
Proficient in common big data toolset in a large-scale environment;
Experienced in deploying ML models to production;
Well versed in setting up continuous integration and deployment for big data or other projects;
Familiar with software development process and culture
Familiar with 3rd party analytics solutions. (e.g. Amplitude, Looker, Segment, Google Tag Manager)

Skills
Cognitive knowledge of various topics in the data domain (e.g. platforms, analysis, ML, etc)
Strong programming skill;
Knowledge and experience in both relational database and NoSQL database (e.g. MongoDB);
Knowledge and experience in cloud-base infrastructure (e.g. AWS, GCP);
Excellent communication skill;
Open mindset on learning, problem-solving;
Very good at speaking/writing in English;

Working Location:
Friendship Building, 31 Le Duan, Ben Nghe Ward, Dist 1, HCMC

If you are self-leading, eager to learn, dare to fail and willing to take any initiatives and transform it into business impact, join us now!"
2961587157|Lead Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Global Fashion Group|Full-time ¬∑ Associate|"About the job
Global Fashion Group (GFG) is the leading fashion and lifestyle retail destination in Asia Pacific, Latin America, and CIS. We connect over 10,000 global, local, and own brands to a market of more than one billion consumers through four established e-commerce platforms: THE ICONIC, ZALORA, dafiti and lamoda. Through an inspiring and seamless customer experience enabled by our own technology ecosystem and operational infrastructure, we are dedicated to being the #1 fashion and lifestyle destination in our markets. With 17 offices and 10 fulfilment centres across four continents, GFG proudly employs a dynamic and diverse team with deep local knowledge and expertise. In 2019, GFG delivered more than 34 million orders to over 13 million Active Customers.

ABOUT THE DATA TEAM

Our vision to bring affordable and sustainable fashion to customers in our markets is powered by technology and data. The GFG Data Team is an integral part of GFG and is essential to enabling a data-driven decision-making culture.

ABOUT THE ROLE

As the Lead Data Engineer in the Data team, you will be working on all aspects of Data, from Platform and Infra build out to pipeline engineering and writing tooling/services for augmenting and fronting the core platform. You will be responsible for building and maintaining the state-of-the-art data Life Cycle management platform, including acquisition, storage, processing and consumption channels. The team works closely with Data Scientists, Data Analytics, Business Intelligence and business stakeholders across the GFG in understanding and tailoring the offerings to their needs.

THE IMPACT YOU‚ÄôLL MAKE

Build and manage the data asset using some of the most scalable and resilient open source big data technologies like Airflow, Spark, Kafka, etc
Build and manage a highly scalable, efficient Data and ML Infrastructure by adopting microservices driven design and architecture with proper DevOps principles and practices
Design and deliver the next-gen data lifecycle management suite of tools/frameworks, including ingestion and consumption on the top of the data lake to support real-time as well as batch use cases
Help the team in integrating various data sources across GFGs group vertical
Build and expose metadata catalog for the Data Lake for easy exploration, profiling as well as lineage requirements
WHAT WILL YOU BRING TO THE TEAM

At least 3+ years of relevant experience in developing scalable, secured, fault tolerant, resilient & mission-critical Big Data platform.
Able to maintain and monitor the ecosystem with high availability.
Must have sound understanding for all Big Data components & Administration Fundamentals. Hands-on in building a complete data platform using various open source technologies.
Must have good fundamental hands-on knowledge of Linux and building big data stack on top of AWS/GCP using Kubernetes.
Strong understanding of big data and related technologies like HDFS, Spark, Presto, Airflow, Kafka, Apache Atlas etc.
Good knowledge of Complex Event Processing systems like Spark Streaming, Kafka, Apache Flink, Beam etc.
Able to drive devops best practices like CI/CD, containerization, blue-green deployments, secrets management etc in the Data ecosystem.
Able to develop an agile platform with auto scale capability up & down as well vertically and horizontally.
Able to develop an observability and monitoring ecosystem for all the components in use in the data ecosystem.
Proficiency in at least one of the programming languages Java, Scala, Python or Go.
WHAT WE OFFER YOU

The unique opportunity to have a serious impact on a growing organisation
A dynamic working environment shaping the face of fashion e-commerce in growth markets
Significant career growth opportunities in a fast-growing business, gain working exposure in the 20+ countries across the group
Work closely with a global talent pool with international mindset


Apply today and join GFG in this exciting role shaping the face of fashion e-commerce!


Global Fashion Group embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements."
2997943535|Senior Data Engineer, KMS Solutions (Ha Noi)|Hanoi, Hanoi, Vietnam|KMS Solutions|Full-time ¬∑ Mid-Senior level|"About the job
As a part of our Engineering team under KMS Solutions, the position is to research data tools to solve customers' requirements, provide solutions, estimation and implement tools, integration.

Work with clients and development team to understand business needs, estimate and develop data solutions for medium/large applications, tools, integration.
Design conceptual, logical and physical data models
Analyze and implement data solutions that solve business problems such as ETL, data warehouse, data cleansing, data integration, data visualization and reporting.
Lead small/medium development teams, ensure the understanding and compliance of offshore engineers to the business requirements, and technical direction

Qualifications

Key requirements:

Good understanding of dimensional and normalized database models.
Fluency in SQL and experience in Extract, Transform, and Load (ETL).
Have experience or high understanding in data modelling.
Having a programming mentality and problem-solving skills
Be flexible on technology
Be able to research new tools, technologies quickly to solve client's need.
Can communicate with clients in English
Have the ability to evaluate and provide solutions for business cases/ issues
Have knowledge/experience in data quality, data integration, big data, data analytics, visualization
Nice to have

Experience in the Business Intelligence (BI) / Data Warehousing (DW) industry
IT consulting skills and experience
Experience with cloud based SaaS platforms
Understanding DaaS (Data as a Service)
Experience working in professional services organization
Experience with columnar databases
Experience in coding script

Additional Information

Thinking of joining KMS Solutions? Yes, you deserve it!

Progressive Career Development

Role-based training foundation
Active role at the global client-side
Continuous professional certification
Simple goals - achievable success
Attractive compensation

Up to 15 months salary/year
Performance review twice a year
Premium healthcare insurance
18+ paid leave/year
Engagement workplace

Flexi mode, modern work environment
Well-being centric
Impactful community organization

Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Join us and let yourself explore other fantastic things!"
3013173459|Data Engineer (Vietnamese only)|ƒê√† Nang, Da Nang City, Vietnam|SmartDev|Full-time ¬∑ Mid-Senior level|"About the job
BENEFIT:
Fringe benefits (20 leave days/ Kindergarten & lunch allowance)
Premium extra healthcare insurance
Yearly career/ performance evolution
A flat organization (respect, teamwork, flexibility, transparency)
13th salary bonus/ competitive salary
Cutting-edge technologies/ Scrum methodology/ Agile development
Udemy/ LeAcademy/ English training course
Great activities (Team Building, Company Trip, Weekly Happy Friday, ‚Ä¶)

Responsibilities
Work closely with our data science to help build complex algorithms that provide unique insights into our data
Use agile software development processes to iteratively make improvements to our back end systems
Model front end and back end data sources to help draw a more comprehensive picture of user flows throughout our system and enable powerful data analysis
Build data pipelines that clean, transform, and aggregate data from disparate sources
Develop models that can be used to make predictions and answer questions for the overall business
Report to PM (Project Manager)

Requirements
Bachelor's degree in computer science, information technology, engineering or equivalent
3 or more years of experience with Python, SQL, and data visualization/ exploration tools
Familiarity with the AWS ecosystem specifically RedShift and RDS
Communication skills, especially explaining technical concepts to non-technical business leaders
Comfort working in a dynamic, research-oriented team with concurrent projects
English communication

NICE TO HAVE
Master's degree in stats, applied math, or related discipline
Experience building or maintaining ETL processes
Professional cerifications
Eager to learn
Team working spirit

Powered by JazzHR

3Be55ryrHd"
2996025994|Senior Data Engineer (ETL, SQL, BI), based in Da Nang|ƒê√† Nang, Da Nang City, Vietnam|KMS Technology, Inc.|Full-time ¬∑ Mid-Senior level|"About the job
You will implement data warehouse data models and dimensional data models, deliver ETL in SQL and data analytics to build dashboards and business data insight.

Key responsibilities:

In collaboration with architect, implement data solutions that solve business problems
Design conceptual, logical and physical data models
Implement effective and scalable end-to-end data pipeline solutions
Optimize SQL queries for scale
Possess a comprehensive understanding of products and services

Qualifications

General requirements:

At least intermediate level of English level
Likely having 3+ years of experience depending on how fast of your learning and developing technical capability
Ability to obtain deep knowledge of the project technologies and work independently with minimum guidance
Ability to self-learn and adapt to new technologies quickly
Technical requirements:

Fluency in SQL and experience in Extract, Transform, and Load (ETL) development in SQL
Good knowledge and hands-on experience of using popular ETL tools such as: SSIS, Talend or Pentaho
Experience one of the following programming languages: Java, Javascript, C# or Groovy
Knowledge of the Business Intelligence (BI) / Data Warehousing (DW) industry
Interested in data business analysis to build metrics and reports
Nice to have:

Experience with reporting and BI tools such as SSRS, PowerBI
Basic knowledge or experience of using cloud platform (AWS/Azure/GCP)
Familiar with Agile development methodologies (Scrum, XP, Kanban)

Additional Information



Working in one of the Best Places to Work in Vietnam
Building large-scale & global software products
Working & growing with Passionate & Talented Team
Diverse careers opportunities with Software Outsourcing, Software Product Development, IT Solutions & Consulting
Attractive Salary and Benefits
Two performance appraisals every year
Onsite opportunities: short-term and long-term assignments in North American (U.S, Canada), Europe, Asia.
Flexible working time
Various training on hot-trend technologies, best practices and soft skills
Premium healthcare insurance for you and your loved ones
Company trip, big annual year-end party every year, team building, etc.
Fitness & sport activities: football, tennis, table-tennis, badminton, yoga, swimming‚Ä¶
Joining community development activities: 1% Pledge, charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Free in-house entertainment facilities (foosball, ping pong, gym‚Ä¶), coffee, and snack (instant noodles, cookies, candies‚Ä¶)
And much more, join us and let yourself explore other fantastic things!"
2997945164|Senior Data Engineer, KMS Solutions|Ho Chi Minh City, Ho Chi Minh City, Vietnam|KMS Solutions|Full-time ¬∑ Mid-Senior level|"About the job
As a part of our Engineering team under KMS Solutions, the position is to design innovative data solution to solve customers' business challenges, to provide requirements, solutions, estimation and implement tools, integration.

Work with clients and development team to understand client business model & business needs, estimate and develop data solutions for medium/large data pipeline, integrate data tools to fit the client requirement.
Design conceptual, logical and physical data models
Analyze and implement data solutions that solve business problems such as ELT, data warehouse, data cleansing, data integration, data visualization and reporting.
Technical lead small/medium development teams, ensure the understanding and compliance of offshore engineers to the business requirements, and technical direction
Be the trusted technical consultant for clients

Qualifications

Key requirements:

Good understanding of dimensional and normalized database models.
Fluency in SQL and experience in Extract, Load, and Transform (ELT).
Have experience or a high understanding of data modeling.
Have experience in tuning and optimizing data pipeline and data queries
Having a programming mentality and problem-solving skills
Be flexible on technology
Be able to research new tools, technologies quickly to solve client's needs.
Can communicate with clients in English
Have the ability to evaluate and provide solutions for business cases/ issues
Have knowledge/experience in data quality, data integration, big data, data analytics, visualization
Nice to have:

Experience in the Business Intelligence (BI) / Data Warehousing (DW) industry
Capacity to listen, consult with clients and understand business models to provide the right solution to clients
Data consulting skills and experience
Experience with cloud-based SaaS platforms
Understanding DaaS (Data as a Service)
Capacity to be flexible, working on a different project, and prioritize the task
Have strong customer obsession skills
Experience working in the professional services organization
Experience with columnar databases
Experience in coding script

Additional Information

Thinking of joining KMS Solutions? Yes, you deserve it!

Progressive Career Development

Role-based training foundation
Active role at the global client-side
Continuous professional certification
Simple goals - achievable success
Attractive compensation

Up to 15 months salary/year
Performance review twice a year
Premium healthcare insurance
18+ paid leave/year
Engagement workplace

Flexi mode, modern work environment
Well-being centric
Impactful community organization

Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Join us and let yourself explore other fantastic things!"
2997942531|Senior Data Engineer, KMS Solutions (Da Nang)|ƒê√† Nang, Da Nang City, Vietnam|KMS Solutions|Full-time ¬∑ Mid-Senior level|"About the job
As a part of our Engineering team under KMS Solutions, the position is to research data tools to solve customers' requirements, provide solutions, estimation and implement tools, integration.

Work with clients and development team to understand business needs, estimate and develop data solutions for medium/large applications, tools, integration.
Design conceptual, logical and physical data models
Analyze and implement data solutions that solve business problems such as ETL, data warehouse, data cleansing, data integration, data visualization and reporting.
Lead small/medium development teams, ensure the understanding and compliance of offshore engineers to the business requirements, and technical direction

Qualifications

Key requirements:

Good understanding of dimensional and normalized database models.
Fluency in SQL and experience in Extract, Transform, and Load (ETL).
Have experience or high understanding in data modelling.
Having a programming mentality and problem-solving skills
Be flexible on technology
Be able to research new tools, technologies quickly to solve client's need.
Can communicate with clients in English
Have the ability to evaluate and provide solutions for business cases/ issues
Have knowledge/experience in data quality, data integration, big data, data analytics, visualization
Nice to have

Experience in the Business Intelligence (BI) / Data Warehousing (DW) industry
IT consulting skills and experience
Experience with cloud based SaaS platforms
Understanding DaaS (Data as a Service)
Experience working in professional services organization
Experience with columnar databases
Experience in coding script

Additional Information

Thinking of joining KMS Solutions? Yes, you deserve it!

Progressive Career Development

Role-based training foundation
Active role at the global client-side
Continuous professional certification
Simple goals - achievable success
Attractive compensation

Up to 15 months salary/year
Performance review twice a year
Premium healthcare insurance
18+ paid leave/year
Engagement workplace

Flexi mode, modern work environment
Well-being centric
Impactful community organization

Community development activities: 1% Pledge, KMS Gives charity every quarter, blood donation, public seminars, career orientation talks,‚Ä¶
Join us and let yourself explore other fantastic things!"
2980022425|Senior Big Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Scalefast|Full-time|"About the job
If You
Have a startup, ownership, and a Senior mindset: You enjoy moving fast with a customer-focused approach, you are comfortable with agile, you are able to take ownership of a feature without having very detailed specifications, you believe that done is better than perfect in a context where everyday day counts
Like building a data pipeline to handle billions of events every day to help our clients understand their customers
Want to work with a team present in 4 countries, Vietnam, France, Japan, and New Caledonia
Our Tech Stack
We process billions of events every day with Postgres and Big Query and we will move to a new architecture with ClickHouse/Redshift
Our app is built using C# 5.0 / .Net core / [ASP.Net](http://asp.net/) Core Web API with latest technology
CloudComputing mindset, we are moving our architecture to AWS and Google Cloud
We have a microservice oriented architecture using Docker & K8S
Quickly evolving data stack using AWS / PostgreSQL / BigQuery
Your Day To Day Will Be

We understand that working with data is not easy, especially with a high-tech background like Air360, so we need you to:
Work with our database engineers, big data engineers, and backend engineers to build and optimize our current database architecture with ClickHouse or Redshift
Research, build and optimize the current data pipeline to get the best performance
Design efficient architecture to store and analyze petabytes of data
Lead large-scale projects and mentor other developers
Implement complex ETL data pipeline workflows
Think of smart data formats to serve the functionalities of the product, while minimizing the cost
Developing tools to help data scientists and the Machine Learning team
by using some open source technologies such as Postgres, ClickHouse, AWS, GCP, Redshift, BigQuery, Kafka, Spark, Akka, Elasticsearch, etc.
Help Us Revolutionize The ECommerce Experience‚Ä¶

Scalefast helps amazing brands develop a successful Direct-to-Consumer online business. Our next-generation technology platform is built to optimize modern eCommerce. Our end-to-end infrastructure includes global merchant-of-record agreements, fulfillment, subscription, loyalty programs, and finance functions to deliver new revenue and delightful brand experiences. With a global presence (USA, Europe & Asia), Scalefast has proven itself with major brands like L‚ÄôOr√©al, Microsoft, Club Med, Hasbro, Flir, to name a few.

On top of our end-to-end DTC eCommerce offering, we provide our clients with Air360, a first-class customer experience and analytics platform which enables brands to understand how users interact with websites and mobile apps to boost customer engagement and rate conversion.

Our powerful technology brings a real complementary upgrade for lots of brands using Google analytics or similar tools.

Many brands and merchants are feeling the pain to maintain a proper tagging strategy and Air360 removes that barrier and allows brands to completely automate this process.

You Can Find Out More About Air360 Here

What can I expect at Scalefast and Air360?
Become part of a multi-cultural company where you can contribute with your experience and learn from the experience of others
Working with a sustainable development team
Work with amazing brands
2 remote days per week once we go back to the office (right now everyone is 100% remote!)
Private medical insurance
Get the opportunity to influence the future of our services and platform
Central Ho Chi Minh City office located a 5-minute walk from Duc Ba Church with green and open office
Lunch allowance
Parking fees allowance
18 days of holiday per year
English classes
Gym voucher
Teambuilding activities (outdoor activities / short trips)
Provide MacBook pro for employees to work most efficiently
Access to private sales by some of the exclusive brands we work with
Mental Health Wellbeing Program
You Must Have
Bachelor‚Äôs degree or equivalent industry experience
- 5/6+ years of Database Engineer experience, preferably in a global company
Strong experience with SQL Query and DBMS like Postgres, SQL Server, MySQL, MariaDB
Strong experience with big database engines, like Clickhouse, BigTable, BigQuery, Redshift
Excellent communication skills
Motivated, with a high desire to learn, results-driven, and with a strong commitment
It‚Äôs Nice To Have
Experience with ETL data process
Experience with AWS/GCP/Azure, Linux (RedHat \ CentOS and Ubuntu)
Experience with SAAS and analytics systems like Google Analytics, Hotjar
Experience with Kubernetes and Docker
Scripting skills (Python \ GO)
Today, more than 20 million people around the world buy through our stores. We celebrate the diversity of our customer base, and we want our employees to reflect those differences. At Scalefast, we‚Äôre committed to equal employment opportunity regardless of race, colour, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We strive to be a more equal opportunity workplace."
3012932566|Senior Data Engineer|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Katalon|Full-time ¬∑ Mid-Senior level|"About the job
About Katalon

Established in 2015, Katalon, Inc. is a global product company providing ‚ÄúAll-in-one‚Äù test automation solutions that empower teams to deliver software with excellence and confidence. Since launch, we have been experiencing exponential growth, continuously furnishing more than 100,000 enterprises worldwide, and were proudly named the ‚ÄúBest Test Automation of 2020‚Äù by Gartner Peer Insights.

RESPONSIBILITY:

The Insights Team at Katalon is like a business intelligence function acting as the single source of truth across the company to provide reports and insights in order to maximize the company's growth. The teams consist of Data Engineers and Data Analysts who welcome challenges, adapt quickly, strive to acquire new knowledge, learn new technologies, accept new responsibilities, and work well individually, as a team, and with other teams within the organization.

We are looking for an experienced Data Engineer to join our team. You will use various methods to build and manage the data infrastructure across the company. Overall, you‚Äôll strive for efficiency by aligning data systems with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources into the central data warehouse. If you are detail-oriented, with excellent organizational skills and experience in this field, we‚Äôd like to hear from you.

Your main responsibilities are:
Assemble large, complex sets of data that meet non-functional and functional business requirements
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Build required infrastructure for optimal extraction, transformation, and loading of data from various data sources
Build analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics
Work with stakeholders including but not limited to the Executive, Product, Engineering, and Revenue teams to support their data infrastructure needs while assisting with data-related technical issues
Maintain an in-depth understanding of relevant data engineering best practices and proactively discuss and share knowledge with the team
Display expertise with tools needed to solve the data problems
Show initiative and support when needed without being asked

Requirements

Must-have
Proven experience as a data engineer or in a similar role (preferred 3+ years)
Technical expertise with database, data warehousing, ELT, and data modeling
Knowledge of programming languages (Python)
Hands-on experience with SQL database design
Ability to communicate with both technical and non-technical stakeholders from different functional teams
Critical thinking, agile mindset and advanced English communication
Ability to influence without authority

Nice-to-have
Great numerical and analytical skills are a plus
Degree in Computer Science, IT, or similar field; a Master‚Äôs is a plus
Data engineering certification is a plus

Benefits

At Katalon, we bring together self-starting, open-minded, and talented people while actively promoting a transparent and growth-enabling working environment.

World-class products, Lifelong comrades, Experts in various fields, Exceptional teams, & Happy workplace are 5 things we are proud to constantly check off the list for the best place to work. But don‚Äôt just take our words for it. Take a better look below!
Attractive compensation package including achievable Quarterly Performance Bonus (3 - 5 salary months per year) and 13th-Month Salary
19 Annual leave days and other supportive allowances
Flexible working time and place together with high-end working equipment
A-class office amenities provided including modern workspace design, in-house entertainment facilities, and unlimited refreshments & snacks
Premium healthcare package for you and your loved ones
A company trip every summer, annual year-end party, team building activities, and so much more fun are waiting for you!

Katalon is proud to be an equal opportunity employer. We care about our people and celebrate our differences. We want to work with talented, collaborative, and innovative people. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other characteristics protected by law."
2984959428|[HCM] Senior Data Engineer - Up to $1200|Ho Chi Minh City, Ho Chi Minh City, Vietnam|Finan|Full-time ¬∑ Associate|"About the job
This job is sourced from a job board. Learn more
Finan is a Singapore - registered technology startup and the owner of the SoBanHang application. Founded by management executives from leading e-commerce businesses in Vietnam, including Lazada, Zalora (Rocket Internet), Topica Edtech Group, OneMountGroup... SoBanHang enables nano and micro-businesses to manage cash flow better with digital bookkeeping apps and increase sales through a hyperlocal online storefront. After 6 months of experiencing hypergrowth, SoBanHang is the market leader and doing the mission of helping thousands of small businesses go online So Ban Hang has been invested by leading investment funds such as FFEBE Ventures, Class 5, Kevin P.Ryan ‚Äì founder of Gilt Groupe, Business Insider and MongoDB. By 2025, SoBanHang will become the trusted partner of 1 million businesses, helping them serve 100 million customers and generate $100 billion in sales. With that hyper-growth, we look for talented teammates to join our rocketship as Senior Data Engineer. This plays a critical role in building a solid tech foundation for hundreds of millions of users. Job description: Work with data to solve business problems, building and maintaining the infrastructure to answer questions and improve processes. Help streamline our data science workflows, adding value to our product offering and building out our customer lifecycle and retention models. Work closely with the data science and business intelligence teams to develop data models and pipelines for research, reporting, and machine learning. Be an advocate for best practices and continued learning. Develop API using Python framework for internal transfer data. Job requirements: 3 or more years of experience with Python, SQL, and data visualization/exploration tools Knowledge of programming languages like SQL Baisc, Postgres, BigQuery, and Python. Familiarity with the AWS ecosystem specifically Kubernetes Engine. Technical proficiency regarding database design development, data models, techniques for data mining, and segmentation. Experience in handling programming ETL frameworks, databases. Problem-solving, teamwork, verbal and written communication skills. Comfort working in a dynamic, research-oriented team with concurrent projects. Our benefits: Create impactful technology products to bring value to society, especially to those who are underserved. Work with tech-giant partners in Vietnam and the region: Vietjet, Savico, Facebook, Google‚Ä¶ and have access to the world's leading investment funds. Young, dynamic start-up environment with knowledgeable and experienced leaders Hone your skills through the new challenges, have your say in contribution towards the common goals. Competitive remuneration package. Have opportunities to become a co-founding member with an attractive ESOP policy. Cool office, work time & location flexibility, other perks include snacks, coffee, and healthy food provided daily."
3008026721|(Middle/Senior) Backend/Data Engineer - Data Platform|Ho Chi Minh City, Ho Chi Minh City, Vietnam|TIKI|Full-time|"About the job
Delivering the best customer experience is the biggest compulsion at Tiki. And our data team is one crucial part of this important mission. We have been trying to understand our customers deeply based on our massive amount of data so that we could make shopping better and easier for our customers as well as grow our business quickly.

Responsibilities
Design the architecture to process user behaviors in real-time
Develop an ‚ÄúOPEN API‚Äù system that helps not only the internal team can use it but also many 3rd services can integrate with.
Build an A/B testing system which can handle hundreds of models at the same time with huge traffic from customers
Handle data pipeline flow. Currently, Tiki is handling :1 billion events per day.
Requirements:
A minimum of 2 year of experience with backend (Golang, Java) is a plus
Strong at object-oriented analysis and design
Understanding of design for large scalability, performance and reliability. Familiar with some systems such as Kafka, Redis, Mysql, MongoDB, Elasticsearch, ‚Ä¶.
Worked with systems to proceed with big data such as Spark, Druid, Hadoop, Cassandra ...
Experience working on a large scale deployment and performance tuning
Rich experiences about container environment such as Docker, Kubernetes
Experience with cloud-based system Google Cloud Platform, Amazon Web Services is a plus
Benefits:

Inside our engineering team:
We iterate constantly. There‚Äòs no such thing as the best version of anything, just a constant streams of improvements and tests.
We move fast, really fast. Major changes can be executed in a few days, many times just a few hours.
We have a data-informed mindset. We try to use data to inform our decision as much as possible.
We are independent. Most of the time, your team will not need technical assistance from other teams.
We take risks. We‚Äòre not afraid to challenge ""best practices"".
Our attractive offers include:
Open communication with passionate and experienced members.
Challenging working environment.
Easy access to the library with tons of startup, product, UX, coding... books.
Private healthcare insurance.
Annual health check-ups.
Special internal programs for Tikiers when shopping on Tiki.vn (free ship TikiNow service, discount...).
Internal events to bond our mutual understanding & spirit such as team building, team outing, Tiki‚Äòs birthday, year-end party...
New & beautiful office with a pantry room (with bar), entertainment & gymnastic equipment, yoga rooms, a library and an open space facilitating cross-department communication.
Competitive salary and performance review, 13th-month pay based on performance."
2978044675|Google Cloud Platform (GCP) ‚Äì Cloud Data Engineer|Ho Chi Minh City, Vietnam|HCL Vietnam|Full-time ¬∑ Mid-Senior level|"About the job
HCL Vietnam Company Limited, (www.hcltech.com) is looking for Senior Java Developer

ABOUT HCL
HCL Technologies is a next-generation global technology company that helps enterprises reimagine their businesses for the digital age. HCL offer an integrated portfolio of products, solutions, services, and IP through our Mode 1-2-3 strategy built around Digital, IoT, Cloud, Automation, Cybersecurity, Analytics, Infrastructure Management and Engineering Services, amongst others, to help enterprises reimagine their businesses for the digital age.
With a worldwide network of R&D, innovation labs and delivery centers, and 150,000+ ‚ÄòIdeapreneurs‚Äô working in 49 countries, HCL serves leading enterprises across key industries, including 250 of the Fortune 500 and 650 of the Global 2000.

INTRODUCTION
HCL is setting up large delivery centres for digital transformation projects in Vietnam and as part of that we are starting a delivery centre in Ho Chi Minh City for Data transformation initiative of a major Global Bank. Work involves transforming legacy data into modern digital data technology and hosting it in Google Cloud Platform. This is an exciting project in which employees get opportunity to experience most modern data tool stack. Project is delivered in agile ways of working, an excellent opportunity to work for a global leader.

RESPONSIBILITIES
You will be responsible for building and running the data processing pipeline on Google cloud platform
‚Ä¢ Work with implementation teams from concept to operations, providing deep technical expertise for successfully deploying large scale data solutions in the enterprise, using modern data/analytics technologies on GCP
‚Ä¢ Work with data team to efficiently use GCP to analyze data, build data models, and generate reports/visualizations
‚Ä¢ Integrate massive datasets from multiple data sources for data modelling
‚Ä¢ Implement methods for Devops automation of all parts of the build data pipelines to deploy from development to production
‚Ä¢ Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management
‚Ä¢ Design pipelines and architectures for data processing
‚Ä¢ Extract, load, transform, clean and validate data

MAIN REQUIREMENTS
‚û¢ Must requirements:
‚Ä¢ At least 3 years of experience in ETL Tools (such as Infromatica, Apache Beam, Kafka)
‚Ä¢ At least 3 years of experience in Google Cloud Platform (BigQuery, DataProc, DataFlow)
‚Ä¢ Having relative experience in any scripting/programming language as following: Java/Python/Go
‚Ä¢ Having relative experience in declarative CI/CD (Jenkins, Azure DevOps)
‚Ä¢ Having relative experience in Databases: SQL and NoSQL
‚Ä¢ Have a strong engineering mindset to automate tasks, identify use cases, test cases, improve the system, PR/Incident resolution and deployments

‚û¢ Good to Have:
‚Ä¢ Having relative experience in Automation: Kubernetes or Docker & Containerization
‚Ä¢ Having relative experience in Infrastructure as a Code (IaaC) (i.e., Terraform, Cloud Formation, Azure ARM Templates)
‚Ä¢ Having knowledge or experience in Big Data - Hadoop ecosystems including HDFS, MapReduce, YARN, HBase, Zookeeper, Spark, Pig, Hive‚Ä¶
‚Ä¢ Having knowledge or experience with Hadoop distributions such as Cloudera, HortonWorks‚Ä¶
‚Ä¢ Having relative experience in Data management:
o Data Governance
o Data Architecture
o Data Modelling
o Data Quality
o Data integration

BENEFIT
‚Ä¢ Attractive package including base salary + 13th month salary + Performance Bonus HCL
‚Ä¢ Insurance based on full base salary
‚Ä¢ Meal allowance 730,000/month
‚Ä¢ 100% of full salary and benefits as an official employee from the 1st day of working
‚Ä¢ Medical Benefit (Bao Viet Insurance Package) for Employee and Family
‚Ä¢ Working in a fast paced, flexible, and multinational working environment with opportunity to travel onsite (in 49 countries)
‚Ä¢ Internal Training (Technical & Functional & English)
‚Ä¢ Working time: 8:30 am-6:00 pm from Mondays to Fridays

For support and more information, please contact:

Ngoc Nguyen (Ms) Recruitment Department
HCL Vietnam Company Limited
Zalo/Mobile: (84)968765839
Email: ngoc_nguyen@hcl.com
Linkedin: www.linkedin.com/in/ngoc-nguyen-6b322422a
Contact the job poster
Ngoc Nguyen 2nd
IT Recruiter at HCL Technologies | Urgently looking for Java Spring, Data Engineer
Job Poster Location
Ho Chi Minh City, Vietnam
Send InMail"
2976005538|Senior Data Engineer (Chatbot)|Ho Chi Minh City, Vietnam|NAB in collaboration with Positive Thinking Company in Vietnam|Full-time ¬∑ Mid-Senior level|"About the job
ABOUT THE JOB

We are seeking a motivated Senior Data Engineer to join the Workplace Service team at National Australia Bank. As a Data Engineer, you‚Äôll work as part of the NAB Workplace Service Support chatbot team, to design, build, optimize, and maintain innovative data engineering & analytic solutions on both Microsoft Azure & NAB‚Äôs in-house Data Platforms. You‚Äôll collaborate directly with both business and technical team members to help them perform & automate data ETL, analysis, and realize actionable insights and value from conversational AI data.

YOUR JOB RESPONSIBILITIES

Collaborate with the SMEs from the Service Support teams to understand the current data workflows and help design autonomous pipelines for conversational AI data ETL.
Contribute to the data engineering solution design, usually in collaboration with business analysts, platform architects, security architects and product owners.
Work closely with other software engineers in a hands-on fashion, to implement the solutions in a programming environment


YOUR SKILLS AND EXPERIENCE

5+ years of relevant industry experience in a technical role, including cloud development, user experience, machine learning & data science and analytics at the enterprise level: Data Engineering; MS Azure (2-3 years); Chatbot DevOps (2-3 years); Service desk or customer service (desirable)
Hands-on experience in data engineering processes, such as: Raw and meta-data services; Data ingestion; Data transformation; Scheduling & workflow; Data model management; Data security & compliance
Hands-on experience in data platforms and toolsets, such as Azure Monitor, Azure Application Insights, Azure Functions, Azure Database, Azure DevOps, PostgreSQL, Redshift, and others. Experience with all of the above-mentioned services is not a requirement.
Strong language capabilities with T/K/SQL, Python, PySpark, SparkSQL, Scala, PowerShell, ARM templates, NodeJS or R
Hands-on experience with analytics & reporting toolset such as PowerBI, Tableau, or EKL stack
Preferred experience in natural language processing and/or conversational AI, chatbot development
Strong understanding of cloud infrastructure & networking concepts
Preferred knowledge of CI/CD Platforms like Managed Kubernetes Service (AKS), Container Platforms, Compliance Build Automation, Agile, and Developer, AppSec tools & testing.
Good understanding of storage, load balancers, virtualization, web, database and messaging services with the ability to dive deep into any of these areas when necessary.
High attention to detail and always ready to push the limits
Ability to work collaboratively in a cross-functional DevOps team environment
Experience building machine learning algorithms, and then testing results against trained data sets, using unstructured inputs and converting them into structured form is desired
Excellent communication skills

Desirable

Master‚Äôs degree in Computer Science, Data Science, Information Systems or related fields
Certified in one or more of the following AZ-900, AZ-203, AZ-400, AI-102, AI-900, DP-900
Certified or similar training in service management like ITIL V3.0


THE BENEFITS AND PERKS
Very competitive remuneration package
Generous private family healthcare for yourself and two family members
A solid team behind you ‚Äì great people who love what they do
The pleasant, enthusiastic, international work environment
Opportunity for traveling & training in Australia
A brand new & state of the art Agile office
Latest technologies, flexible working hours
A promising training and career path
Fun team activities & outing
English learning with native English teachers


If this excites you, let's have a chat over a cup of coffee!"
